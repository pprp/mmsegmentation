*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2022-03-23 16:57:32,832 - mmseg - INFO - Multi-processing start method is `None`
2022-03-23 16:57:32,833 - mmseg - INFO - OpenCV num_threads is `<built-in function getNumThreads>
2022-03-23 16:57:32,833 - mmseg - INFO - OMP num threads is 1
2022-03-23 16:57:33,407 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]
CUDA available: True
GPU 0,1,2,3: NVIDIA GeForce RTX 3090
CUDA_HOME: /data/apps/cuda/11.1
NVCC: Build cuda_11.1.TC455_06.29069683_0
GCC: gcc (GCC) 9.3.0
PyTorch: 1.8.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.9.1
OpenCV: 4.5.4
MMCV: 1.4.7
MMCV Compiler: GCC 8.3
MMCV CUDA Compiler: not available
MMSegmentation: 0.22.1+eb99824
------------------------------------------------------------

2022-03-23 16:57:33,407 - mmseg - INFO - Distributed training: True
2022-03-23 16:57:33,657 - mmseg - INFO - Config:
dataset_type = 'CityscapesDataset'
data_root = '/HOME/scz0088/run/cityscapes/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 1024)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 1024), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 1024), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 1024),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type='CityscapesDataset',
        data_root='/HOME/scz0088/run/cityscapes/',
        img_dir='leftImg8bit/train',
        ann_dir='gtFine/train',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 1024), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 1024), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='CityscapesDataset',
        data_root='/HOME/scz0088/run/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CityscapesDataset',
        data_root='/HOME/scz0088/run/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=
    '/HOME/scz0088/run/project/mmsegmentation/work_dirs/resnet50_rf/model_r50_rf.pth.tar',
    backbone=dict(
        type='ResNet_Att',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        dilations=(1, 1, 2, 4),
        strides=(1, 2, 1, 1),
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        norm_eval=False,
        style='pytorch',
        contract_dilation=True,
        att='RF'),
    decode_head=dict(
        type='ASPPHead',
        in_channels=2048,
        in_index=3,
        channels=512,
        dilations=(1, 12, 24, 36),
        dropout_ratio=0.1,
        num_classes=19,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    auxiliary_head=dict(
        type='FCNHead',
        in_channels=1024,
        in_index=2,
        channels=256,
        num_convs=1,
        concat_input=False,
        dropout_ratio=0.1,
        num_classes=19,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = '/HOME/scz0088/run/project/mmsegmentation/work_dirs/pprp_deeplabv3_r50-d8_512x1024_40k_cityscapes_RF_rerun_fix_noise/latest.pth'
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)
optimizer_config = dict()
lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=50000)
checkpoint_config = dict(
    by_epoch=False, interval=4000, save_last=True, max_keep_ckpts=2)
evaluation = dict(interval=4000, metric='mIoU', pre_eval=True)
work_dir = './work_dirs/pprp_deeplabv3_r50-d8_512x1024_40k_cityscapes_RF_rerun_fix_noise_continue_50k'
gpu_ids = range(0, 4)
auto_resume = False

2022-03-23 16:57:38,132 - mmseg - INFO - Set random seed to 60324266, deterministic: False
/data/run01/scz0088/project/mmsegmentation/mmseg/models/backbones/resnet_att.py:470: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
/data/run01/scz0088/project/mmsegmentation/mmseg/models/backbones/resnet_att.py:470: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
/data/run01/scz0088/project/mmsegmentation/mmseg/models/backbones/resnet_att.py:470: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
/data/run01/scz0088/project/mmsegmentation/mmseg/models/backbones/resnet_att.py:470: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
2022-03-23 16:57:39,137 - mmseg - INFO - initialize ResNet_Att with init_cfg {'type': 'Pretrained', 'checkpoint': '/HOME/scz0088/run/project/mmsegmentation/work_dirs/resnet50_rf/model_r50_rf.pth.tar'}
2022-03-23 16:57:39,138 - mmcv - INFO - load model from: /HOME/scz0088/run/project/mmsegmentation/work_dirs/resnet50_rf/model_r50_rf.pth.tar
2022-03-23 16:57:39,138 - mmcv - INFO - load checkpoint from local path: /HOME/scz0088/run/project/mmsegmentation/work_dirs/resnet50_rf/model_r50_rf.pth.tar
2022-03-23 16:57:40,884 - mmcv - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

2022-03-23 16:57:40,944 - mmseg - INFO - initialize ASPPHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
2022-03-23 16:57:41,050 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
2022-03-23 16:57:41,057 - mmseg - INFO - EncoderDecoder(
  (backbone): ResNet_Att(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (attention): ReceptiveFieldAttention(
          (_ops): ModuleList(
            (0): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): NoiseOp()
            (5): NoiseOp()
          )
          (bottle): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv1x1): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (se): SE(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=256, out_features=64, bias=False)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=64, out_features=256, bias=False)
              (3): Sigmoid()
            )
          )
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (attention): ReceptiveFieldAttention(
          (_ops): ModuleList(
            (0): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): NoiseOp()
            (5): NoiseOp()
          )
          (bottle): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv1x1): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (se): SE(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=256, out_features=64, bias=False)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=64, out_features=256, bias=False)
              (3): Sigmoid()
            )
          )
        )
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (attention): ReceptiveFieldAttention(
          (_ops): ModuleList(
            (0): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): NoiseOp()
            (5): NoiseOp()
          )
          (bottle): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv1x1): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (se): SE(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=256, out_features=64, bias=False)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=64, out_features=256, bias=False)
              (3): Sigmoid()
            )
          )
        )
      )
    )
    (layer2): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (attention): ReceptiveFieldAttention(
          (_ops): ModuleList(
            (0): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
              (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): NoiseOp()
            (5): NoiseOp()
          )
          (bottle): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv1x1): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (se): SE(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=512, out_features=128, bias=False)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=128, out_features=512, bias=False)
              (3): Sigmoid()
            )
          )
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (attention): ReceptiveFieldAttention(
          (_ops): ModuleList(
            (0): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
              (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): NoiseOp()
            (5): NoiseOp()
          )
          (bottle): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv1x1): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (se): SE(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=512, out_features=128, bias=False)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=128, out_features=512, bias=False)
              (3): Sigmoid()
            )
          )
        )
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (attention): ReceptiveFieldAttention(
          (_ops): ModuleList(
            (0): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
              (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): NoiseOp()
            (5): NoiseOp()
          )
          (bottle): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv1x1): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (se): SE(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=512, out_features=128, bias=False)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=128, out_features=512, bias=False)
              (3): Sigmoid()
            )
          )
        )
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (attention): ReceptiveFieldAttention(
          (_ops): ModuleList(
            (0): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
              (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): NoiseOp()
            (5): NoiseOp()
          )
          (bottle): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv1x1): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (se): SE(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=512, out_features=128, bias=False)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=128, out_features=512, bias=False)
              (3): Sigmoid()
            )
          )
        )
      )
    )
    (layer3): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (attention): ReceptiveFieldAttention(
          (_ops): ModuleList(
            (0): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): NoiseOp()
            (5): NoiseOp()
          )
          (bottle): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv1x1): Conv2d(768, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (se): SE(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=1024, out_features=256, bias=False)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=256, out_features=1024, bias=False)
              (3): Sigmoid()
            )
          )
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (attention): ReceptiveFieldAttention(
          (_ops): ModuleList(
            (0): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): NoiseOp()
            (5): NoiseOp()
          )
          (bottle): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv1x1): Conv2d(768, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (se): SE(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=1024, out_features=256, bias=False)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=256, out_features=1024, bias=False)
              (3): Sigmoid()
            )
          )
        )
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (attention): ReceptiveFieldAttention(
          (_ops): ModuleList(
            (0): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): NoiseOp()
            (5): NoiseOp()
          )
          (bottle): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv1x1): Conv2d(768, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (se): SE(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=1024, out_features=256, bias=False)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=256, out_features=1024, bias=False)
              (3): Sigmoid()
            )
          )
        )
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (attention): ReceptiveFieldAttention(
          (_ops): ModuleList(
            (0): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): NoiseOp()
            (5): NoiseOp()
          )
          (bottle): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv1x1): Conv2d(768, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (se): SE(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=1024, out_features=256, bias=False)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=256, out_features=1024, bias=False)
              (3): Sigmoid()
            )
          )
        )
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (attention): ReceptiveFieldAttention(
          (_ops): ModuleList(
            (0): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): NoiseOp()
            (5): NoiseOp()
          )
          (bottle): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv1x1): Conv2d(768, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (se): SE(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=1024, out_features=256, bias=False)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=256, out_features=1024, bias=False)
              (3): Sigmoid()
            )
          )
        )
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (attention): ReceptiveFieldAttention(
          (_ops): ModuleList(
            (0): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): NoiseOp()
            (5): NoiseOp()
          )
          (bottle): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv1x1): Conv2d(768, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (se): SE(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=1024, out_features=256, bias=False)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=256, out_features=1024, bias=False)
              (3): Sigmoid()
            )
          )
        )
      )
    )
    (layer4): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (attention): ReceptiveFieldAttention(
          (_ops): ModuleList(
            (0): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
              (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): NoiseOp()
            (5): NoiseOp()
          )
          (bottle): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv1x1): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (se): SE(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=2048, out_features=512, bias=False)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=2048, bias=False)
              (3): Sigmoid()
            )
          )
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (attention): ReceptiveFieldAttention(
          (_ops): ModuleList(
            (0): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
              (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): NoiseOp()
            (5): NoiseOp()
          )
          (bottle): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv1x1): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (se): SE(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=2048, out_features=512, bias=False)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=2048, bias=False)
              (3): Sigmoid()
            )
          )
        )
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (attention): ReceptiveFieldAttention(
          (_ops): ModuleList(
            (0): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
              (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (4): NoiseOp()
            (5): NoiseOp()
          )
          (bottle): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv1x1): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (se): SE(
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (fc): Sequential(
              (0): Linear(in_features=2048, out_features=512, bias=False)
              (1): ReLU(inplace=True)
              (2): Linear(in_features=512, out_features=2048, bias=False)
              (3): Sigmoid()
            )
          )
        )
      )
    )
  )
  init_cfg={'type': 'Pretrained', 'checkpoint': '/HOME/scz0088/run/project/mmsegmentation/work_dirs/resnet50_rf/model_r50_rf.pth.tar'}
  (decode_head): ASPPHead(
    input_transform=None, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss()
    (conv_seg): Conv2d(512, 19, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (image_pool): Sequential(
      (0): AdaptiveAvgPool2d(output_size=1)
      (1): ConvModule(
        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (aspp_modules): ASPPModule(
      (0): ConvModule(
        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (2): ConvModule(
        (conv): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (3): ConvModule(
        (conv): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(2560, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  (auxiliary_head): FCNHead(
    input_transform=None, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss()
    (conv_seg): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (convs): Sequential(
      (0): ConvModule(
        (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2022-03-23 16:57:41,180 - mmseg - INFO - Loaded 2975 images
2022-03-23 16:57:43,246 - mmseg - INFO - Loaded 500 images
2022-03-23 16:57:43,247 - mmseg - INFO - load checkpoint from local path: /HOME/scz0088/run/project/mmsegmentation/work_dirs/pprp_deeplabv3_r50-d8_512x1024_40k_cityscapes_RF_rerun_fix_noise/latest.pth
2022-03-23 16:57:50,294 - mmseg - INFO - resumed from epoch: 108, iter 39999
2022-03-23 16:57:50,295 - mmseg - INFO - Start running, host: scz0088@g0011, work_dir: /data/run01/scz0088/project/mmsegmentation/work_dirs/pprp_deeplabv3_r50-d8_512x1024_40k_cityscapes_RF_rerun_fix_noise_continue_50k
2022-03-23 16:57:50,296 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2022-03-23 16:57:50,296 - mmseg - INFO - workflow: [('train', 1)], max: 50000 iters
2022-03-23 16:57:50,296 - mmseg - INFO - Checkpoints will be saved to /data/run01/scz0088/project/mmsegmentation/work_dirs/pprp_deeplabv3_r50-d8_512x1024_40k_cityscapes_RF_rerun_fix_noise_continue_50k by HardDiskBackend.
2022-03-23 16:58:09,982 - mmseg - INFO - Saving checkpoint at 40000 iterations
2022-03-23 16:58:11,226 - mmseg - INFO - Exp name: pprp_deeplabv3_r50-d8_512x1024_40k_cityscapes.py
2022-03-23 16:58:11,226 - mmseg - INFO - Iter [40000/50000]	lr: 2.426e-03, eta: 72 days, 7:22:26, time: 12.495, data_time: 0.690, memory: 19929, decode.loss_ce: 0.0987, decode.acc_seg: 96.5156, aux.loss_ce: 0.0561, aux.acc_seg: 95.3719, loss: 0.1548
[                                                  ] 0/500, elapsed: 0s, ETA:[                                ] 1/500, 0.1 task/s, elapsed: 10s, ETA:  5238s[                                ] 2/500, 0.2 task/s, elapsed: 10s, ETA:  2614s[                                ] 3/500, 0.3 task/s, elapsed: 10s, ETA:  1739s[                                ] 4/500, 0.4 task/s, elapsed: 10s, ETA:  1302s[                                ] 5/500, 0.5 task/s, elapsed: 11s, ETA:  1088s[                                ] 6/500, 0.5 task/s, elapsed: 11s, ETA:   905s[                                ] 7/500, 0.6 task/s, elapsed: 11s, ETA:   774s[                                ] 8/500, 0.7 task/s, elapsed: 11s, ETA:   676s[                                ] 9/500, 0.8 task/s, elapsed: 11s, ETA:   626s[                               ] 10/500, 0.9 task/s, elapsed: 11s, ETA:   563s[                               ] 11/500, 1.0 task/s, elapsed: 11s, ETA:   510s[                               ] 12/500, 1.0 task/s, elapsed: 11s, ETA:   467s[                               ] 13/500, 1.1 task/s, elapsed: 12s, ETA:   451s[                               ] 14/500, 1.2 task/s, elapsed: 12s, ETA:   418s[                               ] 15/500, 1.2 task/s, elapsed: 12s, ETA:   389s[                               ] 16/500, 1.3 task/s, elapsed: 12s, ETA:   364s[>                              ] 17/500, 1.4 task/s, elapsed: 13s, ETA:   357s[>                              ] 18/500, 1.4 task/s, elapsed: 13s, ETA:   336s[>                              ] 19/500, 1.5 task/s, elapsed: 13s, ETA:   318s[>                              ] 20/500, 1.6 task/s, elapsed: 13s, ETA:   301s[>                              ] 21/500, 1.6 task/s, elapsed: 13s, ETA:   298s[>                              ] 22/500, 1.7 task/s, elapsed: 13s, ETA:   284s[>                              ] 23/500, 1.8 task/s, elapsed: 13s, ETA:   271s[>                              ] 24/500, 1.8 task/s, elapsed: 13s, ETA:   259s[>                              ] 25/500, 1.8 task/s, elapsed: 14s, ETA:   259s[>                              ] 26/500, 1.9 task/s, elapsed: 14s, ETA:   249s[>                              ] 27/500, 2.0 task/s, elapsed: 14s, ETA:   239s[>                              ] 28/500, 2.1 task/s, elapsed: 14s, ETA:   230s[>                              ] 29/500, 2.1 task/s, elapsed: 14s, ETA:   229s[>                              ] 30/500, 2.1 task/s, elapsed: 14s, ETA:   221s[>                              ] 31/500, 2.2 task/s, elapsed: 14s, ETA:   214s[>                              ] 32/500, 2.3 task/s, elapsed: 14s, ETA:   206s[>>                             ] 33/500, 2.3 task/s, elapsed: 15s, ETA:   207s[>>                             ] 34/500, 2.3 task/s, elapsed: 15s, ETA:   200s[>>                             ] 35/500, 2.4 task/s, elapsed: 15s, ETA:   194s[>>                             ] 36/500, 2.5 task/s, elapsed: 15s, ETA:   188s[>>                             ] 37/500, 2.5 task/s, elapsed: 15s, ETA:   189s[>>                             ] 38/500, 2.5 task/s, elapsed: 15s, ETA:   184s[>>                             ] 39/500, 2.6 task/s, elapsed: 15s, ETA:   179s[>>                             ] 40/500, 2.6 task/s, elapsed: 15s, ETA:   174s[>>                             ] 41/500, 2.6 task/s, elapsed: 16s, ETA:   176s[>>                             ] 42/500, 2.7 task/s, elapsed: 16s, ETA:   171s[>>                             ] 43/500, 2.7 task/s, elapsed: 16s, ETA:   167s[>>                             ] 44/500, 2.8 task/s, elapsed: 16s, ETA:   163s[>>                             ] 45/500, 2.8 task/s, elapsed: 16s, ETA:   164s[>>                             ] 46/500, 2.8 task/s, elapsed: 16s, ETA:   160s[>>                             ] 47/500, 2.9 task/s, elapsed: 16s, ETA:   156s[>>                             ] 48/500, 3.0 task/s, elapsed: 16s, ETA:   153s[>>>                            ] 49/500, 2.9 task/s, elapsed: 17s, ETA:   154s[>>>                            ] 50/500, 3.0 task/s, elapsed: 17s, ETA:   151s[>>>                            ] 51/500, 3.0 task/s, elapsed: 17s, ETA:   147s[>>>                            ] 52/500, 3.1 task/s, elapsed: 17s, ETA:   144s[>>>                            ] 53/500, 3.1 task/s, elapsed: 17s, ETA:   145s[>>>                            ] 54/500, 3.1 task/s, elapsed: 17s, ETA:   142s[>>>                            ] 55/500, 3.2 task/s, elapsed: 17s, ETA:   139s[>>>                            ] 56/500, 3.3 task/s, elapsed: 17s, ETA:   136s[>>>                            ] 57/500, 3.2 task/s, elapsed: 18s, ETA:   138s[>>>                            ] 58/500, 3.3 task/s, elapsed: 18s, ETA:   135s[>>>                            ] 59/500, 3.3 task/s, elapsed: 18s, ETA:   133s[>>>                            ] 60/500, 3.4 task/s, elapsed: 18s, ETA:   130s[>>>                            ] 61/500, 3.3 task/s, elapsed: 18s, ETA:   131s[>>>                            ] 62/500, 3.4 task/s, elapsed: 18s, ETA:   129s[>>>                            ] 63/500, 3.5 task/s, elapsed: 18s, ETA:   126s[>>>                            ] 64/500, 3.5 task/s, elapsed: 18s, ETA:   124s[>>>>                           ] 65/500, 3.5 task/s, elapsed: 19s, ETA:   126s[>>>>                           ] 66/500, 3.5 task/s, elapsed: 19s, ETA:   123s[>>>>                           ] 67/500, 3.6 task/s, elapsed: 19s, ETA:   121s[>>>>                           ] 68/500, 3.6 task/s, elapsed: 19s, ETA:   119s[>>>>                           ] 69/500, 3.6 task/s, elapsed: 19s, ETA:   120s[>>>>                           ] 70/500, 3.6 task/s, elapsed: 19s, ETA:   118s[>>>>                           ] 71/500, 3.7 task/s, elapsed: 19s, ETA:   116s[>>>>                           ] 72/500, 3.7 task/s, elapsed: 19s, ETA:   114s[>>>>                           ] 73/500, 3.7 task/s, elapsed: 20s, ETA:   116s[>>>>                           ] 74/500, 3.7 task/s, elapsed: 20s, ETA:   114s[>>>>                           ] 75/500, 3.8 task/s, elapsed: 20s, ETA:   112s[>>>>                           ] 76/500, 3.8 task/s, elapsed: 20s, ETA:   110s[>>>>                           ] 77/500, 3.8 task/s, elapsed: 20s, ETA:   111s[>>>>                           ] 78/500, 3.9 task/s, elapsed: 20s, ETA:   109s[>>>>                           ] 79/500, 3.9 task/s, elapsed: 20s, ETA:   108s[>>>>                           ] 80/500, 4.0 task/s, elapsed: 20s, ETA:   106s[>>>>>                          ] 81/500, 3.9 task/s, elapsed: 21s, ETA:   107s[>>>>>                          ] 82/500, 4.0 task/s, elapsed: 21s, ETA:   106s[>>>>>                          ] 83/500, 4.0 task/s, elapsed: 21s, ETA:   104s[>>>>>                          ] 84/500, 4.1 task/s, elapsed: 21s, ETA:   103s[>>>>>                          ] 85/500, 4.0 task/s, elapsed: 21s, ETA:   104s[>>>>>                          ] 86/500, 4.1 task/s, elapsed: 21s, ETA:   102s[>>>>>                          ] 87/500, 4.1 task/s, elapsed: 21s, ETA:   101s[>>>>>                          ] 88/500, 4.1 task/s, elapsed: 21s, ETA:    99s[>>>>>                          ] 89/500, 4.1 task/s, elapsed: 22s, ETA:   100s[>>>>>                          ] 90/500, 4.1 task/s, elapsed: 22s, ETA:    99s[>>>>>                          ] 91/500, 4.2 task/s, elapsed: 22s, ETA:    98s[>>>>>                          ] 92/500, 4.2 task/s, elapsed: 22s, ETA:    96s[>>>>>                          ] 93/500, 4.2 task/s, elapsed: 22s, ETA:    97s[>>>>>                          ] 94/500, 4.2 task/s, elapsed: 22s, ETA:    96s[>>>>>                          ] 95/500, 4.3 task/s, elapsed: 22s, ETA:    95s[>>>>>                          ] 96/500, 4.3 task/s, elapsed: 22s, ETA:    93s[>>>>>>                         ] 97/500, 4.3 task/s, elapsed: 23s, ETA:    95s[>>>>>>                         ] 98/500, 4.3 task/s, elapsed: 23s, ETA:    93s[>>>>>>                         ] 99/500, 4.3 task/s, elapsed: 23s, ETA:    92s[>>>>>>                        ] 100/500, 4.4 task/s, elapsed: 23s, ETA:    91s[>>>>>>                        ] 101/500, 4.3 task/s, elapsed: 23s, ETA:    92s[>>>>>>                        ] 102/500, 4.4 task/s, elapsed: 23s, ETA:    91s[>>>>>>                        ] 103/500, 4.4 task/s, elapsed: 23s, ETA:    90s[>>>>>>                        ] 104/500, 4.5 task/s, elapsed: 23s, ETA:    89s[>>>>>>                        ] 105/500, 4.4 task/s, elapsed: 24s, ETA:    90s[>>>>>>                        ] 106/500, 4.5 task/s, elapsed: 24s, ETA:    89s[>>>>>>                        ] 107/500, 4.5 task/s, elapsed: 24s, ETA:    87s[>>>>>>                        ] 108/500, 4.5 task/s, elapsed: 24s, ETA:    86s[>>>>>>                        ] 109/500, 4.5 task/s, elapsed: 24s, ETA:    87s[>>>>>>                        ] 110/500, 4.5 task/s, elapsed: 24s, ETA:    86s[>>>>>>                        ] 111/500, 4.6 task/s, elapsed: 24s, ETA:    85s[>>>>>>                        ] 112/500, 4.6 task/s, elapsed: 24s, ETA:    84s[>>>>>>                        ] 113/500, 4.6 task/s, elapsed: 25s, ETA:    85s[>>>>>>                        ] 114/500, 4.6 task/s, elapsed: 25s, ETA:    84s[>>>>>>                        ] 115/500, 4.6 task/s, elapsed: 25s, ETA:    83s[>>>>>>                        ] 116/500, 4.7 task/s, elapsed: 25s, ETA:    82s[>>>>>>>                       ] 117/500, 4.6 task/s, elapsed: 25s, ETA:    83s[>>>>>>>                       ] 118/500, 4.7 task/s, elapsed: 25s, ETA:    82s[>>>>>>>                       ] 119/500, 4.7 task/s, elapsed: 25s, ETA:    81s[>>>>>>>                       ] 120/500, 4.7 task/s, elapsed: 25s, ETA:    80s[>>>>>>>                       ] 121/500, 4.7 task/s, elapsed: 26s, ETA:    81s[>>>>>>>                       ] 122/500, 4.7 task/s, elapsed: 26s, ETA:    80s[>>>>>>>                       ] 123/500, 4.8 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 124/500, 4.8 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 125/500, 4.7 task/s, elapsed: 26s, ETA:    79s[>>>>>>>                       ] 126/500, 4.8 task/s, elapsed: 26s, ETA:    78s[>>>>>>>                       ] 127/500, 4.8 task/s, elapsed: 26s, ETA:    77s[>>>>>>>                       ] 128/500, 4.9 task/s, elapsed: 26s, ETA:    77s[>>>>>>>                       ] 129/500, 4.8 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 130/500, 4.8 task/s, elapsed: 27s, ETA:    77s[>>>>>>>                       ] 131/500, 4.9 task/s, elapsed: 27s, ETA:    76s[>>>>>>>                       ] 132/500, 4.9 task/s, elapsed: 27s, ETA:    75s[>>>>>>>                       ] 133/500, 4.9 task/s, elapsed: 27s, ETA:    76s[>>>>>>>>                      ] 134/500, 4.9 task/s, elapsed: 27s, ETA:    75s[>>>>>>>>                      ] 135/500, 4.9 task/s, elapsed: 27s, ETA:    74s[>>>>>>>>                      ] 136/500, 5.0 task/s, elapsed: 27s, ETA:    73s[>>>>>>>>                      ] 137/500, 4.9 task/s, elapsed: 28s, ETA:    74s[>>>>>>>>                      ] 138/500, 4.9 task/s, elapsed: 28s, ETA:    73s[>>>>>>>>                      ] 139/500, 5.0 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 140/500, 5.0 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 141/500, 5.0 task/s, elapsed: 28s, ETA:    72s[>>>>>>>>                      ] 142/500, 5.0 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 143/500, 5.0 task/s, elapsed: 28s, ETA:    71s[>>>>>>>>                      ] 144/500, 5.1 task/s, elapsed: 28s, ETA:    70s[>>>>>>>>                      ] 145/500, 5.0 task/s, elapsed: 29s, ETA:    71s[>>>>>>>>                      ] 146/500, 5.1 task/s, elapsed: 29s, ETA:    70s[>>>>>>>>                      ] 147/500, 5.1 task/s, elapsed: 29s, ETA:    69s[>>>>>>>>                      ] 148/500, 5.1 task/s, elapsed: 29s, ETA:    69s[>>>>>>>>                      ] 149/500, 5.1 task/s, elapsed: 29s, ETA:    69s[>>>>>>>>>                     ] 150/500, 5.1 task/s, elapsed: 29s, ETA:    69s[>>>>>>>>>                     ] 151/500, 5.1 task/s, elapsed: 29s, ETA:    68s[>>>>>>>>>                     ] 152/500, 5.2 task/s, elapsed: 29s, ETA:    67s[>>>>>>>>>                     ] 153/500, 5.1 task/s, elapsed: 30s, ETA:    68s[>>>>>>>>>                     ] 154/500, 5.2 task/s, elapsed: 30s, ETA:    67s[>>>>>>>>>                     ] 155/500, 5.2 task/s, elapsed: 30s, ETA:    66s[>>>>>>>>>                     ] 156/500, 5.2 task/s, elapsed: 30s, ETA:    66s[>>>>>>>>>                     ] 157/500, 5.2 task/s, elapsed: 30s, ETA:    66s[>>>>>>>>>                     ] 158/500, 5.2 task/s, elapsed: 30s, ETA:    66s[>>>>>>>>>                     ] 159/500, 5.2 task/s, elapsed: 30s, ETA:    65s[>>>>>>>>>                     ] 160/500, 5.3 task/s, elapsed: 30s, ETA:    65s[>>>>>>>>>                     ] 161/500, 5.2 task/s, elapsed: 31s, ETA:    65s[>>>>>>>>>                     ] 162/500, 5.2 task/s, elapsed: 31s, ETA:    64s[>>>>>>>>>                     ] 163/500, 5.3 task/s, elapsed: 31s, ETA:    64s[>>>>>>>>>                     ] 164/500, 5.3 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>                     ] 165/500, 5.3 task/s, elapsed: 31s, ETA:    64s[>>>>>>>>>                     ] 166/500, 5.3 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>>                    ] 167/500, 5.3 task/s, elapsed: 31s, ETA:    63s[>>>>>>>>>>                    ] 168/500, 5.4 task/s, elapsed: 31s, ETA:    62s[>>>>>>>>>>                    ] 169/500, 5.3 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>>                    ] 170/500, 5.3 task/s, elapsed: 32s, ETA:    62s[>>>>>>>>>>                    ] 171/500, 5.4 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                    ] 172/500, 5.4 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                    ] 173/500, 5.3 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                    ] 174/500, 5.4 task/s, elapsed: 32s, ETA:    61s[>>>>>>>>>>                    ] 175/500, 5.4 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                    ] 176/500, 5.4 task/s, elapsed: 32s, ETA:    60s[>>>>>>>>>>                    ] 177/500, 5.4 task/s, elapsed: 33s, ETA:    60s[>>>>>>>>>>                    ] 178/500, 5.4 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                    ] 179/500, 5.4 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                    ] 180/500, 5.5 task/s, elapsed: 33s, ETA:    58s[>>>>>>>>>>                    ] 181/500, 5.4 task/s, elapsed: 33s, ETA:    59s[>>>>>>>>>>                    ] 182/500, 5.5 task/s, elapsed: 33s, ETA:    58s[>>>>>>>>>>                    ] 183/500, 5.5 task/s, elapsed: 33s, ETA:    58s[>>>>>>>>>>>                   ] 184/500, 5.5 task/s, elapsed: 33s, ETA:    57s[>>>>>>>>>>>                   ] 185/500, 5.5 task/s, elapsed: 34s, ETA:    58s[>>>>>>>>>>>                   ] 186/500, 5.5 task/s, elapsed: 34s, ETA:    57s[>>>>>>>>>>>                   ] 187/500, 5.5 task/s, elapsed: 34s, ETA:    57s[>>>>>>>>>>>                   ] 188/500, 5.5 task/s, elapsed: 34s, ETA:    56s[>>>>>>>>>>>                   ] 189/500, 5.5 task/s, elapsed: 34s, ETA:    57s[>>>>>>>>>>>                   ] 190/500, 5.5 task/s, elapsed: 34s, ETA:    56s[>>>>>>>>>>>                   ] 191/500, 5.6 task/s, elapsed: 34s, ETA:    56s[>>>>>>>>>>>                   ] 192/500, 5.6 task/s, elapsed: 34s, ETA:    55s[>>>>>>>>>>>                   ] 193/500, 5.5 task/s, elapsed: 35s, ETA:    55s[>>>>>>>>>>>                   ] 194/500, 5.6 task/s, elapsed: 35s, ETA:    55s[>>>>>>>>>>>                   ] 195/500, 5.6 task/s, elapsed: 35s, ETA:    55s[>>>>>>>>>>>                   ] 196/500, 5.6 task/s, elapsed: 35s, ETA:    54s[>>>>>>>>>>>                   ] 197/500, 5.6 task/s, elapsed: 35s, ETA:    54s[>>>>>>>>>>>                   ] 198/500, 5.6 task/s, elapsed: 35s, ETA:    54s[>>>>>>>>>>>                   ] 199/500, 5.6 task/s, elapsed: 35s, ETA:    53s[>>>>>>>>>>>>                  ] 200/500, 5.7 task/s, elapsed: 35s, ETA:    53s[>>>>>>>>>>>>                  ] 201/500, 5.6 task/s, elapsed: 36s, ETA:    53s[>>>>>>>>>>>>                  ] 202/500, 5.6 task/s, elapsed: 36s, ETA:    53s[>>>>>>>>>>>>                  ] 203/500, 5.7 task/s, elapsed: 36s, ETA:    52s[>>>>>>>>>>>>                  ] 204/500, 5.7 task/s, elapsed: 36s, ETA:    52s[>>>>>>>>>>>>                  ] 205/500, 5.6 task/s, elapsed: 36s, ETA:    52s[>>>>>>>>>>>>                  ] 206/500, 5.7 task/s, elapsed: 36s, ETA:    52s[>>>>>>>>>>>>                  ] 207/500, 5.7 task/s, elapsed: 36s, ETA:    51s[>>>>>>>>>>>>                  ] 208/500, 5.7 task/s, elapsed: 36s, ETA:    51s[>>>>>>>>>>>>                  ] 209/500, 5.7 task/s, elapsed: 37s, ETA:    51s[>>>>>>>>>>>>                  ] 210/500, 5.7 task/s, elapsed: 37s, ETA:    51s[>>>>>>>>>>>>                  ] 211/500, 5.7 task/s, elapsed: 37s, ETA:    51s[>>>>>>>>>>>>                  ] 212/500, 5.7 task/s, elapsed: 37s, ETA:    50s[>>>>>>>>>>>>                  ] 213/500, 5.7 task/s, elapsed: 37s, ETA:    50s[>>>>>>>>>>>>                  ] 214/500, 5.7 task/s, elapsed: 37s, ETA:    50s[>>>>>>>>>>>>                  ] 215/500, 5.7 task/s, elapsed: 37s, ETA:    50s[>>>>>>>>>>>>                  ] 216/500, 5.8 task/s, elapsed: 37s, ETA:    49s[>>>>>>>>>>>>>                 ] 217/500, 5.7 task/s, elapsed: 38s, ETA:    49s[>>>>>>>>>>>>>                 ] 218/500, 5.8 task/s, elapsed: 38s, ETA:    49s[>>>>>>>>>>>>>                 ] 219/500, 5.8 task/s, elapsed: 38s, ETA:    49s[>>>>>>>>>>>>>                 ] 220/500, 5.8 task/s, elapsed: 38s, ETA:    48s[>>>>>>>>>>>>>                 ] 221/500, 5.8 task/s, elapsed: 38s, ETA:    48s[>>>>>>>>>>>>>                 ] 222/500, 5.8 task/s, elapsed: 38s, ETA:    48s[>>>>>>>>>>>>>                 ] 223/500, 5.8 task/s, elapsed: 38s, ETA:    48s[>>>>>>>>>>>>>                 ] 224/500, 5.8 task/s, elapsed: 38s, ETA:    47s[>>>>>>>>>>>>>                 ] 225/500, 5.8 task/s, elapsed: 39s, ETA:    48s[>>>>>>>>>>>>>                 ] 226/500, 5.8 task/s, elapsed: 39s, ETA:    47s[>>>>>>>>>>>>>                 ] 227/500, 5.8 task/s, elapsed: 39s, ETA:    47s[>>>>>>>>>>>>>                 ] 228/500, 5.9 task/s, elapsed: 39s, ETA:    46s[>>>>>>>>>>>>>                 ] 229/500, 5.8 task/s, elapsed: 39s, ETA:    47s[>>>>>>>>>>>>>                 ] 230/500, 5.8 task/s, elapsed: 39s, ETA:    46s[>>>>>>>>>>>>>                 ] 231/500, 5.9 task/s, elapsed: 39s, ETA:    46s[>>>>>>>>>>>>>                 ] 232/500, 5.9 task/s, elapsed: 39s, ETA:    45s[>>>>>>>>>>>>>                 ] 233/500, 5.8 task/s, elapsed: 40s, ETA:    46s[>>>>>>>>>>>>>>                ] 234/500, 5.9 task/s, elapsed: 40s, ETA:    45s[>>>>>>>>>>>>>>                ] 235/500, 5.9 task/s, elapsed: 40s, ETA:    45s[>>>>>>>>>>>>>>                ] 236/500, 5.9 task/s, elapsed: 40s, ETA:    45s[>>>>>>>>>>>>>>                ] 237/500, 5.9 task/s, elapsed: 40s, ETA:    45s[>>>>>>>>>>>>>>                ] 238/500, 5.9 task/s, elapsed: 40s, ETA:    44s[>>>>>>>>>>>>>>                ] 239/500, 5.9 task/s, elapsed: 40s, ETA:    44s[>>>>>>>>>>>>>>                ] 240/500, 5.9 task/s, elapsed: 40s, ETA:    44s[>>>>>>>>>>>>>>                ] 241/500, 5.9 task/s, elapsed: 41s, ETA:    44s[>>>>>>>>>>>>>>                ] 242/500, 5.9 task/s, elapsed: 41s, ETA:    44s[>>>>>>>>>>>>>>                ] 243/500, 5.9 task/s, elapsed: 41s, ETA:    43s[>>>>>>>>>>>>>>                ] 244/500, 6.0 task/s, elapsed: 41s, ETA:    43s[>>>>>>>>>>>>>>                ] 245/500, 5.9 task/s, elapsed: 41s, ETA:    43s[>>>>>>>>>>>>>>                ] 246/500, 5.9 task/s, elapsed: 41s, ETA:    43s[>>>>>>>>>>>>>>                ] 247/500, 6.0 task/s, elapsed: 41s, ETA:    42s[>>>>>>>>>>>>>>                ] 248/500, 6.0 task/s, elapsed: 41s, ETA:    42s[>>>>>>>>>>>>>>                ] 249/500, 5.9 task/s, elapsed: 42s, ETA:    42s[>>>>>>>>>>>>>>>               ] 250/500, 6.0 task/s, elapsed: 42s, ETA:    42s[>>>>>>>>>>>>>>>               ] 251/500, 6.0 task/s, elapsed: 42s, ETA:    42s[>>>>>>>>>>>>>>>               ] 252/500, 6.0 task/s, elapsed: 42s, ETA:    41s[>>>>>>>>>>>>>>>               ] 253/500, 6.0 task/s, elapsed: 42s, ETA:    41s[>>>>>>>>>>>>>>>               ] 254/500, 6.0 task/s, elapsed: 42s, ETA:    41s[>>>>>>>>>>>>>>>               ] 255/500, 6.0 task/s, elapsed: 42s, ETA:    41s[>>>>>>>>>>>>>>>               ] 256/500, 6.0 task/s, elapsed: 42s, ETA:    40s[>>>>>>>>>>>>>>>               ] 257/500, 6.0 task/s, elapsed: 43s, ETA:    41s[>>>>>>>>>>>>>>>               ] 258/500, 6.0 task/s, elapsed: 43s, ETA:    40s[>>>>>>>>>>>>>>>               ] 259/500, 6.0 task/s, elapsed: 43s, ETA:    40s[>>>>>>>>>>>>>>>               ] 260/500, 6.0 task/s, elapsed: 43s, ETA:    40s[>>>>>>>>>>>>>>>               ] 261/500, 6.0 task/s, elapsed: 44s, ETA:    40s[>>>>>>>>>>>>>>>               ] 262/500, 6.0 task/s, elapsed: 44s, ETA:    40s[>>>>>>>>>>>>>>>               ] 263/500, 6.0 task/s, elapsed: 44s, ETA:    39s[>>>>>>>>>>>>>>>               ] 264/500, 6.1 task/s, elapsed: 44s, ETA:    39s[>>>>>>>>>>>>>>>               ] 265/500, 6.0 task/s, elapsed: 44s, ETA:    39s[>>>>>>>>>>>>>>>               ] 266/500, 6.0 task/s, elapsed: 44s, ETA:    39s[>>>>>>>>>>>>>>>>              ] 267/500, 6.1 task/s, elapsed: 44s, ETA:    38s[>>>>>>>>>>>>>>>>              ] 268/500, 6.1 task/s, elapsed: 44s, ETA:    38s[>>>>>>>>>>>>>>>>              ] 269/500, 6.0 task/s, elapsed: 45s, ETA:    38s[>>>>>>>>>>>>>>>>              ] 270/500, 6.1 task/s, elapsed: 45s, ETA:    38s[>>>>>>>>>>>>>>>>              ] 271/500, 6.1 task/s, elapsed: 45s, ETA:    38s[>>>>>>>>>>>>>>>>              ] 272/500, 6.1 task/s, elapsed: 45s, ETA:    37s[>>>>>>>>>>>>>>>>              ] 273/500, 6.0 task/s, elapsed: 45s, ETA:    38s[>>>>>>>>>>>>>>>>              ] 274/500, 6.1 task/s, elapsed: 45s, ETA:    37s[>>>>>>>>>>>>>>>>              ] 275/500, 6.1 task/s, elapsed: 45s, ETA:    37s[>>>>>>>>>>>>>>>>              ] 276/500, 6.1 task/s, elapsed: 45s, ETA:    37s[>>>>>>>>>>>>>>>>              ] 277/500, 6.1 task/s, elapsed: 46s, ETA:    37s[>>>>>>>>>>>>>>>>              ] 278/500, 6.1 task/s, elapsed: 46s, ETA:    36s[>>>>>>>>>>>>>>>>              ] 279/500, 6.1 task/s, elapsed: 46s, ETA:    36s[>>>>>>>>>>>>>>>>              ] 280/500, 6.1 task/s, elapsed: 46s, ETA:    36s[>>>>>>>>>>>>>>>>              ] 281/500, 6.1 task/s, elapsed: 46s, ETA:    36s[>>>>>>>>>>>>>>>>              ] 282/500, 6.1 task/s, elapsed: 46s, ETA:    36s[>>>>>>>>>>>>>>>>              ] 283/500, 6.1 task/s, elapsed: 46s, ETA:    35s[>>>>>>>>>>>>>>>>>             ] 284/500, 6.2 task/s, elapsed: 46s, ETA:    35s[>>>>>>>>>>>>>>>>>             ] 285/500, 6.1 task/s, elapsed: 47s, ETA:    35s[>>>>>>>>>>>>>>>>>             ] 286/500, 6.1 task/s, elapsed: 47s, ETA:    35s[>>>>>>>>>>>>>>>>>             ] 287/500, 6.2 task/s, elapsed: 47s, ETA:    35s[>>>>>>>>>>>>>>>>>             ] 288/500, 6.2 task/s, elapsed: 47s, ETA:    34s[>>>>>>>>>>>>>>>>>             ] 289/500, 6.1 task/s, elapsed: 47s, ETA:    34s[>>>>>>>>>>>>>>>>>             ] 290/500, 6.1 task/s, elapsed: 47s, ETA:    34s[>>>>>>>>>>>>>>>>>             ] 291/500, 6.2 task/s, elapsed: 47s, ETA:    34s[>>>>>>>>>>>>>>>>>             ] 292/500, 6.2 task/s, elapsed: 47s, ETA:    34s[>>>>>>>>>>>>>>>>>             ] 293/500, 6.1 task/s, elapsed: 48s, ETA:    34s[>>>>>>>>>>>>>>>>>             ] 294/500, 6.2 task/s, elapsed: 48s, ETA:    33s[>>>>>>>>>>>>>>>>>             ] 295/500, 6.2 task/s, elapsed: 48s, ETA:    33s[>>>>>>>>>>>>>>>>>             ] 296/500, 6.2 task/s, elapsed: 48s, ETA:    33s[>>>>>>>>>>>>>>>>>             ] 297/500, 6.2 task/s, elapsed: 48s, ETA:    33s[>>>>>>>>>>>>>>>>>             ] 298/500, 6.2 task/s, elapsed: 48s, ETA:    33s[>>>>>>>>>>>>>>>>>             ] 299/500, 6.2 task/s, elapsed: 48s, ETA:    32s[>>>>>>>>>>>>>>>>>>            ] 300/500, 6.2 task/s, elapsed: 48s, ETA:    32s[>>>>>>>>>>>>>>>>>>            ] 301/500, 6.2 task/s, elapsed: 49s, ETA:    32s[>>>>>>>>>>>>>>>>>>            ] 302/500, 6.2 task/s, elapsed: 49s, ETA:    32s[>>>>>>>>>>>>>>>>>>            ] 303/500, 6.2 task/s, elapsed: 49s, ETA:    32s[>>>>>>>>>>>>>>>>>>            ] 304/500, 6.2 task/s, elapsed: 49s, ETA:    31s[>>>>>>>>>>>>>>>>>>            ] 305/500, 6.2 task/s, elapsed: 49s, ETA:    31s[>>>>>>>>>>>>>>>>>>            ] 306/500, 6.2 task/s, elapsed: 49s, ETA:    31s[>>>>>>>>>>>>>>>>>>            ] 307/500, 6.2 task/s, elapsed: 49s, ETA:    31s[>>>>>>>>>>>>>>>>>>            ] 308/500, 6.3 task/s, elapsed: 49s, ETA:    31s[>>>>>>>>>>>>>>>>>>            ] 309/500, 6.2 task/s, elapsed: 50s, ETA:    31s[>>>>>>>>>>>>>>>>>>            ] 310/500, 6.2 task/s, elapsed: 50s, ETA:    30s[>>>>>>>>>>>>>>>>>>            ] 311/500, 6.3 task/s, elapsed: 50s, ETA:    30s[>>>>>>>>>>>>>>>>>>            ] 312/500, 6.3 task/s, elapsed: 50s, ETA:    30s[>>>>>>>>>>>>>>>>>>            ] 313/500, 6.2 task/s, elapsed: 50s, ETA:    30s[>>>>>>>>>>>>>>>>>>            ] 314/500, 6.3 task/s, elapsed: 50s, ETA:    30s[>>>>>>>>>>>>>>>>>>            ] 315/500, 6.3 task/s, elapsed: 50s, ETA:    29s[>>>>>>>>>>>>>>>>>>            ] 316/500, 6.3 task/s, elapsed: 50s, ETA:    29s[>>>>>>>>>>>>>>>>>>>           ] 317/500, 6.3 task/s, elapsed: 51s, ETA:    29s[>>>>>>>>>>>>>>>>>>>           ] 318/500, 6.3 task/s, elapsed: 51s, ETA:    29s[>>>>>>>>>>>>>>>>>>>           ] 319/500, 6.3 task/s, elapsed: 51s, ETA:    29s[>>>>>>>>>>>>>>>>>>>           ] 320/500, 6.3 task/s, elapsed: 51s, ETA:    28s[>>>>>>>>>>>>>>>>>>>           ] 321/500, 6.3 task/s, elapsed: 51s, ETA:    28s[>>>>>>>>>>>>>>>>>>>           ] 322/500, 6.3 task/s, elapsed: 51s, ETA:    28s[>>>>>>>>>>>>>>>>>>>           ] 323/500, 6.3 task/s, elapsed: 51s, ETA:    28s[>>>>>>>>>>>>>>>>>>>           ] 324/500, 6.3 task/s, elapsed: 51s, ETA:    28s[>>>>>>>>>>>>>>>>>>>           ] 325/500, 6.3 task/s, elapsed: 52s, ETA:    28s[>>>>>>>>>>>>>>>>>>>           ] 326/500, 6.3 task/s, elapsed: 52s, ETA:    28s[>>>>>>>>>>>>>>>>>>>           ] 327/500, 6.3 task/s, elapsed: 52s, ETA:    27s[>>>>>>>>>>>>>>>>>>>           ] 328/500, 6.4 task/s, elapsed: 52s, ETA:    27s[>>>>>>>>>>>>>>>>>>>           ] 329/500, 6.3 task/s, elapsed: 52s, ETA:    27s[>>>>>>>>>>>>>>>>>>>           ] 330/500, 6.3 task/s, elapsed: 52s, ETA:    27s[>>>>>>>>>>>>>>>>>>>           ] 331/500, 6.4 task/s, elapsed: 52s, ETA:    27s[>>>>>>>>>>>>>>>>>>>           ] 332/500, 6.4 task/s, elapsed: 52s, ETA:    26s[>>>>>>>>>>>>>>>>>>>           ] 333/500, 6.3 task/s, elapsed: 53s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>          ] 334/500, 6.4 task/s, elapsed: 53s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>          ] 335/500, 6.4 task/s, elapsed: 53s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>          ] 336/500, 6.4 task/s, elapsed: 53s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>          ] 337/500, 6.3 task/s, elapsed: 53s, ETA:    26s[>>>>>>>>>>>>>>>>>>>>          ] 338/500, 6.4 task/s, elapsed: 53s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>          ] 339/500, 6.4 task/s, elapsed: 53s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>          ] 340/500, 6.4 task/s, elapsed: 53s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>          ] 341/500, 6.4 task/s, elapsed: 54s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>          ] 342/500, 6.4 task/s, elapsed: 54s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>          ] 343/500, 6.4 task/s, elapsed: 54s, ETA:    25s[>>>>>>>>>>>>>>>>>>>>          ] 344/500, 6.4 task/s, elapsed: 54s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>          ] 345/500, 6.4 task/s, elapsed: 54s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>          ] 346/500, 6.4 task/s, elapsed: 54s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>          ] 347/500, 6.4 task/s, elapsed: 54s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>          ] 348/500, 6.4 task/s, elapsed: 54s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>          ] 349/500, 6.4 task/s, elapsed: 55s, ETA:    24s[>>>>>>>>>>>>>>>>>>>>>         ] 350/500, 6.4 task/s, elapsed: 55s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>         ] 351/500, 6.4 task/s, elapsed: 55s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>         ] 352/500, 6.4 task/s, elapsed: 55s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>         ] 353/500, 6.4 task/s, elapsed: 55s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>         ] 354/500, 6.4 task/s, elapsed: 55s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>         ] 355/500, 6.4 task/s, elapsed: 55s, ETA:    23s[>>>>>>>>>>>>>>>>>>>>>         ] 356/500, 6.5 task/s, elapsed: 55s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>         ] 357/500, 6.4 task/s, elapsed: 56s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>         ] 358/500, 6.4 task/s, elapsed: 56s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>         ] 359/500, 6.5 task/s, elapsed: 56s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>         ] 360/500, 6.5 task/s, elapsed: 56s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>         ] 361/500, 6.4 task/s, elapsed: 56s, ETA:    22s[>>>>>>>>>>>>>>>>>>>>>         ] 362/500, 6.5 task/s, elapsed: 56s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>         ] 363/500, 6.5 task/s, elapsed: 56s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>         ] 364/500, 6.5 task/s, elapsed: 56s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>         ] 365/500, 6.4 task/s, elapsed: 57s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>         ] 366/500, 6.5 task/s, elapsed: 57s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>        ] 367/500, 6.5 task/s, elapsed: 57s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>>>        ] 368/500, 6.5 task/s, elapsed: 57s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>        ] 369/500, 6.5 task/s, elapsed: 57s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>        ] 370/500, 6.5 task/s, elapsed: 57s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>        ] 371/500, 6.5 task/s, elapsed: 57s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>        ] 372/500, 6.5 task/s, elapsed: 57s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>        ] 373/500, 6.5 task/s, elapsed: 58s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>>>        ] 374/500, 6.5 task/s, elapsed: 58s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>        ] 375/500, 6.5 task/s, elapsed: 58s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>        ] 376/500, 6.5 task/s, elapsed: 58s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>        ] 377/500, 6.5 task/s, elapsed: 58s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>        ] 378/500, 6.5 task/s, elapsed: 58s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>        ] 379/500, 6.5 task/s, elapsed: 58s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>>        ] 380/500, 6.5 task/s, elapsed: 58s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>        ] 381/500, 6.5 task/s, elapsed: 59s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>        ] 382/500, 6.5 task/s, elapsed: 59s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>        ] 383/500, 6.5 task/s, elapsed: 59s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>       ] 384/500, 6.6 task/s, elapsed: 59s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>       ] 385/500, 6.5 task/s, elapsed: 59s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>>>       ] 386/500, 6.5 task/s, elapsed: 59s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>       ] 387/500, 6.5 task/s, elapsed: 59s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>       ] 388/500, 6.6 task/s, elapsed: 59s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>       ] 389/500, 6.5 task/s, elapsed: 60s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>       ] 390/500, 6.5 task/s, elapsed: 60s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>       ] 391/500, 6.6 task/s, elapsed: 60s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>>       ] 392/500, 6.6 task/s, elapsed: 60s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>       ] 393/500, 6.5 task/s, elapsed: 60s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>       ] 394/500, 6.6 task/s, elapsed: 60s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>       ] 395/500, 6.6 task/s, elapsed: 60s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>       ] 396/500, 6.6 task/s, elapsed: 60s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>       ] 397/500, 6.5 task/s, elapsed: 61s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>       ] 398/500, 6.6 task/s, elapsed: 61s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>>       ] 399/500, 6.6 task/s, elapsed: 61s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 400/500, 6.6 task/s, elapsed: 61s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 401/500, 6.6 task/s, elapsed: 61s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 402/500, 6.6 task/s, elapsed: 61s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 403/500, 6.6 task/s, elapsed: 61s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 404/500, 6.6 task/s, elapsed: 61s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 405/500, 6.6 task/s, elapsed: 62s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 406/500, 6.6 task/s, elapsed: 62s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 407/500, 6.6 task/s, elapsed: 62s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 408/500, 6.6 task/s, elapsed: 62s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 409/500, 6.6 task/s, elapsed: 62s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 410/500, 6.6 task/s, elapsed: 62s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 411/500, 6.6 task/s, elapsed: 62s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 412/500, 6.6 task/s, elapsed: 62s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 413/500, 6.6 task/s, elapsed: 63s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 414/500, 6.6 task/s, elapsed: 63s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 415/500, 6.6 task/s, elapsed: 63s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 416/500, 6.6 task/s, elapsed: 63s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 417/500, 6.6 task/s, elapsed: 63s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 418/500, 6.6 task/s, elapsed: 63s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 419/500, 6.6 task/s, elapsed: 63s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 420/500, 6.7 task/s, elapsed: 63s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 421/500, 6.6 task/s, elapsed: 64s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 422/500, 6.6 task/s, elapsed: 64s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 423/500, 6.7 task/s, elapsed: 64s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 424/500, 6.7 task/s, elapsed: 64s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 425/500, 6.6 task/s, elapsed: 64s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 426/500, 6.6 task/s, elapsed: 64s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 427/500, 6.7 task/s, elapsed: 64s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 428/500, 6.7 task/s, elapsed: 64s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 429/500, 6.6 task/s, elapsed: 65s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 430/500, 6.7 task/s, elapsed: 65s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 431/500, 6.7 task/s, elapsed: 65s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 432/500, 6.7 task/s, elapsed: 65s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 433/500, 6.7 task/s, elapsed: 65s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 434/500, 6.7 task/s, elapsed: 65s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 435/500, 6.7 task/s, elapsed: 65s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 436/500, 6.7 task/s, elapsed: 65s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 437/500, 6.7 task/s, elapsed: 66s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 438/500, 6.7 task/s, elapsed: 66s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 439/500, 6.7 task/s, elapsed: 66s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 440/500, 6.7 task/s, elapsed: 66s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 441/500, 6.7 task/s, elapsed: 66s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 442/500, 6.7 task/s, elapsed: 66s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 443/500, 6.7 task/s, elapsed: 66s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 444/500, 6.7 task/s, elapsed: 66s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 445/500, 6.7 task/s, elapsed: 67s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 446/500, 6.7 task/s, elapsed: 67s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 447/500, 6.7 task/s, elapsed: 67s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 448/500, 6.7 task/s, elapsed: 67s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 449/500, 6.7 task/s, elapsed: 67s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 450/500, 6.7 task/s, elapsed: 67s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 451/500, 6.7 task/s, elapsed: 67s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 452/500, 6.7 task/s, elapsed: 67s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 453/500, 6.7 task/s, elapsed: 68s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 454/500, 6.7 task/s, elapsed: 68s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 455/500, 6.7 task/s, elapsed: 68s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 456/500, 6.8 task/s, elapsed: 68s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 457/500, 6.7 task/s, elapsed: 68s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 458/500, 6.7 task/s, elapsed: 68s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 459/500, 6.7 task/s, elapsed: 68s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 460/500, 6.8 task/s, elapsed: 68s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 461/500, 6.7 task/s, elapsed: 69s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 462/500, 6.7 task/s, elapsed: 69s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 463/500, 6.8 task/s, elapsed: 69s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 464/500, 6.8 task/s, elapsed: 69s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 465/500, 6.7 task/s, elapsed: 69s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 466/500, 6.8 task/s, elapsed: 69s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 467/500, 6.8 task/s, elapsed: 69s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 468/500, 6.8 task/s, elapsed: 69s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 469/500, 6.7 task/s, elapsed: 70s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 470/500, 6.8 task/s, elapsed: 70s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 471/500, 6.8 task/s, elapsed: 70s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 472/500, 6.8 task/s, elapsed: 70s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 473/500, 6.8 task/s, elapsed: 70s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 474/500, 6.8 task/s, elapsed: 70s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 475/500, 6.8 task/s, elapsed: 70s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 476/500, 6.8 task/s, elapsed: 70s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 477/500, 6.8 task/s, elapsed: 71s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 478/500, 6.8 task/s, elapsed: 71s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 479/500, 6.8 task/s, elapsed: 71s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 480/500, 6.8 task/s, elapsed: 71s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 481/500, 6.8 task/s, elapsed: 71s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 482/500, 6.8 task/s, elapsed: 71s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 483/500, 6.8 task/s, elapsed: 71s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 484/500, 6.8 task/s, elapsed: 71s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 485/500, 6.8 task/s, elapsed: 72s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 486/500, 6.8 task/s, elapsed: 72s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 487/500, 6.8 task/s, elapsed: 72s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 488/500, 6.8 task/s, elapsed: 72s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 489/500, 6.8 task/s, elapsed: 72s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 490/500, 6.8 task/s, elapsed: 72s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 491/500, 6.8 task/s, elapsed: 72s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 492/500, 6.8 task/s, elapsed: 72s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 493/500, 6.8 task/s, elapsed: 73s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 494/500, 6.8 task/s, elapsed: 73s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 495/500, 6.8 task/s, elapsed: 73s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 496/500, 6.8 task/s, elapsed: 73s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 497/500, 6.8 task/s, elapsed: 73s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 498/500, 6.8 task/s, elapsed: 73s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 499/500, 6.8 task/s, elapsed: 73s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 500/500, 6.8 task/s, elapsed: 73s, ETA:     0s

2022-03-23 16:59:24,430 - mmseg - INFO - per class results:
2022-03-23 16:59:24,432 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 97.75 | 98.61 |
|    sidewalk   | 83.24 | 91.65 |
|    building   | 91.88 | 96.17 |
|      wall     | 42.68 | 46.62 |
|     fence     | 56.76 | 66.28 |
|      pole     | 62.77 | 74.21 |
| traffic light | 68.49 | 82.55 |
|  traffic sign | 77.06 | 84.83 |
|   vegetation  |  91.7 | 97.12 |
|    terrain    | 62.02 | 68.36 |
|      sky      | 94.02 | 97.66 |
|     person    | 81.39 | 91.22 |
|     rider     | 62.09 | 78.19 |
|      car      | 94.79 | 97.59 |
|     truck     | 80.73 | 91.42 |
|      bus      | 88.84 | 93.63 |
|     train     | 77.87 | 85.55 |
|   motorcycle  | 64.53 | 81.93 |
|    bicycle    | 75.65 | 87.02 |
+---------------+-------+-------+
2022-03-23 16:59:24,432 - mmseg - INFO - Summary:
2022-03-23 16:59:24,432 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.67 | 76.54 | 84.77 |
+-------+-------+-------+
2022-03-23 16:59:24,434 - mmseg - INFO - Exp name: pprp_deeplabv3_r50-d8_512x1024_40k_cityscapes.py
2022-03-23 16:59:24,434 - mmseg - INFO - Iter(val) [125]	aAcc: 0.9567, mIoU: 0.7654, mAcc: 0.8477, IoU.road: 0.9775, IoU.sidewalk: 0.8324, IoU.building: 0.9188, IoU.wall: 0.4268, IoU.fence: 0.5676, IoU.pole: 0.6277, IoU.traffic light: 0.6849, IoU.traffic sign: 0.7706, IoU.vegetation: 0.9170, IoU.terrain: 0.6202, IoU.sky: 0.9402, IoU.person: 0.8139, IoU.rider: 0.6209, IoU.car: 0.9479, IoU.truck: 0.8073, IoU.bus: 0.8884, IoU.train: 0.7787, IoU.motorcycle: 0.6453, IoU.bicycle: 0.7565, Acc.road: 0.9861, Acc.sidewalk: 0.9165, Acc.building: 0.9617, Acc.wall: 0.4662, Acc.fence: 0.6628, Acc.pole: 0.7421, Acc.traffic light: 0.8255, Acc.traffic sign: 0.8483, Acc.vegetation: 0.9712, Acc.terrain: 0.6836, Acc.sky: 0.9766, Acc.person: 0.9122, Acc.rider: 0.7819, Acc.car: 0.9759, Acc.truck: 0.9142, Acc.bus: 0.9363, Acc.train: 0.8555, Acc.motorcycle: 0.8193, Acc.bicycle: 0.8702
2022-03-23 17:00:13,712 - mmseg - INFO - Iter [40050/50000]	lr: 2.415e-03, eta: 1 day, 16:29:41, time: 2.450, data_time: 1.471, memory: 19929, decode.loss_ce: 0.1361, decode.acc_seg: 94.9106, aux.loss_ce: 0.0782, aux.acc_seg: 93.2546, loss: 0.2144
2022-03-23 17:01:03,224 - mmseg - INFO - Iter [40100/50000]	lr: 2.405e-03, eta: 21:41:35, time: 0.990, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1383, decode.acc_seg: 94.8579, aux.loss_ce: 0.0799, aux.acc_seg: 93.1502, loss: 0.2182
2022-03-23 17:01:52,633 - mmseg - INFO - Iter [40150/50000]	lr: 2.395e-03, eta: 15:19:55, time: 0.988, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1428, decode.acc_seg: 94.6958, aux.loss_ce: 0.0806, aux.acc_seg: 92.9190, loss: 0.2234
2022-03-23 17:02:42,012 - mmseg - INFO - Iter [40200/50000]	lr: 2.384e-03, eta: 12:07:42, time: 0.988, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1516, decode.acc_seg: 94.4317, aux.loss_ce: 0.0867, aux.acc_seg: 92.4878, loss: 0.2383
2022-03-23 17:03:31,447 - mmseg - INFO - Iter [40250/50000]	lr: 2.374e-03, eta: 10:11:46, time: 0.989, data_time: 0.006, memory: 19929, decode.loss_ce: 0.1653, decode.acc_seg: 94.0656, aux.loss_ce: 0.0950, aux.acc_seg: 92.0995, loss: 0.2603
2022-03-23 17:04:20,852 - mmseg - INFO - Iter [40300/50000]	lr: 2.363e-03, eta: 8:54:04, time: 0.988, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1475, decode.acc_seg: 94.4934, aux.loss_ce: 0.0852, aux.acc_seg: 92.6950, loss: 0.2326
2022-03-23 17:05:10,106 - mmseg - INFO - Iter [40350/50000]	lr: 2.353e-03, eta: 7:58:11, time: 0.985, data_time: 0.006, memory: 19929, decode.loss_ce: 0.1489, decode.acc_seg: 94.6966, aux.loss_ce: 0.0849, aux.acc_seg: 92.8904, loss: 0.2339
2022-03-23 17:06:01,830 - mmseg - INFO - Iter [40400/50000]	lr: 2.342e-03, eta: 7:17:02, time: 1.035, data_time: 0.053, memory: 19929, decode.loss_ce: 0.1364, decode.acc_seg: 94.9759, aux.loss_ce: 0.0760, aux.acc_seg: 93.4017, loss: 0.2124
2022-03-23 17:06:51,166 - mmseg - INFO - Iter [40450/50000]	lr: 2.332e-03, eta: 6:43:58, time: 0.987, data_time: 0.006, memory: 19929, decode.loss_ce: 0.1447, decode.acc_seg: 94.6502, aux.loss_ce: 0.0794, aux.acc_seg: 93.1146, loss: 0.2242
2022-03-23 17:07:40,511 - mmseg - INFO - Iter [40500/50000]	lr: 2.321e-03, eta: 6:17:20, time: 0.987, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1453, decode.acc_seg: 94.7326, aux.loss_ce: 0.0806, aux.acc_seg: 93.2195, loss: 0.2259
2022-03-23 17:08:29,925 - mmseg - INFO - Iter [40550/50000]	lr: 2.311e-03, eta: 5:55:25, time: 0.988, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1487, decode.acc_seg: 94.5213, aux.loss_ce: 0.0879, aux.acc_seg: 92.5059, loss: 0.2365
2022-03-23 17:09:19,289 - mmseg - INFO - Iter [40600/50000]	lr: 2.300e-03, eta: 5:36:59, time: 0.987, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1523, decode.acc_seg: 94.4622, aux.loss_ce: 0.0848, aux.acc_seg: 92.7377, loss: 0.2371
2022-03-23 17:10:08,726 - mmseg - INFO - Iter [40650/50000]	lr: 2.289e-03, eta: 5:21:17, time: 0.989, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1509, decode.acc_seg: 94.3262, aux.loss_ce: 0.0883, aux.acc_seg: 92.3165, loss: 0.2393
2022-03-23 17:10:58,532 - mmseg - INFO - Iter [40700/50000]	lr: 2.279e-03, eta: 5:07:47, time: 0.996, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1529, decode.acc_seg: 94.4516, aux.loss_ce: 0.0894, aux.acc_seg: 92.4790, loss: 0.2423
2022-03-23 17:11:50,315 - mmseg - INFO - Iter [40750/50000]	lr: 2.268e-03, eta: 4:56:23, time: 1.036, data_time: 0.055, memory: 19929, decode.loss_ce: 0.1491, decode.acc_seg: 94.5299, aux.loss_ce: 0.0876, aux.acc_seg: 92.4966, loss: 0.2366
2022-03-23 17:12:39,651 - mmseg - INFO - Iter [40800/50000]	lr: 2.258e-03, eta: 4:45:49, time: 0.987, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1455, decode.acc_seg: 94.5980, aux.loss_ce: 0.0833, aux.acc_seg: 92.6649, loss: 0.2288
2022-03-23 17:13:29,040 - mmseg - INFO - Iter [40850/50000]	lr: 2.247e-03, eta: 4:36:25, time: 0.988, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1557, decode.acc_seg: 94.2194, aux.loss_ce: 0.0905, aux.acc_seg: 92.0642, loss: 0.2462
2022-03-23 17:14:18,617 - mmseg - INFO - Iter [40900/50000]	lr: 2.237e-03, eta: 4:28:00, time: 0.991, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1615, decode.acc_seg: 94.0588, aux.loss_ce: 0.0917, aux.acc_seg: 92.1071, loss: 0.2532
2022-03-23 17:15:08,211 - mmseg - INFO - Iter [40950/50000]	lr: 2.226e-03, eta: 4:20:22, time: 0.992, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1438, decode.acc_seg: 94.6768, aux.loss_ce: 0.0798, aux.acc_seg: 93.0615, loss: 0.2236
2022-03-23 17:15:57,788 - mmseg - INFO - Exp name: pprp_deeplabv3_r50-d8_512x1024_40k_cityscapes.py
2022-03-23 17:15:57,789 - mmseg - INFO - Iter [41000/50000]	lr: 2.216e-03, eta: 4:13:26, time: 0.992, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1744, decode.acc_seg: 93.6650, aux.loss_ce: 0.0946, aux.acc_seg: 91.8174, loss: 0.2690
2022-03-23 17:16:47,121 - mmseg - INFO - Iter [41050/50000]	lr: 2.205e-03, eta: 4:07:02, time: 0.987, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1572, decode.acc_seg: 94.2664, aux.loss_ce: 0.0861, aux.acc_seg: 92.6833, loss: 0.2434
2022-03-23 17:17:36,588 - mmseg - INFO - Iter [41100/50000]	lr: 2.194e-03, eta: 4:01:10, time: 0.989, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1449, decode.acc_seg: 94.6843, aux.loss_ce: 0.0785, aux.acc_seg: 93.2923, loss: 0.2234
2022-03-23 17:18:28,090 - mmseg - INFO - Iter [41150/50000]	lr: 2.184e-03, eta: 3:55:59, time: 1.030, data_time: 0.052, memory: 19929, decode.loss_ce: 0.1375, decode.acc_seg: 94.9915, aux.loss_ce: 0.0795, aux.acc_seg: 93.2677, loss: 0.2170
2022-03-23 17:19:17,444 - mmseg - INFO - Iter [41200/50000]	lr: 2.173e-03, eta: 3:50:55, time: 0.987, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1456, decode.acc_seg: 94.7365, aux.loss_ce: 0.0846, aux.acc_seg: 92.7782, loss: 0.2302
2022-03-23 17:20:06,920 - mmseg - INFO - Iter [41250/50000]	lr: 2.163e-03, eta: 3:46:12, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1373, decode.acc_seg: 94.9499, aux.loss_ce: 0.0798, aux.acc_seg: 93.2592, loss: 0.2171
2022-03-23 17:20:56,383 - mmseg - INFO - Iter [41300/50000]	lr: 2.152e-03, eta: 3:41:46, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1461, decode.acc_seg: 94.6134, aux.loss_ce: 0.0829, aux.acc_seg: 92.7293, loss: 0.2290
2022-03-23 17:21:45,840 - mmseg - INFO - Iter [41350/50000]	lr: 2.141e-03, eta: 3:37:37, time: 0.989, data_time: 0.009, memory: 19929, decode.loss_ce: 0.1459, decode.acc_seg: 94.6468, aux.loss_ce: 0.0816, aux.acc_seg: 92.9421, loss: 0.2274
2022-03-23 17:22:35,310 - mmseg - INFO - Iter [41400/50000]	lr: 2.131e-03, eta: 3:33:42, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1464, decode.acc_seg: 94.5320, aux.loss_ce: 0.0803, aux.acc_seg: 92.9957, loss: 0.2268
2022-03-23 17:23:24,761 - mmseg - INFO - Iter [41450/50000]	lr: 2.120e-03, eta: 3:29:59, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1573, decode.acc_seg: 94.1352, aux.loss_ce: 0.0923, aux.acc_seg: 91.9889, loss: 0.2496
2022-03-23 17:24:16,666 - mmseg - INFO - Iter [41500/50000]	lr: 2.109e-03, eta: 3:26:42, time: 1.038, data_time: 0.055, memory: 19929, decode.loss_ce: 0.1492, decode.acc_seg: 94.6042, aux.loss_ce: 0.0848, aux.acc_seg: 92.8761, loss: 0.2340
2022-03-23 17:25:06,104 - mmseg - INFO - Iter [41550/50000]	lr: 2.099e-03, eta: 3:23:21, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1508, decode.acc_seg: 94.5060, aux.loss_ce: 0.0885, aux.acc_seg: 92.4647, loss: 0.2393
2022-03-23 17:25:55,622 - mmseg - INFO - Iter [41600/50000]	lr: 2.088e-03, eta: 3:20:10, time: 0.990, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1423, decode.acc_seg: 94.8010, aux.loss_ce: 0.0840, aux.acc_seg: 92.7974, loss: 0.2263
2022-03-23 17:26:45,128 - mmseg - INFO - Iter [41650/50000]	lr: 2.078e-03, eta: 3:17:07, time: 0.990, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1417, decode.acc_seg: 94.8999, aux.loss_ce: 0.0826, aux.acc_seg: 92.8267, loss: 0.2243
2022-03-23 17:27:34,590 - mmseg - INFO - Iter [41700/50000]	lr: 2.067e-03, eta: 3:14:12, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1500, decode.acc_seg: 94.4984, aux.loss_ce: 0.0850, aux.acc_seg: 92.6044, loss: 0.2350
2022-03-23 17:28:24,042 - mmseg - INFO - Iter [41750/50000]	lr: 2.056e-03, eta: 3:11:24, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1400, decode.acc_seg: 94.8333, aux.loss_ce: 0.0822, aux.acc_seg: 92.7771, loss: 0.2222
2022-03-23 17:29:13,483 - mmseg - INFO - Iter [41800/50000]	lr: 2.046e-03, eta: 3:08:43, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1490, decode.acc_seg: 94.5087, aux.loss_ce: 0.0862, aux.acc_seg: 92.5606, loss: 0.2352
2022-03-23 17:30:03,122 - mmseg - INFO - Iter [41850/50000]	lr: 2.035e-03, eta: 3:06:08, time: 0.993, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1443, decode.acc_seg: 94.6115, aux.loss_ce: 0.0847, aux.acc_seg: 92.5656, loss: 0.2290
2022-03-23 17:30:54,796 - mmseg - INFO - Iter [41900/50000]	lr: 2.024e-03, eta: 3:03:48, time: 1.033, data_time: 0.054, memory: 19929, decode.loss_ce: 0.1575, decode.acc_seg: 94.4163, aux.loss_ce: 0.0876, aux.acc_seg: 92.4990, loss: 0.2451
2022-03-23 17:31:44,247 - mmseg - INFO - Iter [41950/50000]	lr: 2.013e-03, eta: 3:01:23, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1657, decode.acc_seg: 93.9891, aux.loss_ce: 0.0914, aux.acc_seg: 92.1598, loss: 0.2572
2022-03-23 17:32:33,725 - mmseg - INFO - Exp name: pprp_deeplabv3_r50-d8_512x1024_40k_cityscapes.py
2022-03-23 17:32:33,725 - mmseg - INFO - Iter [42000/50000]	lr: 2.003e-03, eta: 2:59:03, time: 0.990, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1512, decode.acc_seg: 94.3154, aux.loss_ce: 0.0894, aux.acc_seg: 92.2189, loss: 0.2406
2022-03-23 17:33:23,159 - mmseg - INFO - Iter [42050/50000]	lr: 1.992e-03, eta: 2:56:47, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1467, decode.acc_seg: 94.6504, aux.loss_ce: 0.0806, aux.acc_seg: 93.0080, loss: 0.2273
2022-03-23 17:34:12,709 - mmseg - INFO - Iter [42100/50000]	lr: 1.981e-03, eta: 2:54:36, time: 0.991, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1388, decode.acc_seg: 94.9456, aux.loss_ce: 0.0816, aux.acc_seg: 93.1019, loss: 0.2204
2022-03-23 17:35:02,122 - mmseg - INFO - Iter [42150/50000]	lr: 1.971e-03, eta: 2:52:28, time: 0.988, data_time: 0.009, memory: 19929, decode.loss_ce: 0.1424, decode.acc_seg: 94.7058, aux.loss_ce: 0.0822, aux.acc_seg: 92.9235, loss: 0.2246
2022-03-23 17:35:51,702 - mmseg - INFO - Iter [42200/50000]	lr: 1.960e-03, eta: 2:50:24, time: 0.992, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1428, decode.acc_seg: 94.6259, aux.loss_ce: 0.0829, aux.acc_seg: 92.7321, loss: 0.2258
2022-03-23 17:36:43,486 - mmseg - INFO - Iter [42250/50000]	lr: 1.949e-03, eta: 2:48:31, time: 1.036, data_time: 0.054, memory: 19929, decode.loss_ce: 0.1440, decode.acc_seg: 94.6888, aux.loss_ce: 0.0832, aux.acc_seg: 92.9019, loss: 0.2272
2022-03-23 17:37:32,914 - mmseg - INFO - Iter [42300/50000]	lr: 1.938e-03, eta: 2:46:33, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1412, decode.acc_seg: 94.9411, aux.loss_ce: 0.0846, aux.acc_seg: 92.6734, loss: 0.2258
2022-03-23 17:38:22,516 - mmseg - INFO - Iter [42350/50000]	lr: 1.928e-03, eta: 2:44:38, time: 0.992, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1546, decode.acc_seg: 94.2876, aux.loss_ce: 0.0863, aux.acc_seg: 92.5767, loss: 0.2410
2022-03-23 17:39:11,994 - mmseg - INFO - Iter [42400/50000]	lr: 1.917e-03, eta: 2:42:46, time: 0.990, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1482, decode.acc_seg: 94.4895, aux.loss_ce: 0.0863, aux.acc_seg: 92.5682, loss: 0.2346
2022-03-23 17:40:01,381 - mmseg - INFO - Iter [42450/50000]	lr: 1.906e-03, eta: 2:40:56, time: 0.988, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1515, decode.acc_seg: 94.4597, aux.loss_ce: 0.0854, aux.acc_seg: 92.5547, loss: 0.2369
2022-03-23 17:40:50,861 - mmseg - INFO - Iter [42500/50000]	lr: 1.895e-03, eta: 2:39:09, time: 0.990, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1490, decode.acc_seg: 94.4990, aux.loss_ce: 0.0834, aux.acc_seg: 92.8337, loss: 0.2324
2022-03-23 17:41:40,285 - mmseg - INFO - Iter [42550/50000]	lr: 1.885e-03, eta: 2:37:23, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1431, decode.acc_seg: 94.6700, aux.loss_ce: 0.0809, aux.acc_seg: 92.9598, loss: 0.2239
2022-03-23 17:42:29,495 - mmseg - INFO - Iter [42600/50000]	lr: 1.874e-03, eta: 2:35:40, time: 0.984, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1413, decode.acc_seg: 94.8178, aux.loss_ce: 0.0803, aux.acc_seg: 93.1743, loss: 0.2216
2022-03-23 17:43:21,142 - mmseg - INFO - Iter [42650/50000]	lr: 1.863e-03, eta: 2:34:05, time: 1.033, data_time: 0.054, memory: 19929, decode.loss_ce: 0.1459, decode.acc_seg: 94.6576, aux.loss_ce: 0.0842, aux.acc_seg: 92.8047, loss: 0.2301
2022-03-23 17:44:10,602 - mmseg - INFO - Iter [42700/50000]	lr: 1.852e-03, eta: 2:32:26, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1448, decode.acc_seg: 94.6597, aux.loss_ce: 0.0857, aux.acc_seg: 92.5454, loss: 0.2305
2022-03-23 17:45:00,102 - mmseg - INFO - Iter [42750/50000]	lr: 1.841e-03, eta: 2:30:48, time: 0.990, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1408, decode.acc_seg: 94.7724, aux.loss_ce: 0.0799, aux.acc_seg: 93.1349, loss: 0.2207
2022-03-23 17:45:49,539 - mmseg - INFO - Iter [42800/50000]	lr: 1.831e-03, eta: 2:29:13, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1374, decode.acc_seg: 94.9846, aux.loss_ce: 0.0798, aux.acc_seg: 93.1798, loss: 0.2172
2022-03-23 17:46:38,923 - mmseg - INFO - Iter [42850/50000]	lr: 1.820e-03, eta: 2:27:38, time: 0.988, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1531, decode.acc_seg: 94.3055, aux.loss_ce: 0.0886, aux.acc_seg: 92.2670, loss: 0.2417
2022-03-23 17:47:28,490 - mmseg - INFO - Iter [42900/50000]	lr: 1.809e-03, eta: 2:26:06, time: 0.991, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1437, decode.acc_seg: 94.5251, aux.loss_ce: 0.0812, aux.acc_seg: 92.9639, loss: 0.2248
2022-03-23 17:48:17,936 - mmseg - INFO - Iter [42950/50000]	lr: 1.798e-03, eta: 2:24:35, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1382, decode.acc_seg: 94.8434, aux.loss_ce: 0.0794, aux.acc_seg: 93.0947, loss: 0.2176
2022-03-23 17:49:09,669 - mmseg - INFO - Exp name: pprp_deeplabv3_r50-d8_512x1024_40k_cityscapes.py
2022-03-23 17:49:09,669 - mmseg - INFO - Iter [43000/50000]	lr: 1.787e-03, eta: 2:23:11, time: 1.035, data_time: 0.054, memory: 19929, decode.loss_ce: 0.1505, decode.acc_seg: 94.4401, aux.loss_ce: 0.0852, aux.acc_seg: 92.6799, loss: 0.2356
2022-03-23 17:49:59,009 - mmseg - INFO - Iter [43050/50000]	lr: 1.777e-03, eta: 2:21:42, time: 0.987, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1383, decode.acc_seg: 94.9746, aux.loss_ce: 0.0837, aux.acc_seg: 92.9065, loss: 0.2221
2022-03-23 17:50:48,695 - mmseg - INFO - Iter [43100/50000]	lr: 1.766e-03, eta: 2:20:15, time: 0.994, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1425, decode.acc_seg: 94.6512, aux.loss_ce: 0.0820, aux.acc_seg: 92.8634, loss: 0.2245
2022-03-23 17:51:38,218 - mmseg - INFO - Iter [43150/50000]	lr: 1.755e-03, eta: 2:18:49, time: 0.990, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1459, decode.acc_seg: 94.6252, aux.loss_ce: 0.0812, aux.acc_seg: 93.0521, loss: 0.2271
2022-03-23 17:52:27,559 - mmseg - INFO - Iter [43200/50000]	lr: 1.744e-03, eta: 2:17:24, time: 0.987, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1468, decode.acc_seg: 94.4771, aux.loss_ce: 0.0831, aux.acc_seg: 92.7440, loss: 0.2300
2022-03-23 17:53:16,826 - mmseg - INFO - Iter [43250/50000]	lr: 1.733e-03, eta: 2:16:00, time: 0.985, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1328, decode.acc_seg: 95.1505, aux.loss_ce: 0.0769, aux.acc_seg: 93.2860, loss: 0.2098
2022-03-23 17:54:06,213 - mmseg - INFO - Iter [43300/50000]	lr: 1.722e-03, eta: 2:14:37, time: 0.988, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1460, decode.acc_seg: 94.5476, aux.loss_ce: 0.0824, aux.acc_seg: 92.8750, loss: 0.2284
2022-03-23 17:54:58,194 - mmseg - INFO - Iter [43350/50000]	lr: 1.711e-03, eta: 2:13:20, time: 1.040, data_time: 0.055, memory: 19929, decode.loss_ce: 0.1489, decode.acc_seg: 94.4901, aux.loss_ce: 0.0806, aux.acc_seg: 93.0124, loss: 0.2295
2022-03-23 17:55:47,607 - mmseg - INFO - Iter [43400/50000]	lr: 1.700e-03, eta: 2:11:59, time: 0.988, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1303, decode.acc_seg: 95.2044, aux.loss_ce: 0.0772, aux.acc_seg: 93.2613, loss: 0.2075
2022-03-23 17:56:37,094 - mmseg - INFO - Iter [43450/50000]	lr: 1.689e-03, eta: 2:10:39, time: 0.990, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1382, decode.acc_seg: 94.8863, aux.loss_ce: 0.0796, aux.acc_seg: 93.0872, loss: 0.2178
2022-03-23 17:57:26,588 - mmseg - INFO - Iter [43500/50000]	lr: 1.678e-03, eta: 2:09:20, time: 0.990, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1474, decode.acc_seg: 94.5186, aux.loss_ce: 0.0855, aux.acc_seg: 92.5517, loss: 0.2329
2022-03-23 17:58:16,103 - mmseg - INFO - Iter [43550/50000]	lr: 1.668e-03, eta: 2:08:02, time: 0.990, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1360, decode.acc_seg: 94.9993, aux.loss_ce: 0.0771, aux.acc_seg: 93.3390, loss: 0.2131
2022-03-23 17:59:05,518 - mmseg - INFO - Iter [43600/50000]	lr: 1.657e-03, eta: 2:06:44, time: 0.988, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1386, decode.acc_seg: 94.8838, aux.loss_ce: 0.0796, aux.acc_seg: 93.1072, loss: 0.2182
2022-03-23 17:59:54,983 - mmseg - INFO - Iter [43650/50000]	lr: 1.646e-03, eta: 2:05:28, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1369, decode.acc_seg: 94.9029, aux.loss_ce: 0.0805, aux.acc_seg: 93.1240, loss: 0.2175
2022-03-23 18:00:44,338 - mmseg - INFO - Iter [43700/50000]	lr: 1.635e-03, eta: 2:04:12, time: 0.987, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1384, decode.acc_seg: 94.8915, aux.loss_ce: 0.0802, aux.acc_seg: 93.1220, loss: 0.2186
2022-03-23 18:01:36,261 - mmseg - INFO - Iter [43750/50000]	lr: 1.624e-03, eta: 2:03:00, time: 1.038, data_time: 0.054, memory: 19929, decode.loss_ce: 0.1348, decode.acc_seg: 95.0516, aux.loss_ce: 0.0753, aux.acc_seg: 93.5439, loss: 0.2101
2022-03-23 18:02:25,829 - mmseg - INFO - Iter [43800/50000]	lr: 1.613e-03, eta: 2:01:46, time: 0.991, data_time: 0.009, memory: 19929, decode.loss_ce: 0.1293, decode.acc_seg: 95.2157, aux.loss_ce: 0.0719, aux.acc_seg: 93.8005, loss: 0.2013
2022-03-23 18:03:15,484 - mmseg - INFO - Iter [43850/50000]	lr: 1.602e-03, eta: 2:00:32, time: 0.993, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1519, decode.acc_seg: 94.3517, aux.loss_ce: 0.0876, aux.acc_seg: 92.4482, loss: 0.2394
2022-03-23 18:04:05,688 - mmseg - INFO - Iter [43900/50000]	lr: 1.591e-03, eta: 1:59:20, time: 1.003, data_time: 0.010, memory: 19929, decode.loss_ce: 0.1459, decode.acc_seg: 94.6544, aux.loss_ce: 0.0847, aux.acc_seg: 92.7747, loss: 0.2306
2022-03-23 18:04:55,428 - mmseg - INFO - Iter [43950/50000]	lr: 1.580e-03, eta: 1:58:08, time: 0.996, data_time: 0.010, memory: 19929, decode.loss_ce: 0.1405, decode.acc_seg: 94.8427, aux.loss_ce: 0.0788, aux.acc_seg: 92.9889, loss: 0.2193
2022-03-23 18:05:45,034 - mmseg - INFO - Saving checkpoint at 44000 iterations
2022-03-23 18:05:46,391 - mmseg - INFO - Exp name: pprp_deeplabv3_r50-d8_512x1024_40k_cityscapes.py
2022-03-23 18:05:46,391 - mmseg - INFO - Iter [44000/50000]	lr: 1.569e-03, eta: 1:56:58, time: 1.019, data_time: 0.009, memory: 19929, decode.loss_ce: 0.1342, decode.acc_seg: 95.0637, aux.loss_ce: 0.0770, aux.acc_seg: 93.3948, loss: 0.2113
[                                                  ] 0/500, elapsed: 0s, ETA:[                                 ] 1/500, 1.4 task/s, elapsed: 1s, ETA:   347s[                                 ] 2/500, 2.9 task/s, elapsed: 1s, ETA:   173s[                                 ] 3/500, 4.3 task/s, elapsed: 1s, ETA:   115s[                                 ] 4/500, 5.8 task/s, elapsed: 1s, ETA:    86s[                                 ] 5/500, 4.1 task/s, elapsed: 1s, ETA:   121s[                                 ] 6/500, 4.9 task/s, elapsed: 1s, ETA:   101s[                                 ] 7/500, 5.7 task/s, elapsed: 1s, ETA:    86s[                                 ] 8/500, 6.5 task/s, elapsed: 1s, ETA:    75s[                                 ] 9/500, 5.2 task/s, elapsed: 2s, ETA:    94s[                                ] 10/500, 5.8 task/s, elapsed: 2s, ETA:    84s[                                ] 11/500, 6.4 task/s, elapsed: 2s, ETA:    76s[                                ] 12/500, 7.0 task/s, elapsed: 2s, ETA:    70s[                                ] 13/500, 5.7 task/s, elapsed: 2s, ETA:    86s[                                ] 14/500, 6.1 task/s, elapsed: 2s, ETA:    80s[                                ] 15/500, 6.5 task/s, elapsed: 2s, ETA:    74s[>                               ] 16/500, 7.0 task/s, elapsed: 2s, ETA:    69s[>                               ] 17/500, 6.1 task/s, elapsed: 3s, ETA:    79s[>                               ] 18/500, 6.4 task/s, elapsed: 3s, ETA:    75s[>                               ] 19/500, 6.8 task/s, elapsed: 3s, ETA:    71s[>                               ] 20/500, 7.2 task/s, elapsed: 3s, ETA:    67s[>                               ] 21/500, 6.4 task/s, elapsed: 3s, ETA:    75s[>                               ] 22/500, 6.7 task/s, elapsed: 3s, ETA:    71s[>                               ] 23/500, 7.0 task/s, elapsed: 3s, ETA:    68s[>                               ] 24/500, 7.3 task/s, elapsed: 3s, ETA:    65s[>                               ] 25/500, 6.6 task/s, elapsed: 4s, ETA:    72s[>                               ] 26/500, 6.9 task/s, elapsed: 4s, ETA:    69s[>                               ] 27/500, 7.1 task/s, elapsed: 4s, ETA:    66s[>                               ] 28/500, 7.4 task/s, elapsed: 4s, ETA:    64s[>                               ] 29/500, 6.7 task/s, elapsed: 4s, ETA:    71s[>                               ] 30/500, 6.9 task/s, elapsed: 4s, ETA:    68s[>                               ] 31/500, 7.1 task/s, elapsed: 4s, ETA:    66s[>>                              ] 32/500, 7.4 task/s, elapsed: 4s, ETA:    64s[>>                              ] 33/500, 6.8 task/s, elapsed: 5s, ETA:    68s[>>                              ] 34/500, 7.0 task/s, elapsed: 5s, ETA:    66s[>>                              ] 35/500, 7.2 task/s, elapsed: 5s, ETA:    64s[>>                              ] 36/500, 7.4 task/s, elapsed: 5s, ETA:    62s[>>                              ] 37/500, 6.9 task/s, elapsed: 5s, ETA:    67s[>>                              ] 38/500, 7.1 task/s, elapsed: 5s, ETA:    65s[>>                              ] 39/500, 7.3 task/s, elapsed: 5s, ETA:    63s[>>                              ] 40/500, 7.5 task/s, elapsed: 5s, ETA:    61s[>>                              ] 41/500, 7.0 task/s, elapsed: 6s, ETA:    65s[>>                              ] 42/500, 7.2 task/s, elapsed: 6s, ETA:    63s[>>                              ] 43/500, 7.4 task/s, elapsed: 6s, ETA:    62s[>>                              ] 44/500, 7.6 task/s, elapsed: 6s, ETA:    60s[>>                              ] 45/500, 7.1 task/s, elapsed: 6s, ETA:    64s[>>                              ] 46/500, 7.3 task/s, elapsed: 6s, ETA:    63s[>>>                             ] 47/500, 7.4 task/s, elapsed: 6s, ETA:    61s[>>>                             ] 48/500, 7.6 task/s, elapsed: 6s, ETA:    60s[>>>                             ] 49/500, 7.2 task/s, elapsed: 7s, ETA:    63s[>>>                             ] 50/500, 7.3 task/s, elapsed: 7s, ETA:    61s[>>>                             ] 51/500, 7.5 task/s, elapsed: 7s, ETA:    60s[>>>                             ] 52/500, 7.6 task/s, elapsed: 7s, ETA:    59s[>>>                             ] 53/500, 7.3 task/s, elapsed: 7s, ETA:    62s[>>>                             ] 54/500, 7.4 task/s, elapsed: 7s, ETA:    60s[>>>                             ] 55/500, 7.5 task/s, elapsed: 7s, ETA:    59s[>>>                             ] 56/500, 7.7 task/s, elapsed: 7s, ETA:    58s[>>>                             ] 57/500, 7.3 task/s, elapsed: 8s, ETA:    61s[>>>                             ] 58/500, 7.4 task/s, elapsed: 8s, ETA:    59s[>>>                             ] 59/500, 7.6 task/s, elapsed: 8s, ETA:    58s[>>>                             ] 60/500, 7.7 task/s, elapsed: 8s, ETA:    57s[>>>                             ] 61/500, 7.4 task/s, elapsed: 8s, ETA:    60s[>>>                             ] 62/500, 7.5 task/s, elapsed: 8s, ETA:    59s[>>>>                            ] 63/500, 7.6 task/s, elapsed: 8s, ETA:    58s[>>>>                            ] 64/500, 7.7 task/s, elapsed: 8s, ETA:    57s[>>>>                            ] 65/500, 7.4 task/s, elapsed: 9s, ETA:    59s[>>>>                            ] 66/500, 7.5 task/s, elapsed: 9s, ETA:    58s[>>>>                            ] 67/500, 7.6 task/s, elapsed: 9s, ETA:    57s[>>>>                            ] 68/500, 7.7 task/s, elapsed: 9s, ETA:    56s[>>>>                            ] 69/500, 7.4 task/s, elapsed: 9s, ETA:    58s[>>>>                            ] 70/500, 7.5 task/s, elapsed: 9s, ETA:    57s[>>>>                            ] 71/500, 7.6 task/s, elapsed: 9s, ETA:    56s[>>>>                            ] 72/500, 7.7 task/s, elapsed: 9s, ETA:    55s[>>>>                           ] 73/500, 7.4 task/s, elapsed: 10s, ETA:    57s[>>>>                           ] 74/500, 7.5 task/s, elapsed: 10s, ETA:    57s[>>>>                           ] 75/500, 7.6 task/s, elapsed: 10s, ETA:    56s[>>>>                           ] 76/500, 7.7 task/s, elapsed: 10s, ETA:    55s[>>>>                           ] 77/500, 7.5 task/s, elapsed: 10s, ETA:    57s[>>>>                           ] 78/500, 7.6 task/s, elapsed: 10s, ETA:    56s[>>>>                           ] 79/500, 7.7 task/s, elapsed: 10s, ETA:    55s[>>>>                           ] 80/500, 7.8 task/s, elapsed: 10s, ETA:    54s[>>>>>                          ] 81/500, 7.5 task/s, elapsed: 11s, ETA:    56s[>>>>>                          ] 82/500, 7.5 task/s, elapsed: 11s, ETA:    55s[>>>>>                          ] 83/500, 7.6 task/s, elapsed: 11s, ETA:    55s[>>>>>                          ] 84/500, 7.7 task/s, elapsed: 11s, ETA:    54s[>>>>>                          ] 85/500, 7.5 task/s, elapsed: 11s, ETA:    55s[>>>>>                          ] 86/500, 7.6 task/s, elapsed: 11s, ETA:    55s[>>>>>                          ] 87/500, 7.7 task/s, elapsed: 11s, ETA:    54s[>>>>>                          ] 88/500, 7.7 task/s, elapsed: 11s, ETA:    53s[>>>>>                          ] 89/500, 7.5 task/s, elapsed: 12s, ETA:    55s[>>>>>                          ] 90/500, 7.6 task/s, elapsed: 12s, ETA:    54s[>>>>>                          ] 91/500, 7.7 task/s, elapsed: 12s, ETA:    53s[>>>>>                          ] 92/500, 7.7 task/s, elapsed: 12s, ETA:    53s[>>>>>                          ] 93/500, 7.5 task/s, elapsed: 12s, ETA:    54s[>>>>>                          ] 94/500, 7.6 task/s, elapsed: 12s, ETA:    54s[>>>>>                          ] 95/500, 7.7 task/s, elapsed: 12s, ETA:    53s[>>>>>                          ] 96/500, 7.7 task/s, elapsed: 12s, ETA:    52s[>>>>>>                         ] 97/500, 7.5 task/s, elapsed: 13s, ETA:    54s[>>>>>>                         ] 98/500, 7.6 task/s, elapsed: 13s, ETA:    53s[>>>>>>                         ] 99/500, 7.7 task/s, elapsed: 13s, ETA:    52s[>>>>>>                        ] 100/500, 7.8 task/s, elapsed: 13s, ETA:    52s[>>>>>>                        ] 101/500, 7.5 task/s, elapsed: 13s, ETA:    53s[>>>>>>                        ] 102/500, 7.6 task/s, elapsed: 13s, ETA:    52s[>>>>>>                        ] 103/500, 7.7 task/s, elapsed: 13s, ETA:    52s[>>>>>>                        ] 104/500, 7.8 task/s, elapsed: 13s, ETA:    51s[>>>>>>                        ] 105/500, 7.6 task/s, elapsed: 14s, ETA:    52s[>>>>>>                        ] 106/500, 7.6 task/s, elapsed: 14s, ETA:    52s[>>>>>>                        ] 107/500, 7.7 task/s, elapsed: 14s, ETA:    51s[>>>>>>                        ] 108/500, 7.8 task/s, elapsed: 14s, ETA:    50s[>>>>>>                        ] 109/500, 7.6 task/s, elapsed: 14s, ETA:    52s[>>>>>>                        ] 110/500, 7.6 task/s, elapsed: 14s, ETA:    51s[>>>>>>                        ] 111/500, 7.7 task/s, elapsed: 14s, ETA:    50s[>>>>>>                        ] 112/500, 7.8 task/s, elapsed: 14s, ETA:    50s[>>>>>>                        ] 113/500, 7.6 task/s, elapsed: 15s, ETA:    51s[>>>>>>                        ] 114/500, 7.7 task/s, elapsed: 15s, ETA:    50s[>>>>>>                        ] 115/500, 7.7 task/s, elapsed: 15s, ETA:    50s[>>>>>>                        ] 116/500, 7.8 task/s, elapsed: 15s, ETA:    49s[>>>>>>>                       ] 117/500, 7.6 task/s, elapsed: 15s, ETA:    50s[>>>>>>>                       ] 118/500, 7.7 task/s, elapsed: 15s, ETA:    50s[>>>>>>>                       ] 119/500, 7.7 task/s, elapsed: 15s, ETA:    49s[>>>>>>>                       ] 120/500, 7.8 task/s, elapsed: 15s, ETA:    49s[>>>>>>>                       ] 121/500, 7.6 task/s, elapsed: 16s, ETA:    50s[>>>>>>>                       ] 122/500, 7.7 task/s, elapsed: 16s, ETA:    49s[>>>>>>>                       ] 123/500, 7.8 task/s, elapsed: 16s, ETA:    49s[>>>>>>>                       ] 124/500, 7.8 task/s, elapsed: 16s, ETA:    48s[>>>>>>>                       ] 125/500, 7.6 task/s, elapsed: 16s, ETA:    49s[>>>>>>>                       ] 126/500, 7.7 task/s, elapsed: 16s, ETA:    49s[>>>>>>>                       ] 127/500, 7.8 task/s, elapsed: 16s, ETA:    48s[>>>>>>>                       ] 128/500, 7.8 task/s, elapsed: 16s, ETA:    48s[>>>>>>>                       ] 129/500, 7.6 task/s, elapsed: 17s, ETA:    49s[>>>>>>>                       ] 130/500, 7.7 task/s, elapsed: 17s, ETA:    48s[>>>>>>>                       ] 131/500, 7.7 task/s, elapsed: 17s, ETA:    48s[>>>>>>>                       ] 132/500, 7.8 task/s, elapsed: 17s, ETA:    47s[>>>>>>>                       ] 133/500, 7.6 task/s, elapsed: 17s, ETA:    48s[>>>>>>>>                      ] 134/500, 7.7 task/s, elapsed: 17s, ETA:    48s[>>>>>>>>                      ] 135/500, 7.7 task/s, elapsed: 17s, ETA:    47s[>>>>>>>>                      ] 136/500, 7.8 task/s, elapsed: 17s, ETA:    47s[>>>>>>>>                      ] 137/500, 7.6 task/s, elapsed: 18s, ETA:    48s[>>>>>>>>                      ] 138/500, 7.7 task/s, elapsed: 18s, ETA:    47s[>>>>>>>>                      ] 139/500, 7.7 task/s, elapsed: 18s, ETA:    47s[>>>>>>>>                      ] 140/500, 7.8 task/s, elapsed: 18s, ETA:    46s[>>>>>>>>                      ] 141/500, 7.6 task/s, elapsed: 18s, ETA:    47s[>>>>>>>>                      ] 142/500, 7.7 task/s, elapsed: 18s, ETA:    46s[>>>>>>>>                      ] 143/500, 7.8 task/s, elapsed: 18s, ETA:    46s[>>>>>>>>                      ] 144/500, 7.8 task/s, elapsed: 18s, ETA:    46s[>>>>>>>>                      ] 145/500, 7.6 task/s, elapsed: 19s, ETA:    46s[>>>>>>>>                      ] 146/500, 7.7 task/s, elapsed: 19s, ETA:    46s[>>>>>>>>                      ] 147/500, 7.7 task/s, elapsed: 19s, ETA:    46s[>>>>>>>>                      ] 148/500, 7.8 task/s, elapsed: 19s, ETA:    45s[>>>>>>>>                      ] 149/500, 7.7 task/s, elapsed: 19s, ETA:    46s[>>>>>>>>>                     ] 150/500, 7.7 task/s, elapsed: 19s, ETA:    45s[>>>>>>>>>                     ] 151/500, 7.8 task/s, elapsed: 19s, ETA:    45s[>>>>>>>>>                     ] 152/500, 7.8 task/s, elapsed: 19s, ETA:    45s[>>>>>>>>>                     ] 153/500, 7.7 task/s, elapsed: 20s, ETA:    45s[>>>>>>>>>                     ] 154/500, 7.7 task/s, elapsed: 20s, ETA:    45s[>>>>>>>>>                     ] 155/500, 7.8 task/s, elapsed: 20s, ETA:    44s[>>>>>>>>>                     ] 156/500, 7.8 task/s, elapsed: 20s, ETA:    44s[>>>>>>>>>                     ] 157/500, 7.7 task/s, elapsed: 20s, ETA:    45s[>>>>>>>>>                     ] 158/500, 7.7 task/s, elapsed: 20s, ETA:    44s[>>>>>>>>>                     ] 159/500, 7.8 task/s, elapsed: 20s, ETA:    44s[>>>>>>>>>                     ] 160/500, 7.8 task/s, elapsed: 20s, ETA:    43s[>>>>>>>>>                     ] 161/500, 7.7 task/s, elapsed: 21s, ETA:    44s[>>>>>>>>>                     ] 162/500, 7.7 task/s, elapsed: 21s, ETA:    44s[>>>>>>>>>                     ] 163/500, 7.8 task/s, elapsed: 21s, ETA:    43s[>>>>>>>>>                     ] 164/500, 7.8 task/s, elapsed: 21s, ETA:    43s[>>>>>>>>>                     ] 165/500, 7.7 task/s, elapsed: 21s, ETA:    44s[>>>>>>>>>                     ] 166/500, 7.7 task/s, elapsed: 21s, ETA:    43s[>>>>>>>>>>                    ] 167/500, 7.8 task/s, elapsed: 21s, ETA:    43s[>>>>>>>>>>                    ] 168/500, 7.8 task/s, elapsed: 21s, ETA:    42s[>>>>>>>>>>                    ] 169/500, 7.7 task/s, elapsed: 22s, ETA:    43s[>>>>>>>>>>                    ] 170/500, 7.7 task/s, elapsed: 22s, ETA:    43s[>>>>>>>>>>                    ] 171/500, 7.8 task/s, elapsed: 22s, ETA:    42s[>>>>>>>>>>                    ] 172/500, 7.8 task/s, elapsed: 22s, ETA:    42s[>>>>>>>>>>                    ] 173/500, 7.7 task/s, elapsed: 22s, ETA:    42s[>>>>>>>>>>                    ] 174/500, 7.7 task/s, elapsed: 22s, ETA:    42s[>>>>>>>>>>                    ] 175/500, 7.8 task/s, elapsed: 22s, ETA:    42s[>>>>>>>>>>                    ] 176/500, 7.8 task/s, elapsed: 22s, ETA:    41s[>>>>>>>>>>                    ] 177/500, 7.7 task/s, elapsed: 23s, ETA:    42s[>>>>>>>>>>                    ] 178/500, 7.8 task/s, elapsed: 23s, ETA:    42s[>>>>>>>>>>                    ] 179/500, 7.8 task/s, elapsed: 23s, ETA:    41s[>>>>>>>>>>                    ] 180/500, 7.8 task/s, elapsed: 23s, ETA:    41s[>>>>>>>>>>                    ] 181/500, 7.7 task/s, elapsed: 23s, ETA:    41s[>>>>>>>>>>                    ] 182/500, 7.8 task/s, elapsed: 23s, ETA:    41s[>>>>>>>>>>                    ] 183/500, 7.8 task/s, elapsed: 23s, ETA:    41s[>>>>>>>>>>>                   ] 184/500, 7.8 task/s, elapsed: 23s, ETA:    40s[>>>>>>>>>>>                   ] 185/500, 7.7 task/s, elapsed: 24s, ETA:    41s[>>>>>>>>>>>                   ] 186/500, 7.8 task/s, elapsed: 24s, ETA:    40s[>>>>>>>>>>>                   ] 187/500, 7.8 task/s, elapsed: 24s, ETA:    40s[>>>>>>>>>>>                   ] 188/500, 7.8 task/s, elapsed: 24s, ETA:    40s[>>>>>>>>>>>                   ] 189/500, 7.7 task/s, elapsed: 24s, ETA:    40s[>>>>>>>>>>>                   ] 190/500, 7.8 task/s, elapsed: 24s, ETA:    40s[>>>>>>>>>>>                   ] 191/500, 7.8 task/s, elapsed: 24s, ETA:    40s[>>>>>>>>>>>                   ] 192/500, 7.8 task/s, elapsed: 24s, ETA:    39s[>>>>>>>>>>>                   ] 193/500, 7.7 task/s, elapsed: 25s, ETA:    40s[>>>>>>>>>>>                   ] 194/500, 7.8 task/s, elapsed: 25s, ETA:    39s[>>>>>>>>>>>                   ] 195/500, 7.8 task/s, elapsed: 25s, ETA:    39s[>>>>>>>>>>>                   ] 196/500, 7.8 task/s, elapsed: 25s, ETA:    39s[>>>>>>>>>>>                   ] 197/500, 7.7 task/s, elapsed: 25s, ETA:    39s[>>>>>>>>>>>                   ] 198/500, 7.8 task/s, elapsed: 25s, ETA:    39s[>>>>>>>>>>>                   ] 199/500, 7.8 task/s, elapsed: 25s, ETA:    39s[>>>>>>>>>>>>                  ] 200/500, 7.9 task/s, elapsed: 25s, ETA:    38s[>>>>>>>>>>>>                  ] 201/500, 7.7 task/s, elapsed: 26s, ETA:    39s[>>>>>>>>>>>>                  ] 202/500, 7.8 task/s, elapsed: 26s, ETA:    38s[>>>>>>>>>>>>                  ] 203/500, 7.8 task/s, elapsed: 26s, ETA:    38s[>>>>>>>>>>>>                  ] 204/500, 7.9 task/s, elapsed: 26s, ETA:    38s[>>>>>>>>>>>>                  ] 205/500, 7.7 task/s, elapsed: 26s, ETA:    38s[>>>>>>>>>>>>                  ] 206/500, 7.8 task/s, elapsed: 26s, ETA:    38s[>>>>>>>>>>>>                  ] 207/500, 7.8 task/s, elapsed: 26s, ETA:    37s[>>>>>>>>>>>>                  ] 208/500, 7.9 task/s, elapsed: 26s, ETA:    37s[>>>>>>>>>>>>                  ] 209/500, 7.7 task/s, elapsed: 27s, ETA:    38s[>>>>>>>>>>>>                  ] 210/500, 7.8 task/s, elapsed: 27s, ETA:    37s[>>>>>>>>>>>>                  ] 211/500, 7.8 task/s, elapsed: 27s, ETA:    37s[>>>>>>>>>>>>                  ] 212/500, 7.9 task/s, elapsed: 27s, ETA:    37s[>>>>>>>>>>>>                  ] 213/500, 7.8 task/s, elapsed: 27s, ETA:    37s[>>>>>>>>>>>>                  ] 214/500, 7.8 task/s, elapsed: 27s, ETA:    37s[>>>>>>>>>>>>                  ] 215/500, 7.8 task/s, elapsed: 27s, ETA:    36s[>>>>>>>>>>>>                  ] 216/500, 7.9 task/s, elapsed: 27s, ETA:    36s[>>>>>>>>>>>>>                 ] 217/500, 7.7 task/s, elapsed: 28s, ETA:    37s[>>>>>>>>>>>>>                 ] 218/500, 7.8 task/s, elapsed: 28s, ETA:    36s[>>>>>>>>>>>>>                 ] 219/500, 7.8 task/s, elapsed: 28s, ETA:    36s[>>>>>>>>>>>>>                 ] 220/500, 7.8 task/s, elapsed: 28s, ETA:    36s[>>>>>>>>>>>>>                 ] 221/500, 7.7 task/s, elapsed: 29s, ETA:    36s[>>>>>>>>>>>>>                 ] 222/500, 7.8 task/s, elapsed: 29s, ETA:    36s[>>>>>>>>>>>>>                 ] 223/500, 7.8 task/s, elapsed: 29s, ETA:    35s[>>>>>>>>>>>>>                 ] 224/500, 7.8 task/s, elapsed: 29s, ETA:    35s[>>>>>>>>>>>>>                 ] 225/500, 7.7 task/s, elapsed: 29s, ETA:    36s[>>>>>>>>>>>>>                 ] 226/500, 7.8 task/s, elapsed: 29s, ETA:    35s[>>>>>>>>>>>>>                 ] 227/500, 7.8 task/s, elapsed: 29s, ETA:    35s[>>>>>>>>>>>>>                 ] 228/500, 7.8 task/s, elapsed: 29s, ETA:    35s[>>>>>>>>>>>>>                 ] 229/500, 7.7 task/s, elapsed: 30s, ETA:    35s[>>>>>>>>>>>>>                 ] 230/500, 7.8 task/s, elapsed: 30s, ETA:    35s[>>>>>>>>>>>>>                 ] 231/500, 7.8 task/s, elapsed: 30s, ETA:    34s[>>>>>>>>>>>>>                 ] 232/500, 7.8 task/s, elapsed: 30s, ETA:    34s[>>>>>>>>>>>>>                 ] 233/500, 7.7 task/s, elapsed: 30s, ETA:    35s[>>>>>>>>>>>>>>                ] 234/500, 7.8 task/s, elapsed: 30s, ETA:    34s[>>>>>>>>>>>>>>                ] 235/500, 7.8 task/s, elapsed: 30s, ETA:    34s[>>>>>>>>>>>>>>                ] 236/500, 7.8 task/s, elapsed: 30s, ETA:    34s[>>>>>>>>>>>>>>                ] 237/500, 7.7 task/s, elapsed: 31s, ETA:    34s[>>>>>>>>>>>>>>                ] 238/500, 7.8 task/s, elapsed: 31s, ETA:    34s[>>>>>>>>>>>>>>                ] 239/500, 7.8 task/s, elapsed: 31s, ETA:    33s[>>>>>>>>>>>>>>                ] 240/500, 7.8 task/s, elapsed: 31s, ETA:    33s[>>>>>>>>>>>>>>                ] 241/500, 7.7 task/s, elapsed: 31s, ETA:    33s[>>>>>>>>>>>>>>                ] 242/500, 7.8 task/s, elapsed: 31s, ETA:    33s[>>>>>>>>>>>>>>                ] 243/500, 7.8 task/s, elapsed: 31s, ETA:    33s[>>>>>>>>>>>>>>                ] 244/500, 7.8 task/s, elapsed: 31s, ETA:    33s[>>>>>>>>>>>>>>                ] 245/500, 7.7 task/s, elapsed: 32s, ETA:    33s[>>>>>>>>>>>>>>                ] 246/500, 7.8 task/s, elapsed: 32s, ETA:    33s[>>>>>>>>>>>>>>                ] 247/500, 7.8 task/s, elapsed: 32s, ETA:    32s[>>>>>>>>>>>>>>                ] 248/500, 7.8 task/s, elapsed: 32s, ETA:    32s[>>>>>>>>>>>>>>                ] 249/500, 7.7 task/s, elapsed: 32s, ETA:    32s[>>>>>>>>>>>>>>>               ] 250/500, 7.8 task/s, elapsed: 32s, ETA:    32s[>>>>>>>>>>>>>>>               ] 251/500, 7.8 task/s, elapsed: 32s, ETA:    32s[>>>>>>>>>>>>>>>               ] 252/500, 7.8 task/s, elapsed: 32s, ETA:    32s[>>>>>>>>>>>>>>>               ] 253/500, 7.7 task/s, elapsed: 33s, ETA:    32s[>>>>>>>>>>>>>>>               ] 254/500, 7.8 task/s, elapsed: 33s, ETA:    32s[>>>>>>>>>>>>>>>               ] 255/500, 7.8 task/s, elapsed: 33s, ETA:    31s[>>>>>>>>>>>>>>>               ] 256/500, 7.8 task/s, elapsed: 33s, ETA:    31s[>>>>>>>>>>>>>>>               ] 257/500, 7.7 task/s, elapsed: 33s, ETA:    31s[>>>>>>>>>>>>>>>               ] 258/500, 7.8 task/s, elapsed: 33s, ETA:    31s[>>>>>>>>>>>>>>>               ] 259/500, 7.8 task/s, elapsed: 33s, ETA:    31s[>>>>>>>>>>>>>>>               ] 260/500, 7.8 task/s, elapsed: 33s, ETA:    31s[>>>>>>>>>>>>>>>               ] 261/500, 7.7 task/s, elapsed: 34s, ETA:    31s[>>>>>>>>>>>>>>>               ] 262/500, 7.8 task/s, elapsed: 34s, ETA:    31s[>>>>>>>>>>>>>>>               ] 263/500, 7.8 task/s, elapsed: 34s, ETA:    30s[>>>>>>>>>>>>>>>               ] 264/500, 7.8 task/s, elapsed: 34s, ETA:    30s[>>>>>>>>>>>>>>>               ] 265/500, 7.7 task/s, elapsed: 34s, ETA:    30s[>>>>>>>>>>>>>>>               ] 266/500, 7.8 task/s, elapsed: 34s, ETA:    30s[>>>>>>>>>>>>>>>>              ] 267/500, 7.8 task/s, elapsed: 34s, ETA:    30s[>>>>>>>>>>>>>>>>              ] 268/500, 7.8 task/s, elapsed: 34s, ETA:    30s[>>>>>>>>>>>>>>>>              ] 269/500, 7.8 task/s, elapsed: 35s, ETA:    30s[>>>>>>>>>>>>>>>>              ] 270/500, 7.8 task/s, elapsed: 35s, ETA:    30s[>>>>>>>>>>>>>>>>              ] 271/500, 7.8 task/s, elapsed: 35s, ETA:    29s[>>>>>>>>>>>>>>>>              ] 272/500, 7.8 task/s, elapsed: 35s, ETA:    29s[>>>>>>>>>>>>>>>>              ] 273/500, 7.8 task/s, elapsed: 35s, ETA:    29s[>>>>>>>>>>>>>>>>              ] 274/500, 7.8 task/s, elapsed: 35s, ETA:    29s[>>>>>>>>>>>>>>>>              ] 275/500, 7.8 task/s, elapsed: 35s, ETA:    29s[>>>>>>>>>>>>>>>>              ] 276/500, 7.8 task/s, elapsed: 35s, ETA:    29s[>>>>>>>>>>>>>>>>              ] 277/500, 7.7 task/s, elapsed: 36s, ETA:    29s[>>>>>>>>>>>>>>>>              ] 278/500, 7.8 task/s, elapsed: 36s, ETA:    29s[>>>>>>>>>>>>>>>>              ] 279/500, 7.8 task/s, elapsed: 36s, ETA:    28s[>>>>>>>>>>>>>>>>              ] 280/500, 7.8 task/s, elapsed: 36s, ETA:    28s[>>>>>>>>>>>>>>>>              ] 281/500, 7.7 task/s, elapsed: 36s, ETA:    28s[>>>>>>>>>>>>>>>>              ] 282/500, 7.8 task/s, elapsed: 36s, ETA:    28s[>>>>>>>>>>>>>>>>              ] 283/500, 7.8 task/s, elapsed: 36s, ETA:    28s[>>>>>>>>>>>>>>>>>             ] 284/500, 7.8 task/s, elapsed: 36s, ETA:    28s[>>>>>>>>>>>>>>>>>             ] 285/500, 7.8 task/s, elapsed: 37s, ETA:    28s[>>>>>>>>>>>>>>>>>             ] 286/500, 7.8 task/s, elapsed: 37s, ETA:    27s[>>>>>>>>>>>>>>>>>             ] 287/500, 7.8 task/s, elapsed: 37s, ETA:    27s[>>>>>>>>>>>>>>>>>             ] 288/500, 7.8 task/s, elapsed: 37s, ETA:    27s[>>>>>>>>>>>>>>>>>             ] 289/500, 7.8 task/s, elapsed: 37s, ETA:    27s[>>>>>>>>>>>>>>>>>             ] 290/500, 7.8 task/s, elapsed: 37s, ETA:    27s[>>>>>>>>>>>>>>>>>             ] 291/500, 7.8 task/s, elapsed: 37s, ETA:    27s[>>>>>>>>>>>>>>>>>             ] 292/500, 7.8 task/s, elapsed: 37s, ETA:    27s[>>>>>>>>>>>>>>>>>             ] 293/500, 7.8 task/s, elapsed: 38s, ETA:    27s[>>>>>>>>>>>>>>>>>             ] 294/500, 7.8 task/s, elapsed: 38s, ETA:    26s[>>>>>>>>>>>>>>>>>             ] 295/500, 7.8 task/s, elapsed: 38s, ETA:    26s[>>>>>>>>>>>>>>>>>             ] 296/500, 7.8 task/s, elapsed: 38s, ETA:    26s[>>>>>>>>>>>>>>>>>             ] 297/500, 7.8 task/s, elapsed: 38s, ETA:    26s[>>>>>>>>>>>>>>>>>             ] 298/500, 7.8 task/s, elapsed: 38s, ETA:    26s[>>>>>>>>>>>>>>>>>             ] 299/500, 7.8 task/s, elapsed: 38s, ETA:    26s[>>>>>>>>>>>>>>>>>>            ] 300/500, 7.8 task/s, elapsed: 38s, ETA:    26s[>>>>>>>>>>>>>>>>>>            ] 301/500, 7.8 task/s, elapsed: 39s, ETA:    26s[>>>>>>>>>>>>>>>>>>            ] 302/500, 7.8 task/s, elapsed: 39s, ETA:    25s[>>>>>>>>>>>>>>>>>>            ] 303/500, 7.8 task/s, elapsed: 39s, ETA:    25s[>>>>>>>>>>>>>>>>>>            ] 304/500, 7.8 task/s, elapsed: 39s, ETA:    25s[>>>>>>>>>>>>>>>>>>            ] 305/500, 7.8 task/s, elapsed: 39s, ETA:    25s[>>>>>>>>>>>>>>>>>>            ] 306/500, 7.8 task/s, elapsed: 39s, ETA:    25s[>>>>>>>>>>>>>>>>>>            ] 307/500, 7.8 task/s, elapsed: 39s, ETA:    25s[>>>>>>>>>>>>>>>>>>            ] 308/500, 7.8 task/s, elapsed: 39s, ETA:    24s[>>>>>>>>>>>>>>>>>>            ] 309/500, 7.8 task/s, elapsed: 40s, ETA:    25s[>>>>>>>>>>>>>>>>>>            ] 310/500, 7.8 task/s, elapsed: 40s, ETA:    24s[>>>>>>>>>>>>>>>>>>            ] 311/500, 7.8 task/s, elapsed: 40s, ETA:    24s[>>>>>>>>>>>>>>>>>>            ] 312/500, 7.8 task/s, elapsed: 40s, ETA:    24s[>>>>>>>>>>>>>>>>>>            ] 313/500, 7.8 task/s, elapsed: 40s, ETA:    24s[>>>>>>>>>>>>>>>>>>            ] 314/500, 7.8 task/s, elapsed: 40s, ETA:    24s[>>>>>>>>>>>>>>>>>>            ] 315/500, 7.8 task/s, elapsed: 40s, ETA:    24s[>>>>>>>>>>>>>>>>>>            ] 316/500, 7.9 task/s, elapsed: 40s, ETA:    23s[>>>>>>>>>>>>>>>>>>>           ] 317/500, 7.8 task/s, elapsed: 41s, ETA:    23s[>>>>>>>>>>>>>>>>>>>           ] 318/500, 7.8 task/s, elapsed: 41s, ETA:    23s[>>>>>>>>>>>>>>>>>>>           ] 319/500, 7.8 task/s, elapsed: 41s, ETA:    23s[>>>>>>>>>>>>>>>>>>>           ] 320/500, 7.9 task/s, elapsed: 41s, ETA:    23s[>>>>>>>>>>>>>>>>>>>           ] 321/500, 7.8 task/s, elapsed: 41s, ETA:    23s[>>>>>>>>>>>>>>>>>>>           ] 322/500, 7.8 task/s, elapsed: 41s, ETA:    23s[>>>>>>>>>>>>>>>>>>>           ] 323/500, 7.8 task/s, elapsed: 41s, ETA:    23s[>>>>>>>>>>>>>>>>>>>           ] 324/500, 7.9 task/s, elapsed: 41s, ETA:    22s[>>>>>>>>>>>>>>>>>>>           ] 325/500, 7.8 task/s, elapsed: 42s, ETA:    22s[>>>>>>>>>>>>>>>>>>>           ] 326/500, 7.8 task/s, elapsed: 42s, ETA:    22s[>>>>>>>>>>>>>>>>>>>           ] 327/500, 7.8 task/s, elapsed: 42s, ETA:    22s[>>>>>>>>>>>>>>>>>>>           ] 328/500, 7.9 task/s, elapsed: 42s, ETA:    22s[>>>>>>>>>>>>>>>>>>>           ] 329/500, 7.8 task/s, elapsed: 42s, ETA:    22s[>>>>>>>>>>>>>>>>>>>           ] 330/500, 7.8 task/s, elapsed: 42s, ETA:    22s[>>>>>>>>>>>>>>>>>>>           ] 331/500, 7.9 task/s, elapsed: 42s, ETA:    22s[>>>>>>>>>>>>>>>>>>>           ] 332/500, 7.9 task/s, elapsed: 42s, ETA:    21s[>>>>>>>>>>>>>>>>>>>           ] 333/500, 7.8 task/s, elapsed: 43s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>          ] 334/500, 7.8 task/s, elapsed: 43s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>          ] 335/500, 7.9 task/s, elapsed: 43s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>          ] 336/500, 7.9 task/s, elapsed: 43s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>          ] 337/500, 7.8 task/s, elapsed: 43s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>          ] 338/500, 7.8 task/s, elapsed: 43s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>          ] 339/500, 7.9 task/s, elapsed: 43s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>          ] 340/500, 7.9 task/s, elapsed: 43s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>          ] 341/500, 7.8 task/s, elapsed: 44s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>          ] 342/500, 7.8 task/s, elapsed: 44s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>          ] 343/500, 7.9 task/s, elapsed: 44s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>          ] 344/500, 7.9 task/s, elapsed: 44s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>          ] 345/500, 7.8 task/s, elapsed: 44s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>          ] 346/500, 7.8 task/s, elapsed: 44s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>          ] 347/500, 7.9 task/s, elapsed: 44s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>          ] 348/500, 7.9 task/s, elapsed: 44s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>          ] 349/500, 7.8 task/s, elapsed: 45s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>         ] 350/500, 7.8 task/s, elapsed: 45s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>         ] 351/500, 7.9 task/s, elapsed: 45s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>         ] 352/500, 7.9 task/s, elapsed: 45s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>         ] 353/500, 7.8 task/s, elapsed: 45s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>         ] 354/500, 7.8 task/s, elapsed: 45s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>         ] 355/500, 7.9 task/s, elapsed: 45s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>         ] 356/500, 7.9 task/s, elapsed: 45s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>         ] 357/500, 7.8 task/s, elapsed: 46s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>         ] 358/500, 7.8 task/s, elapsed: 46s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>         ] 359/500, 7.9 task/s, elapsed: 46s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>         ] 360/500, 7.9 task/s, elapsed: 46s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>         ] 361/500, 7.8 task/s, elapsed: 46s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>         ] 362/500, 7.8 task/s, elapsed: 46s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>         ] 363/500, 7.9 task/s, elapsed: 46s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>         ] 364/500, 7.9 task/s, elapsed: 46s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>         ] 365/500, 7.8 task/s, elapsed: 47s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>         ] 366/500, 7.8 task/s, elapsed: 47s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>        ] 367/500, 7.9 task/s, elapsed: 47s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>        ] 368/500, 7.9 task/s, elapsed: 47s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>        ] 369/500, 7.8 task/s, elapsed: 47s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>        ] 370/500, 7.8 task/s, elapsed: 47s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>        ] 371/500, 7.9 task/s, elapsed: 47s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>        ] 372/500, 7.9 task/s, elapsed: 47s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>        ] 373/500, 7.8 task/s, elapsed: 48s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>        ] 374/500, 7.8 task/s, elapsed: 48s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>        ] 375/500, 7.9 task/s, elapsed: 48s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>        ] 376/500, 7.9 task/s, elapsed: 48s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>        ] 377/500, 7.8 task/s, elapsed: 48s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>        ] 378/500, 7.9 task/s, elapsed: 48s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>        ] 379/500, 7.9 task/s, elapsed: 48s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>        ] 380/500, 7.9 task/s, elapsed: 48s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>        ] 381/500, 7.8 task/s, elapsed: 49s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>        ] 382/500, 7.8 task/s, elapsed: 49s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>        ] 383/500, 7.9 task/s, elapsed: 49s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>       ] 384/500, 7.9 task/s, elapsed: 49s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>       ] 385/500, 7.8 task/s, elapsed: 49s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>       ] 386/500, 7.8 task/s, elapsed: 49s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>       ] 387/500, 7.9 task/s, elapsed: 49s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>       ] 388/500, 7.9 task/s, elapsed: 49s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>       ] 389/500, 7.8 task/s, elapsed: 50s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>       ] 390/500, 7.8 task/s, elapsed: 50s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>       ] 391/500, 7.9 task/s, elapsed: 50s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>       ] 392/500, 7.9 task/s, elapsed: 50s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>       ] 393/500, 7.8 task/s, elapsed: 50s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>       ] 394/500, 7.9 task/s, elapsed: 50s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>       ] 395/500, 7.9 task/s, elapsed: 50s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>       ] 396/500, 7.9 task/s, elapsed: 50s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>       ] 397/500, 7.8 task/s, elapsed: 51s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>       ] 398/500, 7.9 task/s, elapsed: 51s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>       ] 399/500, 7.9 task/s, elapsed: 51s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 400/500, 7.9 task/s, elapsed: 51s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 401/500, 7.8 task/s, elapsed: 51s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 402/500, 7.9 task/s, elapsed: 51s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 403/500, 7.9 task/s, elapsed: 51s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 404/500, 7.9 task/s, elapsed: 51s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 405/500, 7.8 task/s, elapsed: 52s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 406/500, 7.9 task/s, elapsed: 52s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 407/500, 7.9 task/s, elapsed: 52s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 408/500, 7.9 task/s, elapsed: 52s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 409/500, 7.8 task/s, elapsed: 52s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 410/500, 7.9 task/s, elapsed: 52s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 411/500, 7.9 task/s, elapsed: 52s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 412/500, 7.9 task/s, elapsed: 52s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 413/500, 7.8 task/s, elapsed: 53s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 414/500, 7.9 task/s, elapsed: 53s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 415/500, 7.9 task/s, elapsed: 53s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 416/500, 7.9 task/s, elapsed: 53s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 417/500, 7.8 task/s, elapsed: 53s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 418/500, 7.9 task/s, elapsed: 53s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 419/500, 7.9 task/s, elapsed: 53s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 420/500, 7.9 task/s, elapsed: 53s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 421/500, 7.8 task/s, elapsed: 54s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 422/500, 7.9 task/s, elapsed: 54s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 423/500, 7.9 task/s, elapsed: 54s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 424/500, 7.9 task/s, elapsed: 54s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 425/500, 7.9 task/s, elapsed: 54s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 426/500, 7.9 task/s, elapsed: 54s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 427/500, 7.9 task/s, elapsed: 54s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 428/500, 7.9 task/s, elapsed: 54s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 429/500, 7.9 task/s, elapsed: 55s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 430/500, 7.9 task/s, elapsed: 55s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 431/500, 7.9 task/s, elapsed: 55s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 432/500, 7.9 task/s, elapsed: 55s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 433/500, 7.9 task/s, elapsed: 55s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 434/500, 7.9 task/s, elapsed: 55s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 435/500, 7.9 task/s, elapsed: 55s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 436/500, 7.9 task/s, elapsed: 55s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 437/500, 7.9 task/s, elapsed: 56s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 438/500, 7.9 task/s, elapsed: 56s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 439/500, 7.9 task/s, elapsed: 56s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 440/500, 7.9 task/s, elapsed: 56s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 441/500, 7.9 task/s, elapsed: 56s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 442/500, 7.9 task/s, elapsed: 56s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 443/500, 7.9 task/s, elapsed: 56s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 444/500, 7.9 task/s, elapsed: 56s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 445/500, 7.9 task/s, elapsed: 57s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 446/500, 7.9 task/s, elapsed: 57s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 447/500, 7.9 task/s, elapsed: 57s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 448/500, 7.9 task/s, elapsed: 57s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 449/500, 7.9 task/s, elapsed: 57s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 450/500, 7.9 task/s, elapsed: 57s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 451/500, 7.9 task/s, elapsed: 57s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 452/500, 7.9 task/s, elapsed: 57s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 453/500, 7.9 task/s, elapsed: 58s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 454/500, 7.9 task/s, elapsed: 58s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 455/500, 7.9 task/s, elapsed: 58s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 456/500, 7.9 task/s, elapsed: 58s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 457/500, 7.9 task/s, elapsed: 58s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 458/500, 7.9 task/s, elapsed: 58s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 459/500, 7.9 task/s, elapsed: 58s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 460/500, 7.9 task/s, elapsed: 58s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 461/500, 7.9 task/s, elapsed: 59s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 462/500, 7.9 task/s, elapsed: 59s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 463/500, 7.9 task/s, elapsed: 59s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 464/500, 7.9 task/s, elapsed: 59s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 465/500, 7.9 task/s, elapsed: 59s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 466/500, 7.9 task/s, elapsed: 59s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 467/500, 7.9 task/s, elapsed: 59s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 468/500, 7.9 task/s, elapsed: 59s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 469/500, 7.9 task/s, elapsed: 60s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 470/500, 7.9 task/s, elapsed: 60s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 471/500, 7.9 task/s, elapsed: 60s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 472/500, 7.9 task/s, elapsed: 60s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 473/500, 7.9 task/s, elapsed: 60s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 474/500, 7.9 task/s, elapsed: 60s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 475/500, 7.9 task/s, elapsed: 60s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 476/500, 7.9 task/s, elapsed: 60s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 477/500, 7.9 task/s, elapsed: 61s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 478/500, 7.9 task/s, elapsed: 61s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 479/500, 7.9 task/s, elapsed: 61s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 480/500, 7.9 task/s, elapsed: 61s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 481/500, 7.9 task/s, elapsed: 61s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 482/500, 7.9 task/s, elapsed: 61s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 483/500, 7.9 task/s, elapsed: 61s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 484/500, 7.9 task/s, elapsed: 61s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 485/500, 7.9 task/s, elapsed: 62s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 486/500, 7.9 task/s, elapsed: 62s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 487/500, 7.9 task/s, elapsed: 62s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 488/500, 7.9 task/s, elapsed: 62s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 489/500, 7.9 task/s, elapsed: 62s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 490/500, 7.9 task/s, elapsed: 62s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 491/500, 7.9 task/s, elapsed: 62s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 492/500, 7.9 task/s, elapsed: 62s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 493/500, 7.9 task/s, elapsed: 63s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 494/500, 7.9 task/s, elapsed: 63s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 495/500, 7.9 task/s, elapsed: 63s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 496/500, 7.9 task/s, elapsed: 63s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 497/500, 7.9 task/s, elapsed: 63s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 498/500, 7.9 task/s, elapsed: 63s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 499/500, 7.9 task/s, elapsed: 63s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 500/500, 7.9 task/s, elapsed: 63s, ETA:     0s

2022-03-23 18:06:49,574 - mmseg - INFO - per class results:
2022-03-23 18:06:49,604 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 97.88 | 98.81 |
|    sidewalk   | 83.56 | 92.02 |
|    building   | 91.71 | 95.91 |
|      wall     |  43.6 | 47.74 |
|     fence     | 56.43 | 66.11 |
|      pole     | 61.64 | 72.62 |
| traffic light | 68.13 | 83.21 |
|  traffic sign | 72.48 | 89.19 |
|   vegetation  | 91.73 | 96.88 |
|    terrain    | 59.46 | 66.55 |
|      sky      | 94.12 |  97.7 |
|     person    | 81.21 | 90.14 |
|     rider     | 62.75 | 79.29 |
|      car      | 94.68 | 97.58 |
|     truck     | 78.73 | 85.08 |
|      bus      | 81.69 |  92.5 |
|     train     |  70.3 | 74.74 |
|   motorcycle  | 65.24 | 75.32 |
|    bicycle    | 76.33 | 87.67 |
+---------------+-------+-------+
2022-03-23 18:06:49,604 - mmseg - INFO - Summary:
2022-03-23 18:06:49,604 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.62 | 75.35 | 83.63 |
+-------+-------+-------+
2022-03-23 18:06:49,607 - mmseg - INFO - Exp name: pprp_deeplabv3_r50-d8_512x1024_40k_cityscapes.py
2022-03-23 18:06:49,607 - mmseg - INFO - Iter(val) [125]	aAcc: 0.9562, mIoU: 0.7535, mAcc: 0.8363, IoU.road: 0.9788, IoU.sidewalk: 0.8356, IoU.building: 0.9171, IoU.wall: 0.4360, IoU.fence: 0.5643, IoU.pole: 0.6164, IoU.traffic light: 0.6813, IoU.traffic sign: 0.7248, IoU.vegetation: 0.9173, IoU.terrain: 0.5946, IoU.sky: 0.9412, IoU.person: 0.8121, IoU.rider: 0.6275, IoU.car: 0.9468, IoU.truck: 0.7873, IoU.bus: 0.8169, IoU.train: 0.7030, IoU.motorcycle: 0.6524, IoU.bicycle: 0.7633, Acc.road: 0.9881, Acc.sidewalk: 0.9202, Acc.building: 0.9591, Acc.wall: 0.4774, Acc.fence: 0.6611, Acc.pole: 0.7262, Acc.traffic light: 0.8321, Acc.traffic sign: 0.8919, Acc.vegetation: 0.9688, Acc.terrain: 0.6655, Acc.sky: 0.9770, Acc.person: 0.9014, Acc.rider: 0.7929, Acc.car: 0.9758, Acc.truck: 0.8508, Acc.bus: 0.9250, Acc.train: 0.7474, Acc.motorcycle: 0.7532, Acc.bicycle: 0.8767
2022-03-23 18:07:39,251 - mmseg - INFO - Iter [44050/50000]	lr: 1.558e-03, eta: 1:57:19, time: 2.257, data_time: 1.272, memory: 19929, decode.loss_ce: 0.1415, decode.acc_seg: 94.7441, aux.loss_ce: 0.0795, aux.acc_seg: 93.1785, loss: 0.2210
2022-03-23 18:08:31,223 - mmseg - INFO - Iter [44100/50000]	lr: 1.547e-03, eta: 1:56:09, time: 1.039, data_time: 0.054, memory: 19929, decode.loss_ce: 0.1388, decode.acc_seg: 94.8918, aux.loss_ce: 0.0754, aux.acc_seg: 93.4855, loss: 0.2142
2022-03-23 18:09:20,813 - mmseg - INFO - Iter [44150/50000]	lr: 1.536e-03, eta: 1:54:57, time: 0.992, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1420, decode.acc_seg: 94.8058, aux.loss_ce: 0.0801, aux.acc_seg: 93.0557, loss: 0.2221
2022-03-23 18:10:10,286 - mmseg - INFO - Iter [44200/50000]	lr: 1.525e-03, eta: 1:53:45, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1433, decode.acc_seg: 94.7696, aux.loss_ce: 0.0821, aux.acc_seg: 93.1358, loss: 0.2254
2022-03-23 18:10:59,611 - mmseg - INFO - Iter [44250/50000]	lr: 1.514e-03, eta: 1:52:33, time: 0.987, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1347, decode.acc_seg: 95.0939, aux.loss_ce: 0.0773, aux.acc_seg: 93.2383, loss: 0.2120
2022-03-23 18:11:49,107 - mmseg - INFO - Iter [44300/50000]	lr: 1.503e-03, eta: 1:51:22, time: 0.990, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1404, decode.acc_seg: 94.8572, aux.loss_ce: 0.0803, aux.acc_seg: 93.2407, loss: 0.2207
2022-03-23 18:12:38,460 - mmseg - INFO - Iter [44350/50000]	lr: 1.491e-03, eta: 1:50:12, time: 0.987, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1347, decode.acc_seg: 95.0307, aux.loss_ce: 0.0760, aux.acc_seg: 93.4168, loss: 0.2108
2022-03-23 18:13:27,998 - mmseg - INFO - Iter [44400/50000]	lr: 1.480e-03, eta: 1:49:02, time: 0.991, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1298, decode.acc_seg: 95.1995, aux.loss_ce: 0.0730, aux.acc_seg: 93.6986, loss: 0.2028
2022-03-23 18:14:17,501 - mmseg - INFO - Iter [44450/50000]	lr: 1.469e-03, eta: 1:47:52, time: 0.990, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1358, decode.acc_seg: 94.9668, aux.loss_ce: 0.0758, aux.acc_seg: 93.4258, loss: 0.2116
2022-03-23 18:15:09,234 - mmseg - INFO - Iter [44500/50000]	lr: 1.458e-03, eta: 1:46:46, time: 1.035, data_time: 0.053, memory: 19929, decode.loss_ce: 0.1296, decode.acc_seg: 95.1929, aux.loss_ce: 0.0758, aux.acc_seg: 93.3699, loss: 0.2054
2022-03-23 18:15:58,721 - mmseg - INFO - Iter [44550/50000]	lr: 1.447e-03, eta: 1:45:37, time: 0.990, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1299, decode.acc_seg: 95.1808, aux.loss_ce: 0.0766, aux.acc_seg: 93.3729, loss: 0.2065
2022-03-23 18:16:48,215 - mmseg - INFO - Iter [44600/50000]	lr: 1.436e-03, eta: 1:44:29, time: 0.990, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1406, decode.acc_seg: 94.9156, aux.loss_ce: 0.0783, aux.acc_seg: 93.3184, loss: 0.2190
2022-03-23 18:17:37,703 - mmseg - INFO - Iter [44650/50000]	lr: 1.425e-03, eta: 1:43:21, time: 0.990, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1387, decode.acc_seg: 94.8126, aux.loss_ce: 0.0787, aux.acc_seg: 93.1193, loss: 0.2173
2022-03-23 18:18:27,109 - mmseg - INFO - Iter [44700/50000]	lr: 1.414e-03, eta: 1:42:13, time: 0.988, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1256, decode.acc_seg: 95.3692, aux.loss_ce: 0.0695, aux.acc_seg: 94.0146, loss: 0.1951
2022-03-23 18:19:16,767 - mmseg - INFO - Iter [44750/50000]	lr: 1.403e-03, eta: 1:41:06, time: 0.993, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1407, decode.acc_seg: 94.7274, aux.loss_ce: 0.0824, aux.acc_seg: 92.7936, loss: 0.2231
2022-03-23 18:20:06,152 - mmseg - INFO - Iter [44800/50000]	lr: 1.391e-03, eta: 1:40:00, time: 0.988, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1405, decode.acc_seg: 94.6563, aux.loss_ce: 0.0820, aux.acc_seg: 92.7924, loss: 0.2224
2022-03-23 18:20:57,880 - mmseg - INFO - Iter [44850/50000]	lr: 1.380e-03, eta: 1:38:55, time: 1.034, data_time: 0.054, memory: 19929, decode.loss_ce: 0.1399, decode.acc_seg: 94.8496, aux.loss_ce: 0.0764, aux.acc_seg: 93.4316, loss: 0.2163
2022-03-23 18:21:47,214 - mmseg - INFO - Iter [44900/50000]	lr: 1.369e-03, eta: 1:37:49, time: 0.987, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1388, decode.acc_seg: 94.8432, aux.loss_ce: 0.0780, aux.acc_seg: 93.1865, loss: 0.2168
2022-03-23 18:22:36,646 - mmseg - INFO - Iter [44950/50000]	lr: 1.358e-03, eta: 1:36:43, time: 0.989, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1395, decode.acc_seg: 94.8950, aux.loss_ce: 0.0800, aux.acc_seg: 93.1699, loss: 0.2195
2022-03-23 18:23:25,943 - mmseg - INFO - Exp name: pprp_deeplabv3_r50-d8_512x1024_40k_cityscapes.py
2022-03-23 18:23:25,943 - mmseg - INFO - Iter [45000/50000]	lr: 1.347e-03, eta: 1:35:38, time: 0.986, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1383, decode.acc_seg: 94.9431, aux.loss_ce: 0.0778, aux.acc_seg: 93.4201, loss: 0.2161
2022-03-23 18:24:15,339 - mmseg - INFO - Iter [45050/50000]	lr: 1.335e-03, eta: 1:34:33, time: 0.988, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1491, decode.acc_seg: 94.5259, aux.loss_ce: 0.0862, aux.acc_seg: 92.6769, loss: 0.2353
2022-03-23 18:25:04,778 - mmseg - INFO - Iter [45100/50000]	lr: 1.324e-03, eta: 1:33:28, time: 0.989, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1350, decode.acc_seg: 94.8991, aux.loss_ce: 0.0796, aux.acc_seg: 92.8514, loss: 0.2147
2022-03-23 18:25:54,320 - mmseg - INFO - Iter [45150/50000]	lr: 1.313e-03, eta: 1:32:23, time: 0.991, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1383, decode.acc_seg: 94.9699, aux.loss_ce: 0.0775, aux.acc_seg: 93.2652, loss: 0.2158
2022-03-23 18:26:43,875 - mmseg - INFO - Iter [45200/50000]	lr: 1.302e-03, eta: 1:31:19, time: 0.991, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1403, decode.acc_seg: 94.9419, aux.loss_ce: 0.0811, aux.acc_seg: 93.1105, loss: 0.2214
2022-03-23 18:27:35,545 - mmseg - INFO - Iter [45250/50000]	lr: 1.290e-03, eta: 1:30:17, time: 1.034, data_time: 0.052, memory: 19929, decode.loss_ce: 0.1433, decode.acc_seg: 94.5906, aux.loss_ce: 0.0821, aux.acc_seg: 92.7212, loss: 0.2255
2022-03-23 18:28:24,878 - mmseg - INFO - Iter [45300/50000]	lr: 1.279e-03, eta: 1:29:13, time: 0.987, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1331, decode.acc_seg: 95.0677, aux.loss_ce: 0.0755, aux.acc_seg: 93.5037, loss: 0.2086
2022-03-23 18:29:14,421 - mmseg - INFO - Iter [45350/50000]	lr: 1.268e-03, eta: 1:28:10, time: 0.991, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1281, decode.acc_seg: 95.2733, aux.loss_ce: 0.0749, aux.acc_seg: 93.4972, loss: 0.2030
2022-03-23 18:30:03,828 - mmseg - INFO - Iter [45400/50000]	lr: 1.256e-03, eta: 1:27:07, time: 0.988, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1295, decode.acc_seg: 95.2477, aux.loss_ce: 0.0735, aux.acc_seg: 93.6930, loss: 0.2030
2022-03-23 18:30:53,189 - mmseg - INFO - Iter [45450/50000]	lr: 1.245e-03, eta: 1:26:04, time: 0.987, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1299, decode.acc_seg: 95.1182, aux.loss_ce: 0.0723, aux.acc_seg: 93.7302, loss: 0.2022
2022-03-23 18:31:42,651 - mmseg - INFO - Iter [45500/50000]	lr: 1.234e-03, eta: 1:25:01, time: 0.989, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1336, decode.acc_seg: 94.9603, aux.loss_ce: 0.0775, aux.acc_seg: 93.1712, loss: 0.2111
2022-03-23 18:32:32,154 - mmseg - INFO - Iter [45550/50000]	lr: 1.222e-03, eta: 1:23:58, time: 0.990, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1387, decode.acc_seg: 94.7844, aux.loss_ce: 0.0740, aux.acc_seg: 93.4915, loss: 0.2127
2022-03-23 18:33:24,066 - mmseg - INFO - Iter [45600/50000]	lr: 1.211e-03, eta: 1:22:58, time: 1.038, data_time: 0.056, memory: 19929, decode.loss_ce: 0.1322, decode.acc_seg: 95.1595, aux.loss_ce: 0.0757, aux.acc_seg: 93.4077, loss: 0.2079
2022-03-23 18:34:13,683 - mmseg - INFO - Iter [45650/50000]	lr: 1.200e-03, eta: 1:21:56, time: 0.992, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1307, decode.acc_seg: 95.1052, aux.loss_ce: 0.0733, aux.acc_seg: 93.6407, loss: 0.2040
2022-03-23 18:35:03,053 - mmseg - INFO - Iter [45700/50000]	lr: 1.188e-03, eta: 1:20:54, time: 0.987, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1402, decode.acc_seg: 94.8451, aux.loss_ce: 0.0806, aux.acc_seg: 93.0797, loss: 0.2207
2022-03-23 18:35:52,565 - mmseg - INFO - Iter [45750/50000]	lr: 1.177e-03, eta: 1:19:53, time: 0.990, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1395, decode.acc_seg: 94.8970, aux.loss_ce: 0.0793, aux.acc_seg: 93.1729, loss: 0.2188
2022-03-23 18:36:42,095 - mmseg - INFO - Iter [45800/50000]	lr: 1.166e-03, eta: 1:18:51, time: 0.991, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1388, decode.acc_seg: 94.8851, aux.loss_ce: 0.0807, aux.acc_seg: 92.9668, loss: 0.2195
2022-03-23 18:37:31,571 - mmseg - INFO - Iter [45850/50000]	lr: 1.154e-03, eta: 1:17:50, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1578, decode.acc_seg: 94.3463, aux.loss_ce: 0.0896, aux.acc_seg: 92.5177, loss: 0.2474
2022-03-23 18:38:21,016 - mmseg - INFO - Iter [45900/50000]	lr: 1.143e-03, eta: 1:16:49, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1353, decode.acc_seg: 94.9560, aux.loss_ce: 0.0801, aux.acc_seg: 92.9386, loss: 0.2154
2022-03-23 18:39:10,546 - mmseg - INFO - Iter [45950/50000]	lr: 1.131e-03, eta: 1:15:48, time: 0.991, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1501, decode.acc_seg: 94.6643, aux.loss_ce: 0.0834, aux.acc_seg: 92.8730, loss: 0.2335
2022-03-23 18:40:02,443 - mmseg - INFO - Exp name: pprp_deeplabv3_r50-d8_512x1024_40k_cityscapes.py
2022-03-23 18:40:02,443 - mmseg - INFO - Iter [46000/50000]	lr: 1.120e-03, eta: 1:14:49, time: 1.038, data_time: 0.058, memory: 19929, decode.loss_ce: 0.1308, decode.acc_seg: 95.1885, aux.loss_ce: 0.0753, aux.acc_seg: 93.6524, loss: 0.2061
2022-03-23 18:40:51,806 - mmseg - INFO - Iter [46050/50000]	lr: 1.108e-03, eta: 1:13:49, time: 0.987, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1378, decode.acc_seg: 94.9262, aux.loss_ce: 0.0791, aux.acc_seg: 93.1269, loss: 0.2169
2022-03-23 18:41:41,308 - mmseg - INFO - Iter [46100/50000]	lr: 1.097e-03, eta: 1:12:49, time: 0.990, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1327, decode.acc_seg: 95.1498, aux.loss_ce: 0.0747, aux.acc_seg: 93.6576, loss: 0.2074
2022-03-23 18:42:30,786 - mmseg - INFO - Iter [46150/50000]	lr: 1.085e-03, eta: 1:11:48, time: 0.990, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1367, decode.acc_seg: 94.9434, aux.loss_ce: 0.0800, aux.acc_seg: 93.0457, loss: 0.2166
2022-03-23 18:43:20,347 - mmseg - INFO - Iter [46200/50000]	lr: 1.074e-03, eta: 1:10:49, time: 0.991, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1331, decode.acc_seg: 95.1182, aux.loss_ce: 0.0776, aux.acc_seg: 93.2009, loss: 0.2107
2022-03-23 18:44:09,792 - mmseg - INFO - Iter [46250/50000]	lr: 1.062e-03, eta: 1:09:49, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1312, decode.acc_seg: 95.1365, aux.loss_ce: 0.0722, aux.acc_seg: 93.6118, loss: 0.2033
2022-03-23 18:44:59,169 - mmseg - INFO - Iter [46300/50000]	lr: 1.051e-03, eta: 1:08:49, time: 0.988, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1319, decode.acc_seg: 95.0740, aux.loss_ce: 0.0749, aux.acc_seg: 93.3916, loss: 0.2068
2022-03-23 18:45:50,653 - mmseg - INFO - Iter [46350/50000]	lr: 1.039e-03, eta: 1:07:51, time: 1.030, data_time: 0.054, memory: 19929, decode.loss_ce: 0.1310, decode.acc_seg: 95.2915, aux.loss_ce: 0.0736, aux.acc_seg: 93.7891, loss: 0.2046
2022-03-23 18:46:40,064 - mmseg - INFO - Iter [46400/50000]	lr: 1.028e-03, eta: 1:06:51, time: 0.988, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1305, decode.acc_seg: 95.1716, aux.loss_ce: 0.0726, aux.acc_seg: 93.5523, loss: 0.2031
2022-03-23 18:47:29,496 - mmseg - INFO - Iter [46450/50000]	lr: 1.016e-03, eta: 1:05:52, time: 0.989, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1337, decode.acc_seg: 95.1720, aux.loss_ce: 0.0812, aux.acc_seg: 93.0675, loss: 0.2149
2022-03-23 18:48:19,061 - mmseg - INFO - Iter [46500/50000]	lr: 1.004e-03, eta: 1:04:53, time: 0.991, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1335, decode.acc_seg: 95.0381, aux.loss_ce: 0.0761, aux.acc_seg: 93.3923, loss: 0.2096
2022-03-23 18:49:08,527 - mmseg - INFO - Iter [46550/50000]	lr: 9.927e-04, eta: 1:03:54, time: 0.989, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1355, decode.acc_seg: 95.0785, aux.loss_ce: 0.0817, aux.acc_seg: 93.1459, loss: 0.2173
2022-03-23 18:49:57,853 - mmseg - INFO - Iter [46600/50000]	lr: 9.811e-04, eta: 1:02:56, time: 0.987, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1279, decode.acc_seg: 95.2948, aux.loss_ce: 0.0720, aux.acc_seg: 93.8563, loss: 0.2000
2022-03-23 18:50:47,238 - mmseg - INFO - Iter [46650/50000]	lr: 9.694e-04, eta: 1:01:57, time: 0.988, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1374, decode.acc_seg: 94.8390, aux.loss_ce: 0.0801, aux.acc_seg: 93.0956, loss: 0.2175
2022-03-23 18:51:39,329 - mmseg - INFO - Iter [46700/50000]	lr: 9.577e-04, eta: 1:01:00, time: 1.042, data_time: 0.055, memory: 19929, decode.loss_ce: 0.1422, decode.acc_seg: 94.8843, aux.loss_ce: 0.0792, aux.acc_seg: 93.1944, loss: 0.2214
2022-03-23 18:52:28,733 - mmseg - INFO - Iter [46750/50000]	lr: 9.460e-04, eta: 1:00:01, time: 0.988, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1381, decode.acc_seg: 94.8477, aux.loss_ce: 0.0792, aux.acc_seg: 93.2359, loss: 0.2173
2022-03-23 18:53:18,048 - mmseg - INFO - Iter [46800/50000]	lr: 9.343e-04, eta: 0:59:03, time: 0.986, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1376, decode.acc_seg: 95.0238, aux.loss_ce: 0.0788, aux.acc_seg: 93.2673, loss: 0.2164
2022-03-23 18:54:07,558 - mmseg - INFO - Iter [46850/50000]	lr: 9.226e-04, eta: 0:58:05, time: 0.990, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1389, decode.acc_seg: 94.8716, aux.loss_ce: 0.0798, aux.acc_seg: 92.9443, loss: 0.2187
2022-03-23 18:54:57,189 - mmseg - INFO - Iter [46900/50000]	lr: 9.108e-04, eta: 0:57:07, time: 0.992, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1399, decode.acc_seg: 94.9326, aux.loss_ce: 0.0789, aux.acc_seg: 93.1241, loss: 0.2188
2022-03-23 18:55:46,678 - mmseg - INFO - Iter [46950/50000]	lr: 8.990e-04, eta: 0:56:09, time: 0.990, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1271, decode.acc_seg: 95.2790, aux.loss_ce: 0.0718, aux.acc_seg: 93.8022, loss: 0.1988
2022-03-23 18:56:36,158 - mmseg - INFO - Exp name: pprp_deeplabv3_r50-d8_512x1024_40k_cityscapes.py
2022-03-23 18:56:36,158 - mmseg - INFO - Iter [47000/50000]	lr: 8.872e-04, eta: 0:55:12, time: 0.990, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1314, decode.acc_seg: 95.1165, aux.loss_ce: 0.0781, aux.acc_seg: 93.2088, loss: 0.2095
2022-03-23 18:57:25,720 - mmseg - INFO - Iter [47050/50000]	lr: 8.754e-04, eta: 0:54:14, time: 0.991, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1298, decode.acc_seg: 95.2112, aux.loss_ce: 0.0740, aux.acc_seg: 93.4734, loss: 0.2038
2022-03-23 18:58:17,574 - mmseg - INFO - Iter [47100/50000]	lr: 8.636e-04, eta: 0:53:18, time: 1.037, data_time: 0.054, memory: 19929, decode.loss_ce: 0.1306, decode.acc_seg: 95.1828, aux.loss_ce: 0.0783, aux.acc_seg: 93.0850, loss: 0.2088
2022-03-23 18:59:07,057 - mmseg - INFO - Iter [47150/50000]	lr: 8.517e-04, eta: 0:52:20, time: 0.990, data_time: 0.009, memory: 19929, decode.loss_ce: 0.1312, decode.acc_seg: 95.1522, aux.loss_ce: 0.0788, aux.acc_seg: 93.1552, loss: 0.2100
2022-03-23 18:59:56,655 - mmseg - INFO - Iter [47200/50000]	lr: 8.399e-04, eta: 0:51:23, time: 0.992, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1289, decode.acc_seg: 95.2951, aux.loss_ce: 0.0739, aux.acc_seg: 93.7241, loss: 0.2027
2022-03-23 19:00:46,208 - mmseg - INFO - Iter [47250/50000]	lr: 8.280e-04, eta: 0:50:26, time: 0.991, data_time: 0.009, memory: 19929, decode.loss_ce: 0.1284, decode.acc_seg: 95.3024, aux.loss_ce: 0.0748, aux.acc_seg: 93.6926, loss: 0.2032
2022-03-23 19:01:35,845 - mmseg - INFO - Iter [47300/50000]	lr: 8.160e-04, eta: 0:49:29, time: 0.993, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1362, decode.acc_seg: 95.0290, aux.loss_ce: 0.0780, aux.acc_seg: 93.3083, loss: 0.2141
2022-03-23 19:02:25,325 - mmseg - INFO - Iter [47350/50000]	lr: 8.041e-04, eta: 0:48:32, time: 0.990, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1282, decode.acc_seg: 95.2978, aux.loss_ce: 0.0750, aux.acc_seg: 93.5744, loss: 0.2033
2022-03-23 19:03:14,713 - mmseg - INFO - Iter [47400/50000]	lr: 7.921e-04, eta: 0:47:35, time: 0.988, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1262, decode.acc_seg: 95.3455, aux.loss_ce: 0.0739, aux.acc_seg: 93.6338, loss: 0.2001
2022-03-23 19:04:06,500 - mmseg - INFO - Iter [47450/50000]	lr: 7.801e-04, eta: 0:46:39, time: 1.036, data_time: 0.055, memory: 19929, decode.loss_ce: 0.1290, decode.acc_seg: 95.2065, aux.loss_ce: 0.0754, aux.acc_seg: 93.3433, loss: 0.2044
2022-03-23 19:04:55,854 - mmseg - INFO - Iter [47500/50000]	lr: 7.681e-04, eta: 0:45:42, time: 0.987, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1263, decode.acc_seg: 95.2793, aux.loss_ce: 0.0699, aux.acc_seg: 93.7946, loss: 0.1962
2022-03-23 19:05:45,258 - mmseg - INFO - Iter [47550/50000]	lr: 7.561e-04, eta: 0:44:46, time: 0.988, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1378, decode.acc_seg: 95.0900, aux.loss_ce: 0.0773, aux.acc_seg: 93.4268, loss: 0.2151
2022-03-23 19:06:34,835 - mmseg - INFO - Iter [47600/50000]	lr: 7.440e-04, eta: 0:43:49, time: 0.992, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1327, decode.acc_seg: 95.0000, aux.loss_ce: 0.0737, aux.acc_seg: 93.5633, loss: 0.2065
2022-03-23 19:07:24,470 - mmseg - INFO - Iter [47650/50000]	lr: 7.320e-04, eta: 0:42:53, time: 0.993, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1329, decode.acc_seg: 95.0302, aux.loss_ce: 0.0755, aux.acc_seg: 93.4672, loss: 0.2084
2022-03-23 19:08:14,092 - mmseg - INFO - Iter [47700/50000]	lr: 7.199e-04, eta: 0:41:56, time: 0.992, data_time: 0.009, memory: 19929, decode.loss_ce: 0.1381, decode.acc_seg: 94.8240, aux.loss_ce: 0.0784, aux.acc_seg: 93.2297, loss: 0.2165
2022-03-23 19:09:04,148 - mmseg - INFO - Iter [47750/50000]	lr: 7.077e-04, eta: 0:41:00, time: 1.001, data_time: 0.009, memory: 19929, decode.loss_ce: 0.1266, decode.acc_seg: 95.2934, aux.loss_ce: 0.0730, aux.acc_seg: 93.5863, loss: 0.1997
2022-03-23 19:09:53,644 - mmseg - INFO - Iter [47800/50000]	lr: 6.956e-04, eta: 0:40:04, time: 0.989, data_time: 0.009, memory: 19929, decode.loss_ce: 0.1232, decode.acc_seg: 95.4008, aux.loss_ce: 0.0736, aux.acc_seg: 93.5763, loss: 0.1967
2022-03-23 19:10:45,508 - mmseg - INFO - Iter [47850/50000]	lr: 6.834e-04, eta: 0:39:09, time: 1.038, data_time: 0.056, memory: 19929, decode.loss_ce: 0.1290, decode.acc_seg: 95.2851, aux.loss_ce: 0.0740, aux.acc_seg: 93.7449, loss: 0.2029
2022-03-23 19:11:35,168 - mmseg - INFO - Iter [47900/50000]	lr: 6.711e-04, eta: 0:38:13, time: 0.993, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1308, decode.acc_seg: 95.1716, aux.loss_ce: 0.0767, aux.acc_seg: 93.4767, loss: 0.2075
2022-03-23 19:12:24,797 - mmseg - INFO - Iter [47950/50000]	lr: 6.589e-04, eta: 0:37:17, time: 0.993, data_time: 0.009, memory: 19929, decode.loss_ce: 0.1266, decode.acc_seg: 95.3568, aux.loss_ce: 0.0771, aux.acc_seg: 93.3497, loss: 0.2037
2022-03-23 19:13:14,351 - mmseg - INFO - Saving checkpoint at 48000 iterations
2022-03-23 19:13:15,775 - mmseg - INFO - Exp name: pprp_deeplabv3_r50-d8_512x1024_40k_cityscapes.py
2022-03-23 19:13:15,775 - mmseg - INFO - Iter [48000/50000]	lr: 6.466e-04, eta: 0:36:22, time: 1.020, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1312, decode.acc_seg: 95.0865, aux.loss_ce: 0.0730, aux.acc_seg: 93.6792, loss: 0.2042
[                                                  ] 0/500, elapsed: 0s, ETA:[                                 ] 1/500, 1.3 task/s, elapsed: 1s, ETA:   373s[                                 ] 2/500, 2.7 task/s, elapsed: 1s, ETA:   186s[                                 ] 3/500, 4.0 task/s, elapsed: 1s, ETA:   124s[                                 ] 4/500, 5.3 task/s, elapsed: 1s, ETA:    93s[                                 ] 5/500, 3.8 task/s, elapsed: 1s, ETA:   130s[                                 ] 6/500, 4.6 task/s, elapsed: 1s, ETA:   108s[                                 ] 7/500, 5.3 task/s, elapsed: 1s, ETA:    92s[                                 ] 8/500, 6.1 task/s, elapsed: 1s, ETA:    80s[                                 ] 9/500, 5.0 task/s, elapsed: 2s, ETA:    99s[                                ] 10/500, 5.5 task/s, elapsed: 2s, ETA:    89s[                                ] 11/500, 6.1 task/s, elapsed: 2s, ETA:    80s[                                ] 12/500, 6.6 task/s, elapsed: 2s, ETA:    73s[                                ] 13/500, 5.7 task/s, elapsed: 2s, ETA:    86s[                                ] 14/500, 6.1 task/s, elapsed: 2s, ETA:    80s[                                ] 15/500, 6.5 task/s, elapsed: 2s, ETA:    74s[>                               ] 16/500, 7.0 task/s, elapsed: 2s, ETA:    70s[>                               ] 17/500, 5.9 task/s, elapsed: 3s, ETA:    82s[>                               ] 18/500, 6.3 task/s, elapsed: 3s, ETA:    77s[>                               ] 19/500, 6.6 task/s, elapsed: 3s, ETA:    73s[>                               ] 20/500, 7.0 task/s, elapsed: 3s, ETA:    69s[>                               ] 21/500, 6.2 task/s, elapsed: 3s, ETA:    77s[>                               ] 22/500, 6.5 task/s, elapsed: 3s, ETA:    74s[>                               ] 23/500, 6.8 task/s, elapsed: 3s, ETA:    70s[>                               ] 24/500, 7.1 task/s, elapsed: 3s, ETA:    67s[>                               ] 25/500, 6.4 task/s, elapsed: 4s, ETA:    74s[>                               ] 26/500, 6.7 task/s, elapsed: 4s, ETA:    71s[>                               ] 27/500, 6.9 task/s, elapsed: 4s, ETA:    68s[>                               ] 28/500, 7.2 task/s, elapsed: 4s, ETA:    66s[>                               ] 29/500, 6.6 task/s, elapsed: 4s, ETA:    71s[>                               ] 30/500, 6.8 task/s, elapsed: 4s, ETA:    69s[>                               ] 31/500, 7.1 task/s, elapsed: 4s, ETA:    66s[>>                              ] 32/500, 7.3 task/s, elapsed: 4s, ETA:    64s[>>                              ] 33/500, 6.7 task/s, elapsed: 5s, ETA:    69s[>>                              ] 34/500, 6.9 task/s, elapsed: 5s, ETA:    67s[>>                              ] 35/500, 7.2 task/s, elapsed: 5s, ETA:    65s[>>                              ] 36/500, 7.4 task/s, elapsed: 5s, ETA:    63s[>>                              ] 37/500, 6.9 task/s, elapsed: 5s, ETA:    68s[>>                              ] 38/500, 7.0 task/s, elapsed: 5s, ETA:    66s[>>                              ] 39/500, 7.2 task/s, elapsed: 5s, ETA:    64s[>>                              ] 40/500, 7.4 task/s, elapsed: 5s, ETA:    62s[>>                              ] 41/500, 7.0 task/s, elapsed: 6s, ETA:    66s[>>                              ] 42/500, 7.1 task/s, elapsed: 6s, ETA:    64s[>>                              ] 43/500, 7.3 task/s, elapsed: 6s, ETA:    63s[>>                              ] 44/500, 7.5 task/s, elapsed: 6s, ETA:    61s[>>                              ] 45/500, 7.0 task/s, elapsed: 6s, ETA:    65s[>>                              ] 46/500, 7.2 task/s, elapsed: 6s, ETA:    63s[>>>                             ] 47/500, 7.3 task/s, elapsed: 6s, ETA:    62s[>>>                             ] 48/500, 7.5 task/s, elapsed: 6s, ETA:    60s[>>>                             ] 49/500, 7.1 task/s, elapsed: 7s, ETA:    63s[>>>                             ] 50/500, 7.3 task/s, elapsed: 7s, ETA:    62s[>>>                             ] 51/500, 7.4 task/s, elapsed: 7s, ETA:    61s[>>>                             ] 52/500, 7.5 task/s, elapsed: 7s, ETA:    59s[>>>                             ] 53/500, 7.1 task/s, elapsed: 7s, ETA:    63s[>>>                             ] 54/500, 7.3 task/s, elapsed: 7s, ETA:    61s[>>>                             ] 55/500, 7.4 task/s, elapsed: 7s, ETA:    60s[>>>                             ] 56/500, 7.5 task/s, elapsed: 7s, ETA:    59s[>>>                             ] 57/500, 7.2 task/s, elapsed: 8s, ETA:    62s[>>>                             ] 58/500, 7.3 task/s, elapsed: 8s, ETA:    60s[>>>                             ] 59/500, 7.5 task/s, elapsed: 8s, ETA:    59s[>>>                             ] 60/500, 7.6 task/s, elapsed: 8s, ETA:    58s[>>>                             ] 61/500, 7.3 task/s, elapsed: 8s, ETA:    61s[>>>                             ] 62/500, 7.4 task/s, elapsed: 8s, ETA:    59s[>>>>                            ] 63/500, 7.5 task/s, elapsed: 8s, ETA:    58s[>>>>                            ] 64/500, 7.6 task/s, elapsed: 8s, ETA:    57s[>>>>                            ] 65/500, 7.3 task/s, elapsed: 9s, ETA:    60s[>>>>                            ] 66/500, 7.4 task/s, elapsed: 9s, ETA:    59s[>>>>                            ] 67/500, 7.5 task/s, elapsed: 9s, ETA:    58s[>>>>                            ] 68/500, 7.6 task/s, elapsed: 9s, ETA:    57s[>>>>                            ] 69/500, 7.3 task/s, elapsed: 9s, ETA:    59s[>>>>                            ] 70/500, 7.4 task/s, elapsed: 9s, ETA:    58s[>>>>                            ] 71/500, 7.5 task/s, elapsed: 9s, ETA:    57s[>>>>                            ] 72/500, 7.6 task/s, elapsed: 9s, ETA:    56s[>>>>                           ] 73/500, 7.3 task/s, elapsed: 10s, ETA:    58s[>>>>                           ] 74/500, 7.4 task/s, elapsed: 10s, ETA:    57s[>>>>                           ] 75/500, 7.5 task/s, elapsed: 10s, ETA:    56s[>>>>                           ] 76/500, 7.6 task/s, elapsed: 10s, ETA:    55s[>>>>                           ] 77/500, 7.4 task/s, elapsed: 10s, ETA:    57s[>>>>                           ] 78/500, 7.5 task/s, elapsed: 10s, ETA:    56s[>>>>                           ] 79/500, 7.6 task/s, elapsed: 10s, ETA:    56s[>>>>                           ] 80/500, 7.7 task/s, elapsed: 10s, ETA:    55s[>>>>>                          ] 81/500, 7.4 task/s, elapsed: 11s, ETA:    57s[>>>>>                          ] 82/500, 7.5 task/s, elapsed: 11s, ETA:    56s[>>>>>                          ] 83/500, 7.6 task/s, elapsed: 11s, ETA:    55s[>>>>>                          ] 84/500, 7.7 task/s, elapsed: 11s, ETA:    54s[>>>>>                          ] 85/500, 7.4 task/s, elapsed: 11s, ETA:    56s[>>>>>                          ] 86/500, 7.5 task/s, elapsed: 11s, ETA:    55s[>>>>>                          ] 87/500, 7.6 task/s, elapsed: 11s, ETA:    54s[>>>>>                          ] 88/500, 7.7 task/s, elapsed: 11s, ETA:    54s[>>>>>                          ] 89/500, 7.4 task/s, elapsed: 12s, ETA:    55s[>>>>>                          ] 90/500, 7.5 task/s, elapsed: 12s, ETA:    54s[>>>>>                          ] 91/500, 7.6 task/s, elapsed: 12s, ETA:    54s[>>>>>                          ] 92/500, 7.7 task/s, elapsed: 12s, ETA:    53s[>>>>>                          ] 93/500, 7.5 task/s, elapsed: 12s, ETA:    54s[>>>>>                          ] 94/500, 7.6 task/s, elapsed: 12s, ETA:    54s[>>>>>                          ] 95/500, 7.6 task/s, elapsed: 12s, ETA:    53s[>>>>>                          ] 96/500, 7.7 task/s, elapsed: 12s, ETA:    52s[>>>>>>                         ] 97/500, 7.5 task/s, elapsed: 13s, ETA:    54s[>>>>>>                         ] 98/500, 7.6 task/s, elapsed: 13s, ETA:    53s[>>>>>>                         ] 99/500, 7.7 task/s, elapsed: 13s, ETA:    52s[>>>>>>                        ] 100/500, 7.7 task/s, elapsed: 13s, ETA:    52s[>>>>>>                        ] 101/500, 7.5 task/s, elapsed: 13s, ETA:    53s[>>>>>>                        ] 102/500, 7.6 task/s, elapsed: 13s, ETA:    52s[>>>>>>                        ] 103/500, 7.7 task/s, elapsed: 13s, ETA:    52s[>>>>>>                        ] 104/500, 7.7 task/s, elapsed: 13s, ETA:    51s[>>>>>>                        ] 105/500, 7.5 task/s, elapsed: 14s, ETA:    52s[>>>>>>                        ] 106/500, 7.6 task/s, elapsed: 14s, ETA:    52s[>>>>>>                        ] 107/500, 7.7 task/s, elapsed: 14s, ETA:    51s[>>>>>>                        ] 108/500, 7.7 task/s, elapsed: 14s, ETA:    51s[>>>>>>                        ] 109/500, 7.5 task/s, elapsed: 14s, ETA:    52s[>>>>>>                        ] 110/500, 7.6 task/s, elapsed: 14s, ETA:    51s[>>>>>>                        ] 111/500, 7.7 task/s, elapsed: 14s, ETA:    51s[>>>>>>                        ] 112/500, 7.8 task/s, elapsed: 14s, ETA:    50s[>>>>>>                        ] 113/500, 7.6 task/s, elapsed: 15s, ETA:    51s[>>>>>>                        ] 114/500, 7.6 task/s, elapsed: 15s, ETA:    51s[>>>>>>                        ] 115/500, 7.7 task/s, elapsed: 15s, ETA:    50s[>>>>>>                        ] 116/500, 7.8 task/s, elapsed: 15s, ETA:    49s[>>>>>>>                       ] 117/500, 7.6 task/s, elapsed: 15s, ETA:    51s[>>>>>>>                       ] 118/500, 7.6 task/s, elapsed: 15s, ETA:    50s[>>>>>>>                       ] 119/500, 7.7 task/s, elapsed: 15s, ETA:    49s[>>>>>>>                       ] 120/500, 7.8 task/s, elapsed: 15s, ETA:    49s[>>>>>>>                       ] 121/500, 7.6 task/s, elapsed: 16s, ETA:    50s[>>>>>>>                       ] 122/500, 7.7 task/s, elapsed: 16s, ETA:    49s[>>>>>>>                       ] 123/500, 7.7 task/s, elapsed: 16s, ETA:    49s[>>>>>>>                       ] 124/500, 7.8 task/s, elapsed: 16s, ETA:    48s[>>>>>>>                       ] 125/500, 7.6 task/s, elapsed: 16s, ETA:    49s[>>>>>>>                       ] 126/500, 7.7 task/s, elapsed: 16s, ETA:    49s[>>>>>>>                       ] 127/500, 7.7 task/s, elapsed: 16s, ETA:    48s[>>>>>>>                       ] 128/500, 7.8 task/s, elapsed: 16s, ETA:    48s[>>>>>>>                       ] 129/500, 7.6 task/s, elapsed: 17s, ETA:    49s[>>>>>>>                       ] 130/500, 7.7 task/s, elapsed: 17s, ETA:    48s[>>>>>>>                       ] 131/500, 7.7 task/s, elapsed: 17s, ETA:    48s[>>>>>>>                       ] 132/500, 7.8 task/s, elapsed: 17s, ETA:    47s[>>>>>>>                       ] 133/500, 7.6 task/s, elapsed: 17s, ETA:    48s[>>>>>>>>                      ] 134/500, 7.7 task/s, elapsed: 17s, ETA:    48s[>>>>>>>>                      ] 135/500, 7.7 task/s, elapsed: 17s, ETA:    47s[>>>>>>>>                      ] 136/500, 7.8 task/s, elapsed: 17s, ETA:    47s[>>>>>>>>                      ] 137/500, 7.6 task/s, elapsed: 18s, ETA:    48s[>>>>>>>>                      ] 138/500, 7.7 task/s, elapsed: 18s, ETA:    47s[>>>>>>>>                      ] 139/500, 7.7 task/s, elapsed: 18s, ETA:    47s[>>>>>>>>                      ] 140/500, 7.8 task/s, elapsed: 18s, ETA:    46s[>>>>>>>>                      ] 141/500, 7.6 task/s, elapsed: 18s, ETA:    47s[>>>>>>>>                      ] 142/500, 7.7 task/s, elapsed: 18s, ETA:    46s[>>>>>>>>                      ] 143/500, 7.8 task/s, elapsed: 18s, ETA:    46s[>>>>>>>>                      ] 144/500, 7.8 task/s, elapsed: 18s, ETA:    46s[>>>>>>>>                      ] 145/500, 7.7 task/s, elapsed: 19s, ETA:    46s[>>>>>>>>                      ] 146/500, 7.7 task/s, elapsed: 19s, ETA:    46s[>>>>>>>>                      ] 147/500, 7.8 task/s, elapsed: 19s, ETA:    45s[>>>>>>>>                      ] 148/500, 7.8 task/s, elapsed: 19s, ETA:    45s[>>>>>>>>                      ] 149/500, 7.7 task/s, elapsed: 19s, ETA:    46s[>>>>>>>>>                     ] 150/500, 7.7 task/s, elapsed: 19s, ETA:    45s[>>>>>>>>>                     ] 151/500, 7.8 task/s, elapsed: 19s, ETA:    45s[>>>>>>>>>                     ] 152/500, 7.8 task/s, elapsed: 19s, ETA:    44s[>>>>>>>>>                     ] 153/500, 7.7 task/s, elapsed: 20s, ETA:    45s[>>>>>>>>>                     ] 154/500, 7.7 task/s, elapsed: 20s, ETA:    45s[>>>>>>>>>                     ] 155/500, 7.8 task/s, elapsed: 20s, ETA:    44s[>>>>>>>>>                     ] 156/500, 7.8 task/s, elapsed: 20s, ETA:    44s[>>>>>>>>>                     ] 157/500, 7.7 task/s, elapsed: 20s, ETA:    45s[>>>>>>>>>                     ] 158/500, 7.7 task/s, elapsed: 20s, ETA:    44s[>>>>>>>>>                     ] 159/500, 7.8 task/s, elapsed: 20s, ETA:    44s[>>>>>>>>>                     ] 160/500, 7.8 task/s, elapsed: 20s, ETA:    43s[>>>>>>>>>                     ] 161/500, 7.7 task/s, elapsed: 21s, ETA:    44s[>>>>>>>>>                     ] 162/500, 7.8 task/s, elapsed: 21s, ETA:    44s[>>>>>>>>>                     ] 163/500, 7.8 task/s, elapsed: 21s, ETA:    43s[>>>>>>>>>                     ] 164/500, 7.8 task/s, elapsed: 21s, ETA:    43s[>>>>>>>>>                     ] 165/500, 7.7 task/s, elapsed: 21s, ETA:    43s[>>>>>>>>>                     ] 166/500, 7.8 task/s, elapsed: 21s, ETA:    43s[>>>>>>>>>>                    ] 167/500, 7.8 task/s, elapsed: 21s, ETA:    43s[>>>>>>>>>>                    ] 168/500, 7.9 task/s, elapsed: 21s, ETA:    42s[>>>>>>>>>>                    ] 169/500, 7.7 task/s, elapsed: 22s, ETA:    43s[>>>>>>>>>>                    ] 170/500, 7.8 task/s, elapsed: 22s, ETA:    42s[>>>>>>>>>>                    ] 171/500, 7.8 task/s, elapsed: 22s, ETA:    42s[>>>>>>>>>>                    ] 172/500, 7.9 task/s, elapsed: 22s, ETA:    42s[>>>>>>>>>>                    ] 173/500, 7.7 task/s, elapsed: 22s, ETA:    42s[>>>>>>>>>>                    ] 174/500, 7.8 task/s, elapsed: 22s, ETA:    42s[>>>>>>>>>>                    ] 175/500, 7.8 task/s, elapsed: 22s, ETA:    42s[>>>>>>>>>>                    ] 176/500, 7.9 task/s, elapsed: 22s, ETA:    41s[>>>>>>>>>>                    ] 177/500, 7.7 task/s, elapsed: 23s, ETA:    42s[>>>>>>>>>>                    ] 178/500, 7.8 task/s, elapsed: 23s, ETA:    41s[>>>>>>>>>>                    ] 179/500, 7.8 task/s, elapsed: 23s, ETA:    41s[>>>>>>>>>>                    ] 180/500, 7.9 task/s, elapsed: 23s, ETA:    41s[>>>>>>>>>>                    ] 181/500, 7.8 task/s, elapsed: 23s, ETA:    41s[>>>>>>>>>>                    ] 182/500, 7.8 task/s, elapsed: 23s, ETA:    41s[>>>>>>>>>>                    ] 183/500, 7.8 task/s, elapsed: 23s, ETA:    40s[>>>>>>>>>>>                   ] 184/500, 7.9 task/s, elapsed: 23s, ETA:    40s[>>>>>>>>>>>                   ] 185/500, 7.8 task/s, elapsed: 24s, ETA:    41s[>>>>>>>>>>>                   ] 186/500, 7.8 task/s, elapsed: 24s, ETA:    40s[>>>>>>>>>>>                   ] 187/500, 7.8 task/s, elapsed: 24s, ETA:    40s[>>>>>>>>>>>                   ] 188/500, 7.9 task/s, elapsed: 24s, ETA:    40s[>>>>>>>>>>>                   ] 189/500, 7.8 task/s, elapsed: 24s, ETA:    40s[>>>>>>>>>>>                   ] 190/500, 7.8 task/s, elapsed: 24s, ETA:    40s[>>>>>>>>>>>                   ] 191/500, 7.8 task/s, elapsed: 24s, ETA:    39s[>>>>>>>>>>>                   ] 192/500, 7.9 task/s, elapsed: 24s, ETA:    39s[>>>>>>>>>>>                   ] 193/500, 7.8 task/s, elapsed: 25s, ETA:    40s[>>>>>>>>>>>                   ] 194/500, 7.8 task/s, elapsed: 25s, ETA:    39s[>>>>>>>>>>>                   ] 195/500, 7.9 task/s, elapsed: 25s, ETA:    39s[>>>>>>>>>>>                   ] 196/500, 7.9 task/s, elapsed: 25s, ETA:    39s[>>>>>>>>>>>                   ] 197/500, 7.8 task/s, elapsed: 25s, ETA:    39s[>>>>>>>>>>>                   ] 198/500, 7.8 task/s, elapsed: 25s, ETA:    39s[>>>>>>>>>>>                   ] 199/500, 7.9 task/s, elapsed: 25s, ETA:    38s[>>>>>>>>>>>>                  ] 200/500, 7.9 task/s, elapsed: 25s, ETA:    38s[>>>>>>>>>>>>                  ] 201/500, 7.8 task/s, elapsed: 26s, ETA:    38s[>>>>>>>>>>>>                  ] 202/500, 7.8 task/s, elapsed: 26s, ETA:    38s[>>>>>>>>>>>>                  ] 203/500, 7.9 task/s, elapsed: 26s, ETA:    38s[>>>>>>>>>>>>                  ] 204/500, 7.9 task/s, elapsed: 26s, ETA:    37s[>>>>>>>>>>>>                  ] 205/500, 7.8 task/s, elapsed: 26s, ETA:    38s[>>>>>>>>>>>>                  ] 206/500, 7.8 task/s, elapsed: 26s, ETA:    38s[>>>>>>>>>>>>                  ] 207/500, 7.9 task/s, elapsed: 26s, ETA:    37s[>>>>>>>>>>>>                  ] 208/500, 7.9 task/s, elapsed: 26s, ETA:    37s[>>>>>>>>>>>>                  ] 209/500, 7.8 task/s, elapsed: 27s, ETA:    37s[>>>>>>>>>>>>                  ] 210/500, 7.8 task/s, elapsed: 27s, ETA:    37s[>>>>>>>>>>>>                  ] 211/500, 7.9 task/s, elapsed: 27s, ETA:    37s[>>>>>>>>>>>>                  ] 212/500, 7.9 task/s, elapsed: 27s, ETA:    36s[>>>>>>>>>>>>                  ] 213/500, 7.8 task/s, elapsed: 27s, ETA:    37s[>>>>>>>>>>>>                  ] 214/500, 7.8 task/s, elapsed: 27s, ETA:    37s[>>>>>>>>>>>>                  ] 215/500, 7.9 task/s, elapsed: 27s, ETA:    36s[>>>>>>>>>>>>                  ] 216/500, 7.9 task/s, elapsed: 27s, ETA:    36s[>>>>>>>>>>>>>                 ] 217/500, 7.8 task/s, elapsed: 28s, ETA:    36s[>>>>>>>>>>>>>                 ] 218/500, 7.8 task/s, elapsed: 28s, ETA:    36s[>>>>>>>>>>>>>                 ] 219/500, 7.9 task/s, elapsed: 28s, ETA:    36s[>>>>>>>>>>>>>                 ] 220/500, 7.9 task/s, elapsed: 28s, ETA:    35s[>>>>>>>>>>>>>                 ] 221/500, 7.8 task/s, elapsed: 28s, ETA:    36s[>>>>>>>>>>>>>                 ] 222/500, 7.8 task/s, elapsed: 28s, ETA:    36s[>>>>>>>>>>>>>                 ] 223/500, 7.9 task/s, elapsed: 28s, ETA:    35s[>>>>>>>>>>>>>                 ] 224/500, 7.9 task/s, elapsed: 28s, ETA:    35s[>>>>>>>>>>>>>                 ] 225/500, 7.8 task/s, elapsed: 29s, ETA:    35s[>>>>>>>>>>>>>                 ] 226/500, 7.8 task/s, elapsed: 29s, ETA:    35s[>>>>>>>>>>>>>                 ] 227/500, 7.9 task/s, elapsed: 29s, ETA:    35s[>>>>>>>>>>>>>                 ] 228/500, 7.9 task/s, elapsed: 29s, ETA:    34s[>>>>>>>>>>>>>                 ] 229/500, 7.8 task/s, elapsed: 29s, ETA:    35s[>>>>>>>>>>>>>                 ] 230/500, 7.8 task/s, elapsed: 29s, ETA:    34s[>>>>>>>>>>>>>                 ] 231/500, 7.9 task/s, elapsed: 29s, ETA:    34s[>>>>>>>>>>>>>                 ] 232/500, 7.9 task/s, elapsed: 29s, ETA:    34s[>>>>>>>>>>>>>                 ] 233/500, 7.8 task/s, elapsed: 30s, ETA:    34s[>>>>>>>>>>>>>>                ] 234/500, 7.8 task/s, elapsed: 30s, ETA:    34s[>>>>>>>>>>>>>>                ] 235/500, 7.9 task/s, elapsed: 30s, ETA:    34s[>>>>>>>>>>>>>>                ] 236/500, 7.9 task/s, elapsed: 30s, ETA:    33s[>>>>>>>>>>>>>>                ] 237/500, 7.8 task/s, elapsed: 30s, ETA:    34s[>>>>>>>>>>>>>>                ] 238/500, 7.8 task/s, elapsed: 30s, ETA:    33s[>>>>>>>>>>>>>>                ] 239/500, 7.9 task/s, elapsed: 30s, ETA:    33s[>>>>>>>>>>>>>>                ] 240/500, 7.9 task/s, elapsed: 30s, ETA:    33s[>>>>>>>>>>>>>>                ] 241/500, 7.8 task/s, elapsed: 31s, ETA:    33s[>>>>>>>>>>>>>>                ] 242/500, 7.8 task/s, elapsed: 31s, ETA:    33s[>>>>>>>>>>>>>>                ] 243/500, 7.9 task/s, elapsed: 31s, ETA:    33s[>>>>>>>>>>>>>>                ] 244/500, 7.9 task/s, elapsed: 31s, ETA:    32s[>>>>>>>>>>>>>>                ] 245/500, 7.8 task/s, elapsed: 31s, ETA:    33s[>>>>>>>>>>>>>>                ] 246/500, 7.9 task/s, elapsed: 31s, ETA:    32s[>>>>>>>>>>>>>>                ] 247/500, 7.9 task/s, elapsed: 31s, ETA:    32s[>>>>>>>>>>>>>>                ] 248/500, 7.9 task/s, elapsed: 31s, ETA:    32s[>>>>>>>>>>>>>>                ] 249/500, 7.8 task/s, elapsed: 32s, ETA:    32s[>>>>>>>>>>>>>>>               ] 250/500, 7.9 task/s, elapsed: 32s, ETA:    32s[>>>>>>>>>>>>>>>               ] 251/500, 7.9 task/s, elapsed: 32s, ETA:    32s[>>>>>>>>>>>>>>>               ] 252/500, 7.9 task/s, elapsed: 32s, ETA:    31s[>>>>>>>>>>>>>>>               ] 253/500, 7.8 task/s, elapsed: 32s, ETA:    32s[>>>>>>>>>>>>>>>               ] 254/500, 7.9 task/s, elapsed: 32s, ETA:    31s[>>>>>>>>>>>>>>>               ] 255/500, 7.9 task/s, elapsed: 32s, ETA:    31s[>>>>>>>>>>>>>>>               ] 256/500, 7.9 task/s, elapsed: 32s, ETA:    31s[>>>>>>>>>>>>>>>               ] 257/500, 7.8 task/s, elapsed: 33s, ETA:    31s[>>>>>>>>>>>>>>>               ] 258/500, 7.9 task/s, elapsed: 33s, ETA:    31s[>>>>>>>>>>>>>>>               ] 259/500, 7.9 task/s, elapsed: 33s, ETA:    31s[>>>>>>>>>>>>>>>               ] 260/500, 7.9 task/s, elapsed: 33s, ETA:    30s[>>>>>>>>>>>>>>>               ] 261/500, 7.8 task/s, elapsed: 33s, ETA:    31s[>>>>>>>>>>>>>>>               ] 262/500, 7.9 task/s, elapsed: 33s, ETA:    30s[>>>>>>>>>>>>>>>               ] 263/500, 7.9 task/s, elapsed: 33s, ETA:    30s[>>>>>>>>>>>>>>>               ] 264/500, 7.9 task/s, elapsed: 33s, ETA:    30s[>>>>>>>>>>>>>>>               ] 265/500, 7.8 task/s, elapsed: 34s, ETA:    30s[>>>>>>>>>>>>>>>               ] 266/500, 7.9 task/s, elapsed: 34s, ETA:    30s[>>>>>>>>>>>>>>>>              ] 267/500, 7.9 task/s, elapsed: 34s, ETA:    30s[>>>>>>>>>>>>>>>>              ] 268/500, 7.9 task/s, elapsed: 34s, ETA:    29s[>>>>>>>>>>>>>>>>              ] 269/500, 7.8 task/s, elapsed: 34s, ETA:    29s[>>>>>>>>>>>>>>>>              ] 270/500, 7.9 task/s, elapsed: 34s, ETA:    29s[>>>>>>>>>>>>>>>>              ] 271/500, 7.9 task/s, elapsed: 34s, ETA:    29s[>>>>>>>>>>>>>>>>              ] 272/500, 7.9 task/s, elapsed: 34s, ETA:    29s[>>>>>>>>>>>>>>>>              ] 273/500, 7.8 task/s, elapsed: 35s, ETA:    29s[>>>>>>>>>>>>>>>>              ] 274/500, 7.9 task/s, elapsed: 35s, ETA:    29s[>>>>>>>>>>>>>>>>              ] 275/500, 7.9 task/s, elapsed: 35s, ETA:    28s[>>>>>>>>>>>>>>>>              ] 276/500, 7.9 task/s, elapsed: 35s, ETA:    28s[>>>>>>>>>>>>>>>>              ] 277/500, 7.8 task/s, elapsed: 35s, ETA:    28s[>>>>>>>>>>>>>>>>              ] 278/500, 7.9 task/s, elapsed: 35s, ETA:    28s[>>>>>>>>>>>>>>>>              ] 279/500, 7.9 task/s, elapsed: 35s, ETA:    28s[>>>>>>>>>>>>>>>>              ] 280/500, 7.9 task/s, elapsed: 35s, ETA:    28s[>>>>>>>>>>>>>>>>              ] 281/500, 7.8 task/s, elapsed: 36s, ETA:    28s[>>>>>>>>>>>>>>>>              ] 282/500, 7.9 task/s, elapsed: 36s, ETA:    28s[>>>>>>>>>>>>>>>>              ] 283/500, 7.9 task/s, elapsed: 36s, ETA:    27s[>>>>>>>>>>>>>>>>>             ] 284/500, 7.9 task/s, elapsed: 36s, ETA:    27s[>>>>>>>>>>>>>>>>>             ] 285/500, 7.8 task/s, elapsed: 36s, ETA:    27s[>>>>>>>>>>>>>>>>>             ] 286/500, 7.9 task/s, elapsed: 36s, ETA:    27s[>>>>>>>>>>>>>>>>>             ] 287/500, 7.9 task/s, elapsed: 36s, ETA:    27s[>>>>>>>>>>>>>>>>>             ] 288/500, 7.9 task/s, elapsed: 36s, ETA:    27s[>>>>>>>>>>>>>>>>>             ] 289/500, 7.8 task/s, elapsed: 37s, ETA:    27s[>>>>>>>>>>>>>>>>>             ] 290/500, 7.9 task/s, elapsed: 37s, ETA:    27s[>>>>>>>>>>>>>>>>>             ] 291/500, 7.9 task/s, elapsed: 37s, ETA:    26s[>>>>>>>>>>>>>>>>>             ] 292/500, 7.9 task/s, elapsed: 37s, ETA:    26s[>>>>>>>>>>>>>>>>>             ] 293/500, 7.9 task/s, elapsed: 37s, ETA:    26s[>>>>>>>>>>>>>>>>>             ] 294/500, 7.9 task/s, elapsed: 37s, ETA:    26s[>>>>>>>>>>>>>>>>>             ] 295/500, 7.9 task/s, elapsed: 37s, ETA:    26s[>>>>>>>>>>>>>>>>>             ] 296/500, 7.9 task/s, elapsed: 37s, ETA:    26s[>>>>>>>>>>>>>>>>>             ] 297/500, 7.9 task/s, elapsed: 38s, ETA:    26s[>>>>>>>>>>>>>>>>>             ] 298/500, 7.9 task/s, elapsed: 38s, ETA:    26s[>>>>>>>>>>>>>>>>>             ] 299/500, 7.9 task/s, elapsed: 38s, ETA:    25s[>>>>>>>>>>>>>>>>>>            ] 300/500, 7.9 task/s, elapsed: 38s, ETA:    25s[>>>>>>>>>>>>>>>>>>            ] 301/500, 7.9 task/s, elapsed: 38s, ETA:    25s[>>>>>>>>>>>>>>>>>>            ] 302/500, 7.9 task/s, elapsed: 38s, ETA:    25s[>>>>>>>>>>>>>>>>>>            ] 303/500, 7.9 task/s, elapsed: 38s, ETA:    25s[>>>>>>>>>>>>>>>>>>            ] 304/500, 7.9 task/s, elapsed: 38s, ETA:    25s[>>>>>>>>>>>>>>>>>>            ] 305/500, 7.9 task/s, elapsed: 39s, ETA:    25s[>>>>>>>>>>>>>>>>>>            ] 306/500, 7.9 task/s, elapsed: 39s, ETA:    25s[>>>>>>>>>>>>>>>>>>            ] 307/500, 7.9 task/s, elapsed: 39s, ETA:    24s[>>>>>>>>>>>>>>>>>>            ] 308/500, 7.9 task/s, elapsed: 39s, ETA:    24s[>>>>>>>>>>>>>>>>>>            ] 309/500, 7.9 task/s, elapsed: 39s, ETA:    24s[>>>>>>>>>>>>>>>>>>            ] 310/500, 7.9 task/s, elapsed: 39s, ETA:    24s[>>>>>>>>>>>>>>>>>>            ] 311/500, 7.9 task/s, elapsed: 39s, ETA:    24s[>>>>>>>>>>>>>>>>>>            ] 312/500, 7.9 task/s, elapsed: 39s, ETA:    24s[>>>>>>>>>>>>>>>>>>            ] 313/500, 7.9 task/s, elapsed: 40s, ETA:    24s[>>>>>>>>>>>>>>>>>>            ] 314/500, 7.9 task/s, elapsed: 40s, ETA:    24s[>>>>>>>>>>>>>>>>>>            ] 315/500, 7.9 task/s, elapsed: 40s, ETA:    23s[>>>>>>>>>>>>>>>>>>            ] 316/500, 7.9 task/s, elapsed: 40s, ETA:    23s[>>>>>>>>>>>>>>>>>>>           ] 317/500, 7.9 task/s, elapsed: 40s, ETA:    23s[>>>>>>>>>>>>>>>>>>>           ] 318/500, 7.9 task/s, elapsed: 40s, ETA:    23s[>>>>>>>>>>>>>>>>>>>           ] 319/500, 7.9 task/s, elapsed: 40s, ETA:    23s[>>>>>>>>>>>>>>>>>>>           ] 320/500, 8.0 task/s, elapsed: 40s, ETA:    23s[>>>>>>>>>>>>>>>>>>>           ] 321/500, 7.9 task/s, elapsed: 41s, ETA:    23s[>>>>>>>>>>>>>>>>>>>           ] 322/500, 7.9 task/s, elapsed: 41s, ETA:    22s[>>>>>>>>>>>>>>>>>>>           ] 323/500, 7.9 task/s, elapsed: 41s, ETA:    22s[>>>>>>>>>>>>>>>>>>>           ] 324/500, 8.0 task/s, elapsed: 41s, ETA:    22s[>>>>>>>>>>>>>>>>>>>           ] 325/500, 7.9 task/s, elapsed: 41s, ETA:    22s[>>>>>>>>>>>>>>>>>>>           ] 326/500, 7.9 task/s, elapsed: 41s, ETA:    22s[>>>>>>>>>>>>>>>>>>>           ] 327/500, 7.9 task/s, elapsed: 41s, ETA:    22s[>>>>>>>>>>>>>>>>>>>           ] 328/500, 8.0 task/s, elapsed: 41s, ETA:    22s[>>>>>>>>>>>>>>>>>>>           ] 329/500, 7.9 task/s, elapsed: 42s, ETA:    22s[>>>>>>>>>>>>>>>>>>>           ] 330/500, 7.9 task/s, elapsed: 42s, ETA:    21s[>>>>>>>>>>>>>>>>>>>           ] 331/500, 7.9 task/s, elapsed: 42s, ETA:    21s[>>>>>>>>>>>>>>>>>>>           ] 332/500, 8.0 task/s, elapsed: 42s, ETA:    21s[>>>>>>>>>>>>>>>>>>>           ] 333/500, 7.9 task/s, elapsed: 42s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>          ] 334/500, 7.9 task/s, elapsed: 42s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>          ] 335/500, 7.9 task/s, elapsed: 42s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>          ] 336/500, 8.0 task/s, elapsed: 42s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>          ] 337/500, 7.9 task/s, elapsed: 43s, ETA:    21s[>>>>>>>>>>>>>>>>>>>>          ] 338/500, 7.9 task/s, elapsed: 43s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>          ] 339/500, 7.9 task/s, elapsed: 43s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>          ] 340/500, 8.0 task/s, elapsed: 43s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>          ] 341/500, 7.9 task/s, elapsed: 43s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>          ] 342/500, 7.9 task/s, elapsed: 43s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>          ] 343/500, 7.9 task/s, elapsed: 43s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>          ] 344/500, 8.0 task/s, elapsed: 43s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>          ] 345/500, 7.9 task/s, elapsed: 44s, ETA:    20s[>>>>>>>>>>>>>>>>>>>>          ] 346/500, 7.9 task/s, elapsed: 44s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>          ] 347/500, 7.9 task/s, elapsed: 44s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>          ] 348/500, 8.0 task/s, elapsed: 44s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>          ] 349/500, 7.9 task/s, elapsed: 44s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>         ] 350/500, 7.9 task/s, elapsed: 44s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>         ] 351/500, 7.9 task/s, elapsed: 44s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>         ] 352/500, 8.0 task/s, elapsed: 44s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>         ] 353/500, 7.9 task/s, elapsed: 45s, ETA:    19s[>>>>>>>>>>>>>>>>>>>>>         ] 354/500, 7.9 task/s, elapsed: 45s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>         ] 355/500, 7.9 task/s, elapsed: 45s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>         ] 356/500, 8.0 task/s, elapsed: 45s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>         ] 357/500, 7.9 task/s, elapsed: 45s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>         ] 358/500, 7.9 task/s, elapsed: 45s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>         ] 359/500, 7.9 task/s, elapsed: 45s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>         ] 360/500, 8.0 task/s, elapsed: 45s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>         ] 361/500, 7.9 task/s, elapsed: 46s, ETA:    18s[>>>>>>>>>>>>>>>>>>>>>         ] 362/500, 7.9 task/s, elapsed: 46s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>         ] 363/500, 7.9 task/s, elapsed: 46s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>         ] 364/500, 8.0 task/s, elapsed: 46s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>         ] 365/500, 7.9 task/s, elapsed: 46s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>         ] 366/500, 7.9 task/s, elapsed: 46s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>        ] 367/500, 7.9 task/s, elapsed: 46s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>        ] 368/500, 8.0 task/s, elapsed: 46s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>        ] 369/500, 7.9 task/s, elapsed: 47s, ETA:    17s[>>>>>>>>>>>>>>>>>>>>>>        ] 370/500, 7.9 task/s, elapsed: 47s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>        ] 371/500, 8.0 task/s, elapsed: 47s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>        ] 372/500, 8.0 task/s, elapsed: 47s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>        ] 373/500, 7.9 task/s, elapsed: 47s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>        ] 374/500, 7.9 task/s, elapsed: 47s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>        ] 375/500, 8.0 task/s, elapsed: 47s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>        ] 376/500, 8.0 task/s, elapsed: 47s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>        ] 377/500, 7.9 task/s, elapsed: 48s, ETA:    16s[>>>>>>>>>>>>>>>>>>>>>>        ] 378/500, 7.9 task/s, elapsed: 48s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>        ] 379/500, 8.0 task/s, elapsed: 48s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>        ] 380/500, 8.0 task/s, elapsed: 48s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>        ] 381/500, 7.9 task/s, elapsed: 48s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>        ] 382/500, 7.9 task/s, elapsed: 48s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>        ] 383/500, 8.0 task/s, elapsed: 48s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>       ] 384/500, 8.0 task/s, elapsed: 48s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>       ] 385/500, 7.9 task/s, elapsed: 49s, ETA:    15s[>>>>>>>>>>>>>>>>>>>>>>>       ] 386/500, 7.9 task/s, elapsed: 49s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>       ] 387/500, 8.0 task/s, elapsed: 49s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>       ] 388/500, 8.0 task/s, elapsed: 49s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>       ] 389/500, 7.9 task/s, elapsed: 49s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>       ] 390/500, 7.9 task/s, elapsed: 49s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>       ] 391/500, 8.0 task/s, elapsed: 49s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>       ] 392/500, 8.0 task/s, elapsed: 49s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>       ] 393/500, 7.9 task/s, elapsed: 50s, ETA:    14s[>>>>>>>>>>>>>>>>>>>>>>>       ] 394/500, 7.9 task/s, elapsed: 50s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>       ] 395/500, 8.0 task/s, elapsed: 50s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>       ] 396/500, 8.0 task/s, elapsed: 50s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>       ] 397/500, 7.9 task/s, elapsed: 50s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>       ] 398/500, 7.9 task/s, elapsed: 50s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>       ] 399/500, 8.0 task/s, elapsed: 50s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 400/500, 8.0 task/s, elapsed: 50s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 401/500, 7.9 task/s, elapsed: 51s, ETA:    13s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 402/500, 7.9 task/s, elapsed: 51s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 403/500, 7.9 task/s, elapsed: 51s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 404/500, 8.0 task/s, elapsed: 51s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 405/500, 7.9 task/s, elapsed: 51s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 406/500, 7.9 task/s, elapsed: 51s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 407/500, 7.9 task/s, elapsed: 51s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 408/500, 8.0 task/s, elapsed: 51s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 409/500, 7.9 task/s, elapsed: 52s, ETA:    12s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 410/500, 7.9 task/s, elapsed: 52s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 411/500, 7.9 task/s, elapsed: 52s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 412/500, 8.0 task/s, elapsed: 52s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 413/500, 7.9 task/s, elapsed: 52s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 414/500, 7.9 task/s, elapsed: 52s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 415/500, 8.0 task/s, elapsed: 52s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>      ] 416/500, 8.0 task/s, elapsed: 52s, ETA:    11s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 417/500, 7.9 task/s, elapsed: 53s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 418/500, 7.9 task/s, elapsed: 53s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 419/500, 8.0 task/s, elapsed: 53s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 420/500, 8.0 task/s, elapsed: 53s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 421/500, 7.9 task/s, elapsed: 53s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 422/500, 7.9 task/s, elapsed: 53s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 423/500, 8.0 task/s, elapsed: 53s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 424/500, 8.0 task/s, elapsed: 53s, ETA:    10s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 425/500, 7.9 task/s, elapsed: 54s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 426/500, 7.9 task/s, elapsed: 54s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 427/500, 7.9 task/s, elapsed: 54s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 428/500, 8.0 task/s, elapsed: 54s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 429/500, 7.9 task/s, elapsed: 54s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 430/500, 7.9 task/s, elapsed: 54s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 431/500, 8.0 task/s, elapsed: 54s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 432/500, 8.0 task/s, elapsed: 54s, ETA:     9s[>>>>>>>>>>>>>>>>>>>>>>>>>     ] 433/500, 7.9 task/s, elapsed: 55s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 434/500, 7.9 task/s, elapsed: 55s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 435/500, 8.0 task/s, elapsed: 55s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 436/500, 8.0 task/s, elapsed: 55s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 437/500, 7.9 task/s, elapsed: 55s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 438/500, 7.9 task/s, elapsed: 55s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 439/500, 8.0 task/s, elapsed: 55s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 440/500, 8.0 task/s, elapsed: 55s, ETA:     8s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 441/500, 7.9 task/s, elapsed: 56s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 442/500, 7.9 task/s, elapsed: 56s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 443/500, 8.0 task/s, elapsed: 56s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 444/500, 8.0 task/s, elapsed: 56s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 445/500, 7.9 task/s, elapsed: 56s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 446/500, 7.9 task/s, elapsed: 56s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 447/500, 8.0 task/s, elapsed: 56s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 448/500, 8.0 task/s, elapsed: 56s, ETA:     7s[>>>>>>>>>>>>>>>>>>>>>>>>>>    ] 449/500, 7.9 task/s, elapsed: 57s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 450/500, 7.9 task/s, elapsed: 57s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 451/500, 8.0 task/s, elapsed: 57s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 452/500, 8.0 task/s, elapsed: 57s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 453/500, 7.9 task/s, elapsed: 57s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 454/500, 7.9 task/s, elapsed: 57s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 455/500, 8.0 task/s, elapsed: 57s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 456/500, 8.0 task/s, elapsed: 57s, ETA:     6s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 457/500, 7.9 task/s, elapsed: 58s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 458/500, 7.9 task/s, elapsed: 58s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 459/500, 8.0 task/s, elapsed: 58s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 460/500, 8.0 task/s, elapsed: 58s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 461/500, 7.9 task/s, elapsed: 58s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 462/500, 7.9 task/s, elapsed: 58s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 463/500, 8.0 task/s, elapsed: 58s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 464/500, 8.0 task/s, elapsed: 58s, ETA:     5s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 465/500, 7.9 task/s, elapsed: 59s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 466/500, 7.9 task/s, elapsed: 59s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 467/500, 8.0 task/s, elapsed: 59s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 468/500, 8.0 task/s, elapsed: 59s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 469/500, 7.9 task/s, elapsed: 59s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 470/500, 7.9 task/s, elapsed: 59s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 471/500, 7.9 task/s, elapsed: 59s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 472/500, 8.0 task/s, elapsed: 59s, ETA:     4s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 473/500, 7.9 task/s, elapsed: 60s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 474/500, 7.9 task/s, elapsed: 60s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 475/500, 7.9 task/s, elapsed: 60s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 476/500, 8.0 task/s, elapsed: 60s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 477/500, 7.9 task/s, elapsed: 60s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 478/500, 7.9 task/s, elapsed: 60s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 479/500, 7.9 task/s, elapsed: 60s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 480/500, 8.0 task/s, elapsed: 60s, ETA:     3s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 481/500, 7.9 task/s, elapsed: 61s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 482/500, 7.9 task/s, elapsed: 61s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 483/500, 8.0 task/s, elapsed: 61s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 484/500, 8.0 task/s, elapsed: 61s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 485/500, 7.9 task/s, elapsed: 61s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 486/500, 7.9 task/s, elapsed: 61s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 487/500, 8.0 task/s, elapsed: 61s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 488/500, 8.0 task/s, elapsed: 61s, ETA:     2s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 489/500, 7.9 task/s, elapsed: 62s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 490/500, 7.9 task/s, elapsed: 62s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 491/500, 8.0 task/s, elapsed: 62s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 492/500, 8.0 task/s, elapsed: 62s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 493/500, 7.9 task/s, elapsed: 62s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 494/500, 7.9 task/s, elapsed: 62s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 495/500, 8.0 task/s, elapsed: 62s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 496/500, 8.0 task/s, elapsed: 62s, ETA:     1s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 497/500, 7.9 task/s, elapsed: 63s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 498/500, 7.9 task/s, elapsed: 63s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 499/500, 8.0 task/s, elapsed: 63s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 500/500, 8.0 task/s, elapsed: 63s, ETA:     0s

2022-03-23 19:14:18,625 - mmseg - INFO - per class results:
2022-03-23 19:14:18,626 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 97.85 | 98.69 |
|    sidewalk   | 83.57 | 92.09 |
|    building   | 92.03 | 96.35 |
|      wall     | 50.31 | 56.48 |
|     fence     | 56.86 | 73.14 |
|      pole     | 62.81 | 74.48 |
| traffic light | 69.37 | 81.32 |
|  traffic sign | 76.65 |  83.0 |
|   vegetation  | 92.17 | 96.59 |
|    terrain    | 60.97 | 67.12 |
|      sky      | 93.97 | 98.02 |
|     person    | 81.53 |  90.6 |
|     rider     | 62.12 | 75.46 |
|      car      |  94.8 | 97.62 |
|     truck     |  78.1 | 89.92 |
|      bus      | 87.21 | 92.02 |
|     train     | 77.66 | 87.95 |
|   motorcycle  | 65.33 | 77.03 |
|    bicycle    | 76.69 | 87.38 |
+---------------+-------+-------+
2022-03-23 19:14:18,626 - mmseg - INFO - Summary:
2022-03-23 19:14:18,626 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 95.77 | 76.84 | 85.01 |
+-------+-------+-------+
2022-03-23 19:14:18,627 - mmseg - INFO - Exp name: pprp_deeplabv3_r50-d8_512x1024_40k_cityscapes.py
2022-03-23 19:14:18,627 - mmseg - INFO - Iter(val) [125]	aAcc: 0.9577, mIoU: 0.7684, mAcc: 0.8501, IoU.road: 0.9785, IoU.sidewalk: 0.8357, IoU.building: 0.9203, IoU.wall: 0.5031, IoU.fence: 0.5686, IoU.pole: 0.6281, IoU.traffic light: 0.6937, IoU.traffic sign: 0.7665, IoU.vegetation: 0.9217, IoU.terrain: 0.6097, IoU.sky: 0.9397, IoU.person: 0.8153, IoU.rider: 0.6212, IoU.car: 0.9480, IoU.truck: 0.7810, IoU.bus: 0.8721, IoU.train: 0.7766, IoU.motorcycle: 0.6533, IoU.bicycle: 0.7669, Acc.road: 0.9869, Acc.sidewalk: 0.9209, Acc.building: 0.9635, Acc.wall: 0.5648, Acc.fence: 0.7314, Acc.pole: 0.7448, Acc.traffic light: 0.8132, Acc.traffic sign: 0.8300, Acc.vegetation: 0.9659, Acc.terrain: 0.6712, Acc.sky: 0.9802, Acc.person: 0.9060, Acc.rider: 0.7546, Acc.car: 0.9762, Acc.truck: 0.8992, Acc.bus: 0.9202, Acc.train: 0.8795, Acc.motorcycle: 0.7703, Acc.bicycle: 0.8738
2022-03-23 19:15:08,057 - mmseg - INFO - Iter [48050/50000]	lr: 6.343e-04, eta: 0:35:41, time: 2.246, data_time: 1.265, memory: 19929, decode.loss_ce: 0.1330, decode.acc_seg: 95.1178, aux.loss_ce: 0.0778, aux.acc_seg: 93.1833, loss: 0.2107
2022-03-23 19:15:57,714 - mmseg - INFO - Iter [48100/50000]	lr: 6.220e-04, eta: 0:34:45, time: 0.993, data_time: 0.009, memory: 19929, decode.loss_ce: 0.1370, decode.acc_seg: 94.9018, aux.loss_ce: 0.0768, aux.acc_seg: 93.3047, loss: 0.2138
2022-03-23 19:16:47,223 - mmseg - INFO - Iter [48150/50000]	lr: 6.096e-04, eta: 0:33:49, time: 0.990, data_time: 0.009, memory: 19929, decode.loss_ce: 0.1301, decode.acc_seg: 95.2632, aux.loss_ce: 0.0758, aux.acc_seg: 93.4783, loss: 0.2059
2022-03-23 19:17:39,257 - mmseg - INFO - Iter [48200/50000]	lr: 5.972e-04, eta: 0:32:53, time: 1.041, data_time: 0.055, memory: 19929, decode.loss_ce: 0.1251, decode.acc_seg: 95.2721, aux.loss_ce: 0.0693, aux.acc_seg: 93.9519, loss: 0.1944
2022-03-23 19:18:29,063 - mmseg - INFO - Iter [48250/50000]	lr: 5.848e-04, eta: 0:31:57, time: 0.996, data_time: 0.009, memory: 19929, decode.loss_ce: 0.1295, decode.acc_seg: 95.2817, aux.loss_ce: 0.0753, aux.acc_seg: 93.5047, loss: 0.2048
2022-03-23 19:19:18,788 - mmseg - INFO - Iter [48300/50000]	lr: 5.723e-04, eta: 0:31:02, time: 0.994, data_time: 0.009, memory: 19929, decode.loss_ce: 0.1284, decode.acc_seg: 95.2006, aux.loss_ce: 0.0734, aux.acc_seg: 93.6402, loss: 0.2018
2022-03-23 19:20:08,244 - mmseg - INFO - Iter [48350/50000]	lr: 5.598e-04, eta: 0:30:06, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1260, decode.acc_seg: 95.2757, aux.loss_ce: 0.0741, aux.acc_seg: 93.5405, loss: 0.2001
2022-03-23 19:20:57,786 - mmseg - INFO - Iter [48400/50000]	lr: 5.472e-04, eta: 0:29:10, time: 0.991, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1298, decode.acc_seg: 95.2756, aux.loss_ce: 0.0720, aux.acc_seg: 93.8828, loss: 0.2018
2022-03-23 19:21:47,244 - mmseg - INFO - Iter [48450/50000]	lr: 5.346e-04, eta: 0:28:14, time: 0.989, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1356, decode.acc_seg: 95.0335, aux.loss_ce: 0.0787, aux.acc_seg: 93.2164, loss: 0.2143
2022-03-23 19:22:36,829 - mmseg - INFO - Iter [48500/50000]	lr: 5.220e-04, eta: 0:27:19, time: 0.992, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1229, decode.acc_seg: 95.4735, aux.loss_ce: 0.0702, aux.acc_seg: 93.8897, loss: 0.1931
2022-03-23 19:23:26,383 - mmseg - INFO - Iter [48550/50000]	lr: 5.093e-04, eta: 0:26:23, time: 0.991, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1312, decode.acc_seg: 95.1069, aux.loss_ce: 0.0751, aux.acc_seg: 93.4627, loss: 0.2063
2022-03-23 19:24:18,250 - mmseg - INFO - Iter [48600/50000]	lr: 4.966e-04, eta: 0:25:28, time: 1.037, data_time: 0.054, memory: 19929, decode.loss_ce: 0.1339, decode.acc_seg: 95.1394, aux.loss_ce: 0.0783, aux.acc_seg: 93.3082, loss: 0.2122
2022-03-23 19:25:07,763 - mmseg - INFO - Iter [48650/50000]	lr: 4.838e-04, eta: 0:24:33, time: 0.990, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1295, decode.acc_seg: 95.2120, aux.loss_ce: 0.0745, aux.acc_seg: 93.6436, loss: 0.2039
2022-03-23 19:25:57,325 - mmseg - INFO - Iter [48700/50000]	lr: 4.710e-04, eta: 0:23:37, time: 0.991, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1289, decode.acc_seg: 95.2131, aux.loss_ce: 0.0729, aux.acc_seg: 93.6348, loss: 0.2018
2022-03-23 19:26:46,995 - mmseg - INFO - Iter [48750/50000]	lr: 4.582e-04, eta: 0:22:42, time: 0.994, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1317, decode.acc_seg: 95.0755, aux.loss_ce: 0.0748, aux.acc_seg: 93.4666, loss: 0.2065
2022-03-23 19:27:36,592 - mmseg - INFO - Iter [48800/50000]	lr: 4.453e-04, eta: 0:21:47, time: 0.992, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1325, decode.acc_seg: 95.0751, aux.loss_ce: 0.0759, aux.acc_seg: 93.4759, loss: 0.2084
2022-03-23 19:28:26,163 - mmseg - INFO - Iter [48850/50000]	lr: 4.323e-04, eta: 0:20:52, time: 0.991, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1325, decode.acc_seg: 95.0736, aux.loss_ce: 0.0770, aux.acc_seg: 93.3782, loss: 0.2094
2022-03-23 19:29:15,545 - mmseg - INFO - Iter [48900/50000]	lr: 4.193e-04, eta: 0:19:57, time: 0.988, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1259, decode.acc_seg: 95.3443, aux.loss_ce: 0.0761, aux.acc_seg: 93.4401, loss: 0.2020
2022-03-23 19:30:07,470 - mmseg - INFO - Iter [48950/50000]	lr: 4.062e-04, eta: 0:19:02, time: 1.038, data_time: 0.055, memory: 19929, decode.loss_ce: 0.1321, decode.acc_seg: 95.1905, aux.loss_ce: 0.0758, aux.acc_seg: 93.5108, loss: 0.2079
2022-03-23 19:30:57,037 - mmseg - INFO - Exp name: pprp_deeplabv3_r50-d8_512x1024_40k_cityscapes.py
2022-03-23 19:30:57,038 - mmseg - INFO - Iter [49000/50000]	lr: 3.931e-04, eta: 0:18:07, time: 0.991, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1229, decode.acc_seg: 95.5100, aux.loss_ce: 0.0696, aux.acc_seg: 93.9820, loss: 0.1925
2022-03-23 19:31:46,702 - mmseg - INFO - Iter [49050/50000]	lr: 3.798e-04, eta: 0:17:12, time: 0.993, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1271, decode.acc_seg: 95.2858, aux.loss_ce: 0.0730, aux.acc_seg: 93.6762, loss: 0.2001
2022-03-23 19:32:36,437 - mmseg - INFO - Iter [49100/50000]	lr: 3.666e-04, eta: 0:16:18, time: 0.995, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1291, decode.acc_seg: 95.2169, aux.loss_ce: 0.0743, aux.acc_seg: 93.4715, loss: 0.2034
2022-03-23 19:33:26,124 - mmseg - INFO - Iter [49150/50000]	lr: 3.532e-04, eta: 0:15:23, time: 0.994, data_time: 0.009, memory: 19929, decode.loss_ce: 0.1278, decode.acc_seg: 95.2740, aux.loss_ce: 0.0722, aux.acc_seg: 93.6338, loss: 0.2000
2022-03-23 19:34:15,859 - mmseg - INFO - Iter [49200/50000]	lr: 3.398e-04, eta: 0:14:28, time: 0.995, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1305, decode.acc_seg: 95.1233, aux.loss_ce: 0.0764, aux.acc_seg: 93.4975, loss: 0.2069
2022-03-23 19:35:05,466 - mmseg - INFO - Iter [49250/50000]	lr: 3.263e-04, eta: 0:13:33, time: 0.992, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1248, decode.acc_seg: 95.3398, aux.loss_ce: 0.0698, aux.acc_seg: 93.9831, loss: 0.1946
2022-03-23 19:35:57,581 - mmseg - INFO - Iter [49300/50000]	lr: 3.127e-04, eta: 0:12:39, time: 1.042, data_time: 0.056, memory: 19929, decode.loss_ce: 0.1225, decode.acc_seg: 95.4799, aux.loss_ce: 0.0695, aux.acc_seg: 93.9445, loss: 0.1920
2022-03-23 19:36:47,381 - mmseg - INFO - Iter [49350/50000]	lr: 2.990e-04, eta: 0:11:44, time: 0.996, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1275, decode.acc_seg: 95.2534, aux.loss_ce: 0.0765, aux.acc_seg: 93.3383, loss: 0.2040
2022-03-23 19:37:37,058 - mmseg - INFO - Iter [49400/50000]	lr: 2.852e-04, eta: 0:10:50, time: 0.994, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1275, decode.acc_seg: 95.3250, aux.loss_ce: 0.0727, aux.acc_seg: 93.8068, loss: 0.2002
2022-03-23 19:38:26,870 - mmseg - INFO - Iter [49450/50000]	lr: 2.712e-04, eta: 0:09:55, time: 0.996, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1271, decode.acc_seg: 95.2183, aux.loss_ce: 0.0749, aux.acc_seg: 93.4132, loss: 0.2020
2022-03-23 19:39:16,651 - mmseg - INFO - Iter [49500/50000]	lr: 2.572e-04, eta: 0:09:01, time: 0.996, data_time: 0.007, memory: 19929, decode.loss_ce: 0.1253, decode.acc_seg: 95.3494, aux.loss_ce: 0.0734, aux.acc_seg: 93.6533, loss: 0.1987
2022-03-23 19:40:06,728 - mmseg - INFO - Iter [49550/50000]	lr: 2.430e-04, eta: 0:08:07, time: 1.002, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1259, decode.acc_seg: 95.4069, aux.loss_ce: 0.0691, aux.acc_seg: 94.0799, loss: 0.1950
2022-03-23 19:40:56,792 - mmseg - INFO - Iter [49600/50000]	lr: 2.286e-04, eta: 0:07:12, time: 1.001, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1272, decode.acc_seg: 95.2628, aux.loss_ce: 0.0712, aux.acc_seg: 93.7985, loss: 0.1984
2022-03-23 19:41:46,866 - mmseg - INFO - Iter [49650/50000]	lr: 2.141e-04, eta: 0:06:18, time: 1.002, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1256, decode.acc_seg: 95.3699, aux.loss_ce: 0.0708, aux.acc_seg: 93.8995, loss: 0.1963
2022-03-23 19:42:39,443 - mmseg - INFO - Iter [49700/50000]	lr: 1.994e-04, eta: 0:05:24, time: 1.052, data_time: 0.055, memory: 19929, decode.loss_ce: 0.1293, decode.acc_seg: 95.1542, aux.loss_ce: 0.0741, aux.acc_seg: 93.5519, loss: 0.2034
2022-03-23 19:43:29,431 - mmseg - INFO - Iter [49750/50000]	lr: 1.844e-04, eta: 0:04:30, time: 1.000, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1195, decode.acc_seg: 95.5374, aux.loss_ce: 0.0683, aux.acc_seg: 94.0879, loss: 0.1879
2022-03-23 19:44:19,405 - mmseg - INFO - Iter [49800/50000]	lr: 1.691e-04, eta: 0:03:36, time: 1.000, data_time: 0.010, memory: 19929, decode.loss_ce: 0.1235, decode.acc_seg: 95.4137, aux.loss_ce: 0.0728, aux.acc_seg: 93.6435, loss: 0.1964
2022-03-23 19:45:09,269 - mmseg - INFO - Iter [49850/50000]	lr: 1.534e-04, eta: 0:02:42, time: 0.997, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1322, decode.acc_seg: 95.1161, aux.loss_ce: 0.0772, aux.acc_seg: 93.1581, loss: 0.2094
2022-03-23 19:45:59,147 - mmseg - INFO - Iter [49900/50000]	lr: 1.372e-04, eta: 0:01:47, time: 0.997, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1238, decode.acc_seg: 95.4892, aux.loss_ce: 0.0723, aux.acc_seg: 93.7625, loss: 0.1961
2022-03-23 19:46:48,711 - mmseg - INFO - Iter [49950/50000]	lr: 1.201e-04, eta: 0:00:53, time: 0.991, data_time: 0.008, memory: 19929, decode.loss_ce: 0.1328, decode.acc_seg: 95.1751, aux.loss_ce: 0.0764, aux.acc_seg: 93.4276, loss: 0.2092
2022-03-23 19:47:38,604 - mmseg - INFO - Saving checkpoint at 50000 iterations
2022-03-23 19:47:39,997 - mmseg - INFO - Exp name: pprp_deeplabv3_r50-d8_512x1024_40k_cityscapes.py
2022-03-23 19:47:39,997 - mmseg - INFO - Iter [50000/50000]	lr: 1.006e-04, eta: 0:00:00, time: 1.026, data_time: 0.009, memory: 19929, decode.loss_ce: 0.1211, decode.acc_seg: 95.5238, aux.loss_ce: 0.0685, aux.acc_seg: 94.0611, loss: 0.1896
